digraph G {
"iboing/CliqueNet" -> "visinf/dpp"
"iboing/CliqueNet" -> "shaohua0116/Group-Normalization-Tensorflow"
"salesforce/ALPRO" -> "tsujuifu/pytorch_violet"
"salesforce/ALPRO" -> "TencentARC/MCQ"
"salesforce/ALPRO" -> "foolwood/DRL"
"salesforce/ALPRO" -> "jayleicn/moment_detr"
"salesforce/ALPRO" -> "linjieli222/HERO"
"salesforce/ALPRO" -> "mengcaopku/LocVTP"
"salesforce/ALPRO" -> "TengdaHan/TemporalAlignNet"
"antoine77340/howto100m" -> "antoine77340/MIL-NCE_HowTo100M"
"antoine77340/howto100m" -> "antoine77340/S3D_HowTo100M"
"antoine77340/howto100m" -> "antoine77340/video_feature_extractor"
"antoine77340/howto100m" -> "cshizhe/hgr_v2t"
"antoine77340/howto100m" -> "gingsi/coot-videotext"
"antoine77340/howto100m" -> "salesforce/densecap"
"antoine77340/howto100m" -> "jayleicn/TVCaption"
"antoine77340/howto100m" -> "m-bain/frozen-in-time"
"antoine77340/howto100m" -> "microsoft/UniVL"
"vijayvee/video-captioning" -> "xiadingZ/video-caption.pytorch"
"vijayvee/video-captioning" -> "zhegan27/SCN_for_video_captioning"
"vijayvee/video-captioning" -> "tgc1997/Awesome-Video-Captioning"
"vijayvee/video-captioning" -> "tsenghungchen/SA-tensorflow"
"vijayvee/video-captioning" -> "scopeInfinity/Video2Description"
"vijayvee/video-captioning" -> "facebookresearch/grounded-video-description"
"vijayvee/video-captioning" -> "chenxinpeng/S2VT"
"vijayvee/video-captioning" -> "xiadingZ/video-caption-openNMT.pytorch"
"vijayvee/video-captioning" -> "JaywongWang/DenseVideoCaptioning"
"vijayvee/video-captioning" -> "CaptainEven/VideoCaption"
"vijayvee/video-captioning" -> "ranjaykrishna/densevid_eval"
"vijayvee/video-captioning" -> "vsubhashini/caffe"
"vijayvee/video-captioning" -> "yaoli/arctic-capgen-vid"
"vijayvee/video-captioning" -> "tgc1997/RMN"
"danieljf24/dual_encoding" -> "niluthpol/multimodal_vtt"
"danieljf24/dual_encoding" -> "danieljf24/hybrid_space"
"danieljf24/dual_encoding" -> "albanie/collaborative-experts"
"danieljf24/dual_encoding" -> "cshizhe/hgr_v2t"
"danieljf24/dual_encoding" -> "danieljf24/awesome-video-text-retrieval"
"danieljf24/dual_encoding" -> "xuchaoxi/video-cnn-feat"
"danieljf24/dual_encoding" -> "danieljf24/w2vv"
"danieljf24/dual_encoding" -> "niluthpol/weak_supervised_video_moment"
"danieljf24/dual_encoding" -> "MKLab-ITI/ndvr-dml" ["e"=1]
"danieljf24/dual_encoding" -> "jiyanggao/TALL"
"danieljf24/dual_encoding" -> "li-xirong/avs"
"tsenghungchen/SA-tensorflow" -> "zhegan27/SCN_for_video_captioning"
"tsenghungchen/SA-tensorflow" -> "yaoli/arctic-capgen-vid"
"tsenghungchen/SA-tensorflow" -> "vijayvee/video-captioning"
"tsenghungchen/SA-tensorflow" -> "jazzsaxmafia/video_to_sequence"
"tsenghungchen/SA-tensorflow" -> "Sundrops/video-caption.pytorch"
"tsenghungchen/SA-tensorflow" -> "vsubhashini/caffe"
"tsenghungchen/SA-tensorflow" -> "JaywongWang/DenseVideoCaptioning"
"tsenghungchen/SA-tensorflow" -> "Yugnaynehc/ssta-captioning"
"tsenghungchen/SA-tensorflow" -> "cgq5/Video-Caption-with-Neuraltalk2"
"tsenghungchen/SA-tensorflow" -> "chenxinpeng/S2VT"
"tsenghungchen/SA-tensorflow" -> "xiadingZ/video-caption.pytorch"
"CryhanFang/CLIP2Video" -> "ArrowLuo/CLIP4Clip"
"CryhanFang/CLIP2Video" -> "m-bain/frozen-in-time"
"CryhanFang/CLIP2Video" -> "danieljf24/awesome-video-text-retrieval"
"CryhanFang/CLIP2Video" -> "starmemda/CAMoE"
"CryhanFang/CLIP2Video" -> "foolwood/DRL"
"CryhanFang/CLIP2Video" -> "albanie/collaborative-experts"
"CryhanFang/CLIP2Video" -> "mzhaoshuai/CenterCLIP"
"CryhanFang/CLIP2Video" -> "jayleicn/ClipBERT" ["e"=1]
"CryhanFang/CLIP2Video" -> "layer6ai-labs/xpool"
"CryhanFang/CLIP2Video" -> "mwray/Semantic-Video-Retrieval"
"CryhanFang/CLIP2Video" -> "TencentARC/MCQ"
"CryhanFang/CLIP2Video" -> "cshizhe/hgr_v2t"
"CryhanFang/CLIP2Video" -> "Deferf/CLIP_Video_Representation"
"CryhanFang/CLIP2Video" -> "gabeur/mmt"
"CryhanFang/CLIP2Video" -> "sallymmx/ActionCLIP" ["e"=1]
"antoine77340/MIL-NCE_HowTo100M" -> "antoine77340/S3D_HowTo100M"
"antoine77340/MIL-NCE_HowTo100M" -> "antoine77340/howto100m"
"antoine77340/MIL-NCE_HowTo100M" -> "microsoft/UniVL"
"antoine77340/MIL-NCE_HowTo100M" -> "gingsi/coot-videotext"
"antoine77340/MIL-NCE_HowTo100M" -> "m-bain/frozen-in-time"
"antoine77340/MIL-NCE_HowTo100M" -> "TengdaHan/CoCLR" ["e"=1]
"antoine77340/MIL-NCE_HowTo100M" -> "antoine77340/video_feature_extractor"
"antoine77340/MIL-NCE_HowTo100M" -> "TengdaHan/TemporalAlignNet"
"antoine77340/MIL-NCE_HowTo100M" -> "HumamAlwassel/XDC" ["e"=1]
"antoine77340/MIL-NCE_HowTo100M" -> "linjieli222/HERO"
"antoine77340/MIL-NCE_HowTo100M" -> "jayleicn/ClipBERT" ["e"=1]
"antoine77340/MIL-NCE_HowTo100M" -> "cshizhe/hgr_v2t"
"antoine77340/MIL-NCE_HowTo100M" -> "facebookresearch/AVID-CMA"
"antoine77340/MIL-NCE_HowTo100M" -> "jayleicn/TVCaption"
"hobincar/pytorch-video-feature-extractor" -> "hobincar/RecNet"
"hobincar/pytorch-video-feature-extractor" -> "nasib-ullah/video-captioning-models-in-Pytorch"
"hobincar/pytorch-video-feature-extractor" -> "hobincar/SA-LSTM"
"ivendrov/order-embedding" -> "ivendrov/order-embeddings-wordnet"
"ivendrov/order-embedding" -> "ryankiros/visual-semantic-embedding"
"linxd5/VSE_Pytorch" -> "josharnoldjosh/Image-Caption-Joint-Embedding"
"m-bain/frozen-in-time" -> "CryhanFang/CLIP2Video"
"m-bain/frozen-in-time" -> "TencentARC/MCQ"
"m-bain/frozen-in-time" -> "ArrowLuo/CLIP4Clip"
"m-bain/frozen-in-time" -> "danieljf24/awesome-video-text-retrieval"
"m-bain/frozen-in-time" -> "showlab/all-in-one"
"m-bain/frozen-in-time" -> "antoine77340/MIL-NCE_HowTo100M"
"m-bain/frozen-in-time" -> "tsujuifu/pytorch_violet"
"m-bain/frozen-in-time" -> "jayleicn/singularity"
"m-bain/frozen-in-time" -> "jayleicn/ClipBERT" ["e"=1]
"m-bain/frozen-in-time" -> "microsoft/UniVL"
"m-bain/frozen-in-time" -> "m-bain/webvid"
"m-bain/frozen-in-time" -> "albanie/collaborative-experts"
"m-bain/frozen-in-time" -> "showlab/EgoVLP"
"m-bain/frozen-in-time" -> "gabeur/mmt"
"m-bain/frozen-in-time" -> "antoine77340/S3D_HowTo100M"
"yytzsy/SCDM" -> "ikuinen/CMIN_moment_retrieval"
"yytzsy/SCDM" -> "JaywongWang/CBP"
"yytzsy/SCDM" -> "runzhouge/MAC"
"yytzsy/SCDM" -> "JaywongWang/TGN"
"yytzsy/SCDM" -> "niluthpol/weak_supervised_video_moment"
"yytzsy/SCDM" -> "dazhang-cv/MAN"
"yytzsy/SCDM" -> "BonnieHuangxin/SLTA"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "WuJie1010/Temporally-language-grounding"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "WuJie1010/TSP-PRL"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "JonghwanMun/LGI4temporalgrounding"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "ikuinen/CMIN_moment_retrieval"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "JaywongWang/CBP"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "microsoft/2D-TAN"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "yytzsy/SCDM"
"WuJie1010/Awesome-Temporally-Language-Grounding" -> "LisaAnne/LocalizingMoments"
"WuJie1010/TSP-PRL" -> "WuJie1010/Temporally-language-grounding"
"WuJie1010/TSP-PRL" -> "WuJie1010/Awesome-Temporally-Language-Grounding"
"WuJie1010/Temporally-language-grounding" -> "WuJie1010/Awesome-Temporally-Language-Grounding"
"WuJie1010/Temporally-language-grounding" -> "WuJie1010/TSP-PRL"
"WuJie1010/Temporally-language-grounding" -> "JaywongWang/CBP"
"WuJie1010/Temporally-language-grounding" -> "niluthpol/weak_supervised_video_moment"
"WuJie1010/Temporally-language-grounding" -> "JonghwanMun/LGI4temporalgrounding"
"WuJie1010/Temporally-language-grounding" -> "iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos"
"lelan-li/SSAH" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"lelan-li/SSAH" -> "zyfsa/cvpr2018-SSAH"
"lelan-li/SSAH" -> "WendellGul/DCMH"
"lelan-li/SSAH" -> "jiangqy/DCMH-CVPR2017"
"lelan-li/SSAH" -> "zhongzhh8/Cross-Modal-Retrieval"
"lelan-li/SSAH" -> "PKU-ICST-MIPL/UGACH_AAAI2018"
"lelan-li/SSAH" -> "yalesong/pvse"
"lelan-li/SSAH" -> "penghu-cs/DSCMR"
"lelan-li/SSAH" -> "sunpeng981712364/ACMR_demo"
"lelan-li/SSAH" -> "lelan-li/DSEH"
"lelan-li/SSAH" -> "niluthpol/multimodal_vtt"
"lelan-li/SSAH" -> "WendellGul/AGAH"
"lelan-li/SSAH" -> "zzs1994/DJSRH"
"lelan-li/SSAH" -> "WangGodder/deep-cross-modal-hashing"
"lelan-li/SSAH" -> "PKU-ICST-MIPL/SCHGAN_TCYB2018"
"ammesatyajit/VideoBERT" -> "MDSKUL/MasterProject"
"CrossmodalGroup/GSMN" -> "CrossmodalGroup/BFAN"
"CrossmodalGroup/GSMN" -> "KunpengLi1994/VSRN"
"CrossmodalGroup/GSMN" -> "ZihaoWang-CV/CAMP_iccv19"
"CrossmodalGroup/GSMN" -> "Paranioar/SGRAF"
"CrossmodalGroup/GSMN" -> "BruceW91/CVSE"
"CrossmodalGroup/GSMN" -> "sunnychencool/AOQ"
"CrossmodalGroup/GSMN" -> "HuiChen24/IMRAM"
"CrossmodalGroup/GSMN" -> "kuanghuei/SCAN"
"CrossmodalGroup/GSMN" -> "Paranioar/Cross-modal_Retrieval_Tutorial"
"CrossmodalGroup/GSMN" -> "kywen1119/DSRAN"
"CrossmodalGroup/GSMN" -> "woodfrog/vse_infty"
"CrossmodalGroup/GSMN" -> "cshizhe/hgr_v2t"
"CrossmodalGroup/GSMN" -> "fartashf/vsepp"
"CrossmodalGroup/GSMN" -> "HaoYang0123/Position-Focused-Attention-Network"
"CrossmodalGroup/GSMN" -> "Wangt-CN/MTFN-RR-PyTorch-Code"
"KunpengLi1994/VSRN" -> "kuanghuei/SCAN"
"KunpengLi1994/VSRN" -> "CrossmodalGroup/GSMN"
"KunpengLi1994/VSRN" -> "fartashf/vsepp"
"KunpengLi1994/VSRN" -> "BruceW91/CVSE"
"KunpengLi1994/VSRN" -> "ZihaoWang-CV/CAMP_iccv19"
"KunpengLi1994/VSRN" -> "Paranioar/SGRAF"
"KunpengLi1994/VSRN" -> "woodfrog/vse_infty"
"KunpengLi1994/VSRN" -> "HuiChen24/IMRAM"
"KunpengLi1994/VSRN" -> "yalesong/pvse"
"KunpengLi1994/VSRN" -> "kywen1119/DSRAN"
"KunpengLi1994/VSRN" -> "sunnychencool/AOQ"
"KunpengLi1994/VSRN" -> "HaoYang0123/Position-Focused-Attention-Network"
"KunpengLi1994/VSRN" -> "cshizhe/hgr_v2t"
"KunpengLi1994/VSRN" -> "CrossmodalGroup/BFAN"
"KunpengLi1994/VSRN" -> "linjieli222/VQA_ReGAT" ["e"=1]
"CrossmodalGroup/NAAF" -> "CrossmodalGroup/CMCAN"
"CrossmodalGroup/NAAF" -> "fortunechen/paper-reading_CrossModelGroup-USTC"
"CrossmodalGroup/NAAF" -> "woodfrog/vse_infty"
"CrossmodalGroup/NAAF" -> "WangFei-2019/Image-text-Retrieval"
"CrossmodalGroup/NAAF" -> "CrossmodalGroup/BFAN"
"kuanghuei/SCAN" -> "fartashf/vsepp"
"kuanghuei/SCAN" -> "KunpengLi1994/VSRN"
"kuanghuei/SCAN" -> "CrossmodalGroup/GSMN"
"kuanghuei/SCAN" -> "Paranioar/Cross-modal_Retrieval_Tutorial"
"kuanghuei/SCAN" -> "Paranioar/SGRAF"
"kuanghuei/SCAN" -> "peteanderson80/bottom-up-attention" ["e"=1]
"kuanghuei/SCAN" -> "ZihaoWang-CV/CAMP_iccv19"
"kuanghuei/SCAN" -> "HuiChen24/IMRAM"
"kuanghuei/SCAN" -> "woodfrog/vse_infty"
"kuanghuei/SCAN" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"kuanghuei/SCAN" -> "jiasenlu/vilbert_beta" ["e"=1]
"kuanghuei/SCAN" -> "lelan-li/SSAH"
"kuanghuei/SCAN" -> "yalesong/pvse"
"kuanghuei/SCAN" -> "kywen1119/DSRAN"
"kuanghuei/SCAN" -> "BruceW91/CVSE"
"UT-Austin-RPL/Ditto" -> "Steve-Tod/utils3d"
"UT-Austin-RPL/Ditto" -> "UT-Austin-RPL/FORGE"
"UT-Austin-RPL/Ditto" -> "daerduoCarey/where2act"
"danieljf24/w2vv" -> "danieljf24/text2image"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "Paranioar/SGRAF"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "woodfrog/vse_infty"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "kuanghuei/SCAN"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "CrossmodalGroup/GSMN"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "LgQu/DIME"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "danieljf24/awesome-video-text-retrieval"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "BruceW91/CVSE"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "zhongzhh8/Cross-Modal-Retrieval"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "HuiChen24/IMRAM"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "ZihaoWang-CV/CAMP_iccv19"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "albanie/collaborative-experts"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "WangGodder/deep-cross-modal-hashing"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "KunpengLi1994/VSRN"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "kywen1119/DSRAN"
"Paranioar/Cross-modal_Retrieval_Tutorial" -> "fartashf/vsepp"
"danieljf24/hybrid_space" -> "xuchaoxi/video-cnn-feat"
"danieljf24/hybrid_space" -> "danieljf24/dual_encoding"
"danieljf24/hybrid_space" -> "albanie/collaborative-experts"
"danieljf24/hybrid_space" -> "danieljf24/awesome-video-text-retrieval"
"danieljf24/hybrid_space" -> "mwray/Semantic-Video-Retrieval"
"microsoft/2D-TAN" -> "ChenJoya/2dtan"
"microsoft/2D-TAN" -> "jiyanggao/TALL"
"microsoft/2D-TAN" -> "ikuinen/CMIN_moment_retrieval"
"microsoft/2D-TAN" -> "JonghwanMun/LGI4temporalgrounding"
"microsoft/2D-TAN" -> "JaywongWang/CBP"
"microsoft/2D-TAN" -> "niluthpol/weak_supervised_video_moment"
"microsoft/2D-TAN" -> "yytzsy/SCDM"
"microsoft/2D-TAN" -> "IsaacChanghau/VSLNet"
"microsoft/2D-TAN" -> "WuJie1010/Temporally-language-grounding"
"microsoft/2D-TAN" -> "MCG-NJU/MMN"
"microsoft/2D-TAN" -> "WuJie1010/Awesome-Temporally-Language-Grounding"
"microsoft/2D-TAN" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"microsoft/2D-TAN" -> "JJBOY/BMN-Boundary-Matching-Network" ["e"=1]
"microsoft/2D-TAN" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"microsoft/2D-TAN" -> "jayleicn/moment_detr"
"HuiChen24/IMRAM" -> "ZihaoWang-CV/CAMP_iccv19"
"HuiChen24/IMRAM" -> "sunnychencool/AOQ"
"HuiChen24/IMRAM" -> "kywen1119/DSRAN"
"HuiChen24/IMRAM" -> "LgQu/DIME"
"HuiChen24/IMRAM" -> "woodfrog/vse_infty"
"HuiChen24/IMRAM" -> "CrossmodalGroup/GSMN"
"HuiChen24/IMRAM" -> "Wangt-CN/MTFN-RR-PyTorch-Code"
"HuiChen24/IMRAM" -> "hardyqr/Visual-Semantic-Embeddings-an-incomplete-list"
"HuiChen24/IMRAM" -> "BruceW91/CVSE"
"HuiChen24/IMRAM" -> "hardyqr/HAL"
"HuiChen24/IMRAM" -> "LgQu/CAMERA"
"Paranioar/SGRAF" -> "Paranioar/Cross-modal_Retrieval_Tutorial"
"Paranioar/SGRAF" -> "woodfrog/vse_infty"
"Paranioar/SGRAF" -> "LgQu/DIME"
"Paranioar/SGRAF" -> "CrossmodalGroup/GSMN"
"Paranioar/SGRAF" -> "BruceW91/CVSE"
"Paranioar/SGRAF" -> "KunpengLi1994/VSRN"
"Paranioar/SGRAF" -> "kuanghuei/SCAN"
"Paranioar/SGRAF" -> "kywen1119/DSRAN"
"Paranioar/SGRAF" -> "HuiChen24/IMRAM"
"Paranioar/SGRAF" -> "CrossmodalGroup/NAAF"
"Paranioar/SGRAF" -> "CrossmodalGroup/CMCAN"
"Paranioar/SGRAF" -> "mesnico/TERN"
"Paranioar/SGRAF" -> "hardyqr/HAL"
"Paranioar/SGRAF" -> "LgQu/CAMERA"
"Paranioar/SGRAF" -> "Wangt-CN/MTFN-RR-PyTorch-Code"
"zhongzhh8/Cross-Modal-Retrieval" -> "WangGodder/deep-cross-modal-hashing"
"zhongzhh8/Cross-Modal-Retrieval" -> "penghu-cs/DSCMR"
"zhongzhh8/Cross-Modal-Retrieval" -> "lelan-li/SSAH"
"zhongzhh8/Cross-Modal-Retrieval" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"zhongzhh8/Cross-Modal-Retrieval" -> "penghu-cs/SDML"
"zhongzhh8/Cross-Modal-Retrieval" -> "HuiChen24/IMRAM"
"zhongzhh8/Cross-Modal-Retrieval" -> "yolo2233/cross-modal-hasing-playground"
"SydCaption/SAAT" -> "tgc1997/RMN"
"SydCaption/SAAT" -> "vsislab/Controllable_XGating"
"SydCaption/SAAT" -> "tgc1997/Awesome-Video-Captioning"
"SydCaption/SAAT" -> "hobincar/SGN"
"SydCaption/SAAT" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"SydCaption/SAAT" -> "WingsBrokenAngel/Semantics-AssistedVideoCaptioning"
"SydCaption/SAAT" -> "yangbang18/Non-Autoregressive-Video-Captioning"
"SydCaption/SAAT" -> "jayleicn/recurrent-transformer"
"IsaacChanghau/DL-NLP-Readings" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"IsaacChanghau/DL-NLP-Readings" -> "IsaacChanghau/VSLNet"
"IsaacChanghau/DL-NLP-Readings" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"IsaacChanghau/DL-NLP-Readings" -> "microsoft/2D-TAN"
"IsaacChanghau/DL-NLP-Readings" -> "iwangjian/Paper-Reading" ["e"=1]
"IsaacChanghau/DL-NLP-Readings" -> "JonghwanMun/LGI4temporalgrounding"
"IsaacChanghau/DL-NLP-Readings" -> "MCG-NJU/MMN"
"IsaacChanghau/DL-NLP-Readings" -> "jiyanggao/TALL"
"IsaacChanghau/DL-NLP-Readings" -> "danieljf24/awesome-video-text-retrieval"
"IsaacChanghau/DL-NLP-Readings" -> "jayleicn/TVRetrieval"
"IsaacChanghau/DL-NLP-Readings" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization" ["e"=1]
"IsaacChanghau/DL-NLP-Readings" -> "Alvin-Zeng/DRN"
"IsaacChanghau/DL-NLP-Readings" -> "ikuinen/CMIN_moment_retrieval"
"IsaacChanghau/DL-NLP-Readings" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" ["e"=1]
"IsaacChanghau/DL-NLP-Readings" -> "IsaacChanghau/ReLoCLNet"
"ArrowLuo/CLIP4Clip" -> "CryhanFang/CLIP2Video"
"ArrowLuo/CLIP4Clip" -> "jayleicn/ClipBERT" ["e"=1]
"ArrowLuo/CLIP4Clip" -> "m-bain/frozen-in-time"
"ArrowLuo/CLIP4Clip" -> "danieljf24/awesome-video-text-retrieval"
"ArrowLuo/CLIP4Clip" -> "starmemda/CAMoE"
"ArrowLuo/CLIP4Clip" -> "microsoft/UniVL"
"ArrowLuo/CLIP4Clip" -> "sallymmx/ActionCLIP" ["e"=1]
"ArrowLuo/CLIP4Clip" -> "albanie/collaborative-experts"
"ArrowLuo/CLIP4Clip" -> "gabeur/mmt"
"ArrowLuo/CLIP4Clip" -> "salesforce/ALBEF" ["e"=1]
"ArrowLuo/CLIP4Clip" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"ArrowLuo/CLIP4Clip" -> "jayleicn/moment_detr"
"ArrowLuo/CLIP4Clip" -> "foolwood/DRL"
"ArrowLuo/CLIP4Clip" -> "mzhaoshuai/CenterCLIP"
"ArrowLuo/CLIP4Clip" -> "KaiyangZhou/CoOp" ["e"=1]
"chenjoya/2dtan" -> "sangminwoo/Explore-And-Match"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "IsaacChanghau/VSLNet"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "r-cui/ViGA"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "microsoft/2D-TAN"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "IsaacChanghau/ReLoCLNet"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "danieljf24/awesome-video-text-retrieval"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "TencentARC/UMT"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "Xun-Yang/Causal_Video_Moment_Retrieval"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "ikuinen/CMIN_moment_retrieval"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "niluthpol/weak_supervised_video_moment"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "jiyanggao/TALL"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "jayleicn/moment_detr"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "JonghwanMun/LGI4temporalgrounding"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "Soldelli/Awesome-Temporal-Language-Grounding-in-Videos"
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" -> "mwray/Semantic-Video-Retrieval"
"CaptainEven/VideoCaption" -> "xiadingZ/video-caption.pytorch"
"CaptainEven/VideoCaption" -> "vijayvee/video-captioning"
"CaptainEven/VideoCaption" -> "Sundrops/video-caption.pytorch"
"CaptainEven/VideoCaption" -> "JaywongWang/DenseVideoCaptioning"
"CaptainEven/VideoCaption" -> "scopeInfinity/Video2Description"
"CaptainEven/VideoCaption" -> "facebookresearch/grounded-video-description"
"VALUE-Leaderboard/StarterCode" -> "VALUE-Leaderboard/DataRelease"
"VALUE-Leaderboard/StarterCode" -> "linjieli222/HERO"
"VALUE-Leaderboard/StarterCode" -> "VALUE-Leaderboard/EvaluationTools"
"VALUE-Leaderboard/StarterCode" -> "tsujuifu/pytorch_violet"
"VisionLearningGroup/caption-guided-saliency" -> "mynlp/cst_captioning"
"jssprz/visual_syntactic_embedding_video_captioning" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"jssprz/visual_syntactic_embedding_video_captioning" -> "hobincar/SGN"
"linjieli222/HERO" -> "VALUE-Leaderboard/StarterCode"
"linjieli222/HERO" -> "ych133/How2R-and-How2QA"
"linjieli222/HERO" -> "microsoft/UniVL"
"linjieli222/HERO" -> "jimmy646/violin"
"linjieli222/HERO" -> "jayleicn/TVCaption"
"linjieli222/HERO" -> "jayleicn/TVRetrieval"
"linjieli222/HERO" -> "linjieli222/HERO_Video_Feature_Extractor"
"linjieli222/HERO" -> "tsujuifu/pytorch_violet"
"linjieli222/HERO" -> "jayleicn/recurrent-transformer"
"linjieli222/HERO" -> "jayleicn/ClipBERT" ["e"=1]
"linjieli222/HERO" -> "jayleicn/TVQAplus"
"linjieli222/HERO" -> "gabeur/mmt"
"linjieli222/HERO" -> "salesforce/ALPRO"
"linjieli222/HERO" -> "gingsi/coot-videotext"
"linjieli222/HERO" -> "antoine77340/MIL-NCE_HowTo100M"
"microsoft/SwinBERT" -> "ttengwang/PDVC"
"microsoft/SwinBERT" -> "microsoft/UniVL"
"microsoft/SwinBERT" -> "MarcusNerva/HMN"
"microsoft/SwinBERT" -> "nasib-ullah/video-captioning-models-in-Pytorch"
"microsoft/SwinBERT" -> "linjieli222/HERO_Video_Feature_Extractor"
"microsoft/SwinBERT" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"ttengwang/PDVC" -> "microsoft/SwinBERT"
"ttengwang/PDVC" -> "syuqings/video-paragraph"
"ttengwang/PDVC" -> "v-iashin/MDVC"
"ttengwang/PDVC" -> "hobincar/SGN"
"ttengwang/PDVC" -> "ttengwang/dense-video-captioning-pytorch"
"zs-zhong/DJSRH" -> "KaiserLew/JDSH"
"Soldelli/MAD" -> "Soldelli/Awesome-Temporal-Language-Grounding-in-Videos"
"Soldelli/MAD" -> "TengdaHan/AutoAD"
"Soldelli/MAD" -> "Soldelli/VLG-Net"
"dhg-wei/DeCap" -> "NNNNAI/Ego4d_NLQ_2022_1st_Place_Solution"
"ikuinen/CMIN_moment_retrieval" -> "yytzsy/SCDM"
"ikuinen/CMIN_moment_retrieval" -> "liudaizong/CSMGAN"
"ikuinen/CMIN_moment_retrieval" -> "iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos"
"ikuinen/CMIN_moment_retrieval" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"ikuinen/CMIN_moment_retrieval" -> "JaywongWang/CBP"
"ikuinen/CMIN_moment_retrieval" -> "JonghwanMun/LGI4temporalgrounding"
"ikuinen/CMIN_moment_retrieval" -> "microsoft/2D-TAN"
"ikuinen/CMIN_moment_retrieval" -> "BonnieHuangxin/SLTA"
"ikuinen/CMIN_moment_retrieval" -> "tanghaoyu258/ACRM-for-moment-retrieval"
"mzhaoshuai/CenterCLIP" -> "NNNNAI/Ego4d_NLQ_2022_1st_Place_Solution"
"mzhaoshuai/CenterCLIP" -> "foolwood/DRL"
"mzhaoshuai/CenterCLIP" -> "pansanity666/INO_VOS"
"mzhaoshuai/CenterCLIP" -> "sxl142/GLoT"
"mzhaoshuai/CenterCLIP" -> "ioanacroi/qb-norm"
"mzhaoshuai/CenterCLIP" -> "dhg-wei/DeCap"
"CrossmodalGroup/SSL-VQA" -> "CrossmodalGroup/BFAN"
"fartashf/vsepp" -> "kuanghuei/SCAN"
"fartashf/vsepp" -> "KunpengLi1994/VSRN"
"fartashf/vsepp" -> "ryankiros/visual-semantic-embedding"
"fartashf/vsepp" -> "yalesong/pvse"
"fartashf/vsepp" -> "CrossmodalGroup/GSMN"
"fartashf/vsepp" -> "peteanderson80/bottom-up-attention" ["e"=1]
"fartashf/vsepp" -> "ZihaoWang-CV/CAMP_iccv19"
"fartashf/vsepp" -> "HuiChen24/IMRAM"
"fartashf/vsepp" -> "woodfrog/vse_infty"
"fartashf/vsepp" -> "cshizhe/hgr_v2t"
"fartashf/vsepp" -> "sunpeng981712364/ACMR_demo"
"fartashf/vsepp" -> "danieljf24/dual_encoding"
"fartashf/vsepp" -> "Paranioar/Cross-modal_Retrieval_Tutorial"
"fartashf/vsepp" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"fartashf/vsepp" -> "niluthpol/multimodal_vtt"
"danieljf24/awesome-video-text-retrieval" -> "albanie/collaborative-experts"
"danieljf24/awesome-video-text-retrieval" -> "gabeur/mmt"
"danieljf24/awesome-video-text-retrieval" -> "CryhanFang/CLIP2Video"
"danieljf24/awesome-video-text-retrieval" -> "cshizhe/hgr_v2t"
"danieljf24/awesome-video-text-retrieval" -> "danieljf24/hybrid_space"
"danieljf24/awesome-video-text-retrieval" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"danieljf24/awesome-video-text-retrieval" -> "ArrowLuo/CLIP4Clip"
"danieljf24/awesome-video-text-retrieval" -> "m-bain/frozen-in-time"
"danieljf24/awesome-video-text-retrieval" -> "jayleicn/ClipBERT" ["e"=1]
"danieljf24/awesome-video-text-retrieval" -> "danieljf24/dual_encoding"
"danieljf24/awesome-video-text-retrieval" -> "Paranioar/Cross-modal_Retrieval_Tutorial"
"danieljf24/awesome-video-text-retrieval" -> "gingsi/coot-videotext"
"danieljf24/awesome-video-text-retrieval" -> "starmemda/CAMoE"
"danieljf24/awesome-video-text-retrieval" -> "niluthpol/multimodal_vtt"
"danieljf24/awesome-video-text-retrieval" -> "microsoft/2D-TAN"
"anosorae/IRRA" -> "OrangeYHChen/TIPCB"
"anosorae/IRRA" -> "zifyloo/SSAN"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "lelan-li/SSAH"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "sunpeng981712364/ACMR_demo"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "penghu-cs/DSCMR"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "zhongzhh8/Cross-Modal-Retrieval"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "jiangqy/DCMH-CVPR2017"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "YingZhangDUT/Cross-Modal-Projection-Learning"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "caoyue10/aaai17-cdq" ["e"=1]
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "zyfsa/cvpr2018-SSAH"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "yalesong/pvse"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "HuiChen24/IMRAM"
"gujiuxiang/Multimodal_Retrieval.pytorch" -> "PKU-ICST-MIPL/UGACH_AAAI2018"
"jiangqy/DCMH-CVPR2017" -> "WendellGul/DCMH"
"jiangqy/DCMH-CVPR2017" -> "lelan-li/SSAH"
"jiangqy/DCMH-CVPR2017" -> "PKU-ICST-MIPL/SCHGAN_TCYB2018"
"jiangqy/DCMH-CVPR2017" -> "zyfsa/cvpr2018-SSAH"
"jiangqy/DCMH-CVPR2017" -> "yolo2233/cross-modal-hasing-playground"
"jiangqy/DCMH-CVPR2017" -> "zzs1994/DJSRH"
"jiangqy/DCMH-CVPR2017" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"jiangqy/DCMH-CVPR2017" -> "jiangqy/DPSH-pytorch" ["e"=1]
"jiangqy/DCMH-CVPR2017" -> "WangGodder/deep-cross-modal-hashing"
"jiangqy/DCMH-CVPR2017" -> "caoyue10/aaai17-cdq" ["e"=1]
"zyfsa/cvpr2018-SSAH" -> "lelan-li/SSAH"
"Xuanmeng-Zhang/MVCGAN" -> "pansanity666/INO_VOS"
"Xuanmeng-Zhang/MVCGAN" -> "NNNNAI/Ego4d_NLQ_2022_1st_Place_Solution"
"WangGodder/deep-cross-modal-hashing" -> "WendellGul/DCMH"
"WangGodder/deep-cross-modal-hashing" -> "zhongzhh8/Cross-Modal-Retrieval"
"WangGodder/deep-cross-modal-hashing" -> "yolo2233/cross-modal-hasing-playground"
"WangGodder/deep-cross-modal-hashing" -> "WendellGul/AGAH"
"kuangliu/pytorch-groupnorm" -> "taokong/group_normalization"
"tuyunbin/Video-Description-with-Spatial-Temporal-Attention" -> "zhegan27/SCN_for_video_captioning"
"microsoft/UniVL" -> "linjieli222/HERO"
"microsoft/UniVL" -> "microsoft/SwinBERT"
"microsoft/UniVL" -> "gingsi/coot-videotext"
"microsoft/UniVL" -> "antoine77340/MIL-NCE_HowTo100M"
"microsoft/UniVL" -> "jayleicn/ClipBERT" ["e"=1]
"microsoft/UniVL" -> "ArrowLuo/CLIP4Clip"
"microsoft/UniVL" -> "tsujuifu/pytorch_violet"
"microsoft/UniVL" -> "m-bain/frozen-in-time"
"microsoft/UniVL" -> "ammesatyajit/VideoBERT"
"microsoft/UniVL" -> "TencentARC/MCQ"
"microsoft/UniVL" -> "VALUE-Leaderboard/StarterCode"
"microsoft/UniVL" -> "salesforce/ALPRO"
"microsoft/UniVL" -> "antoine77340/howto100m"
"microsoft/UniVL" -> "v-iashin/video_features"
"microsoft/UniVL" -> "showlab/all-in-one"
"xyzforever/BEVT" -> "ruiwang2021/mvd"
"xyzforever/BEVT" -> "TencentARC/MCQ"
"v-iashin/MDVC" -> "v-iashin/BMT"
"v-iashin/MDVC" -> "jayleicn/recurrent-transformer"
"v-iashin/MDVC" -> "ttengwang/dense-video-captioning-pytorch"
"v-iashin/MDVC" -> "jayleicn/TVCaption"
"v-iashin/MDVC" -> "salesforce/densecap"
"v-iashin/MDVC" -> "tgc1997/RMN"
"alexandrosstergiou/SoftPool" -> "sebgao/LIP"
"alexandrosstergiou/SoftPool" -> "alexandrosstergiou/adaPool"
"alexandrosstergiou/SoftPool" -> "rentainhe/pytorch-pooling"
"alexandrosstergiou/SoftPool" -> "wofmanaf/SA-Net" ["e"=1]
"microsoft/XPretrain" -> "m-bain/webvid"
"microsoft/XPretrain" -> "jayleicn/singularity"
"microsoft/XPretrain" -> "albanie/collaborative-experts"
"microsoft/XPretrain" -> "TengdaHan/TemporalAlignNet"
"microsoft/XPretrain" -> "jayleicn/ClipBERT" ["e"=1]
"microsoft/XPretrain" -> "salesforce/ALPRO"
"microsoft/XPretrain" -> "CryhanFang/CLIP2Video"
"microsoft/XPretrain" -> "m-bain/frozen-in-time"
"microsoft/XPretrain" -> "microsoft/VideoX" ["e"=1]
"microsoft/XPretrain" -> "ArrowLuo/CLIP4Clip"
"microsoft/XPretrain" -> "TencentARC/MCQ"
"microsoft/XPretrain" -> "zengyan-97/X-VLM" ["e"=1]
"WendellGul/AGAH" -> "starxliu/MTFH"
"penghu-cs/DSCMR" -> "penghu-cs/SDML"
"penghu-cs/DSCMR" -> "zhongzhh8/Cross-Modal-Retrieval"
"penghu-cs/DSCMR" -> "ZihaoWang-CV/CAMP_iccv19"
"penghu-cs/DSCMR" -> "penghu-cs/MAN"
"penghu-cs/DSCMR" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"penghu-cs/DSCMR" -> "lelan-li/SSAH"
"penghu-cs/DSCMR" -> "yalesong/pvse"
"penghu-cs/DSCMR" -> "HuiChen24/IMRAM"
"penghu-cs/DSCMR" -> "zzs1994/DJSRH"
"penghu-cs/DSCMR" -> "jiangqy/DCMH-CVPR2017"
"penghu-cs/DSCMR" -> "sunpeng981712364/ACMR_demo"
"penghu-cs/DSCMR" -> "WendellGul/DCMH"
"penghu-cs/DSCMR" -> "penghu-cs/MRL"
"penghu-cs/DSCMR" -> "cshizhe/hgr_v2t"
"ryankiros/visual-semantic-embedding" -> "fartashf/vsepp"
"ryankiros/visual-semantic-embedding" -> "ivendrov/order-embedding"
"ryankiros/visual-semantic-embedding" -> "linxd5/VSE_Pytorch"
"ryankiros/visual-semantic-embedding" -> "kelvinxu/arctic-captions" ["e"=1]
"ryankiros/visual-semantic-embedding" -> "emansim/text2image" ["e"=1]
"ryankiros/visual-semantic-embedding" -> "s-gupta/visual-concepts" ["e"=1]
"ryankiros/visual-semantic-embedding" -> "ryankiros/skip-thoughts" ["e"=1]
"ryankiros/visual-semantic-embedding" -> "kuanghuei/SCAN"
"ryankiros/visual-semantic-embedding" -> "cesc-park/CRCN"
"ryankiros/visual-semantic-embedding" -> "KunpengLi1994/VSRN"
"ryankiros/visual-semantic-embedding" -> "LuoweiZhou/e2e-gLSTM-sc" ["e"=1]
"ryankiros/visual-semantic-embedding" -> "awentzonline/keras-visual-semantic-embedding"
"ryankiros/visual-semantic-embedding" -> "facebook/eyescream" ["e"=1]
"ryankiros/visual-semantic-embedding" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"ryankiros/visual-semantic-embedding" -> "sunpeng981712364/ACMR_demo"
"JonghwanMun/LGI4temporalgrounding" -> "Alvin-Zeng/DRN"
"JonghwanMun/LGI4temporalgrounding" -> "IsaacChanghau/VSLNet"
"JonghwanMun/LGI4temporalgrounding" -> "jiyanggao/TALL"
"JonghwanMun/LGI4temporalgrounding" -> "ikuinen/CMIN_moment_retrieval"
"JonghwanMun/LGI4temporalgrounding" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"JonghwanMun/LGI4temporalgrounding" -> "microsoft/2D-TAN"
"JonghwanMun/LGI4temporalgrounding" -> "liudaizong/CSMGAN"
"JonghwanMun/LGI4temporalgrounding" -> "niluthpol/weak_supervised_video_moment"
"JonghwanMun/LGI4temporalgrounding" -> "JaywongWang/CBP"
"JonghwanMun/LGI4temporalgrounding" -> "iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos"
"JonghwanMun/LGI4temporalgrounding" -> "WuJie1010/Temporally-language-grounding"
"JonghwanMun/LGI4temporalgrounding" -> "yytzsy/ABLR_code"
"JonghwanMun/LGI4temporalgrounding" -> "ChenJoya/2dtan"
"JonghwanMun/LGI4temporalgrounding" -> "MCG-NJU/MMN"
"JonghwanMun/LGI4temporalgrounding" -> "cshizhe/hgr_v2t"
"MCG-NJU/MMN" -> "Huntersxsx/RaNet"
"MCG-NJU/MMN" -> "haojc/ShufflingVideosForTSG"
"MCG-NJU/MMN" -> "yytzsy/grounding_changing_distribution"
"MCG-NJU/MMN" -> "IsaacChanghau/ReLoCLNet"
"TencentARC/MCQ" -> "m-bain/frozen-in-time"
"TencentARC/MCQ" -> "salesforce/ALPRO"
"TencentARC/MCQ" -> "jayleicn/singularity"
"TencentARC/MCQ" -> "albanie/collaborative-experts"
"TencentARC/MCQ" -> "layer6ai-labs/xpool"
"TencentARC/MCQ" -> "ruiyan1995/Region_Learner"
"TencentARC/MCQ" -> "showlab/all-in-one"
"TencentARC/MCQ" -> "FingerRec/OA-Transformer"
"r-cui/ViGA" -> "sangminwoo/Explore-And-Match"
"rowanz/merlot" -> "tsujuifu/pytorch_violet"
"rowanz/merlot" -> "rowanz/merlot_reserve"
"rowanz/merlot" -> "antoyang/just-ask"
"rowanz/merlot" -> "TencentARC/MCQ"
"rowanz/merlot" -> "jayleicn/ClipBERT" ["e"=1]
"rowanz/merlot" -> "showlab/all-in-one"
"rowanz/merlot" -> "VALUE-Leaderboard/StarterCode"
"rowanz/merlot" -> "salesforce/ALPRO"
"rowanz/merlot" -> "jayleicn/singularity"
"rowanz/merlot" -> "linjieli222/HERO"
"rowanz/merlot" -> "m-bain/frozen-in-time"
"rowanz/merlot" -> "antoine77340/MIL-NCE_HowTo100M"
"rowanz/merlot" -> "MikeWangWZHL/VidIL" ["e"=1]
"tsujuifu/pytorch_violet" -> "salesforce/ALPRO"
"tsujuifu/pytorch_violet" -> "rowanz/merlot"
"tsujuifu/pytorch_violet" -> "antoyang/just-ask"
"tsujuifu/pytorch_violet" -> "VALUE-Leaderboard/StarterCode"
"tsujuifu/pytorch_violet" -> "microsoft/LAVENDER"
"tsujuifu/pytorch_violet" -> "showlab/all-in-one"
"tsujuifu/pytorch_violet" -> "microsoft/UniVL"
"tsujuifu/pytorch_violet" -> "linjieli222/HERO"
"tsujuifu/pytorch_violet" -> "m-bain/frozen-in-time"
"tsujuifu/pytorch_violet" -> "jayleicn/moment_detr"
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "JaywongWang/CBP"
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "liudaizong/CSMGAN"
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "JaywongWang/I3D-Feature-Extractor"
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "JaywongWang/SST-Tensorflow" ["e"=1]
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "IsaacChanghau/VSLNet"
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "DavideA/c3d-pytorch" ["e"=1]
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "JonghwanMun/LGI4temporalgrounding"
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"yyuanad/Pytorch_C3D_Feature_Extractor" -> "yytzsy/SCDM"
"hardyqr/Visual-Semantic-Embeddings-an-incomplete-list" -> "sunnychencool/AOQ"
"antoine77340/video_feature_extractor" -> "antoine77340/howto100m"
"antoine77340/video_feature_extractor" -> "antoine77340/S3D_HowTo100M"
"antoine77340/video_feature_extractor" -> "antoine77340/MIL-NCE_HowTo100M"
"antoine77340/video_feature_extractor" -> "v-iashin/video_features"
"antoine77340/video_feature_extractor" -> "jayleicn/recurrent-transformer"
"antoine77340/video_feature_extractor" -> "albanie/collaborative-experts"
"antoine77340/video_feature_extractor" -> "cshizhe/hgr_v2t"
"antoine77340/video_feature_extractor" -> "gingsi/coot-videotext"
"antoine77340/video_feature_extractor" -> "facebookresearch/grounded-video-description"
"antoine77340/video_feature_extractor" -> "v-iashin/BMT"
"antoine77340/video_feature_extractor" -> "gabeur/mmt"
"antoine77340/video_feature_extractor" -> "hobincar/pytorch-video-feature-extractor"
"antoine77340/video_feature_extractor" -> "danieljf24/dual_encoding"
"antoine77340/video_feature_extractor" -> "jayleicn/ClipBERT" ["e"=1]
"antoine77340/video_feature_extractor" -> "danieljf24/awesome-video-text-retrieval"
"sebgao/LIP" -> "alexandrosstergiou/SoftPool"
"sebgao/LIP" -> "visinf/dpp"
"sebgao/LIP" -> "MCG-NJU/MMN"
"sebgao/LIP" -> "MCG-NJU/BCN" ["e"=1]
"sebgao/LIP" -> "MCG-NJU/CPD-Video" ["e"=1]
"sebgao/LIP" -> "MCG-NJU/AdaMixer" ["e"=1]
"YunseokJANG/tgif-qa" -> "fanchenyou/HME-VideoQA"
"YunseokJANG/tgif-qa" -> "thaolmk54/hcrn-videoqa"
"YunseokJANG/tgif-qa" -> "MILVLG/activitynet-qa"
"YunseokJANG/tgif-qa" -> "jayleicn/TVQAplus"
"YunseokJANG/tgif-qa" -> "raingo/TGIF-Release"
"YunseokJANG/tgif-qa" -> "xudejing/video-question-answering"
"YunseokJANG/tgif-qa" -> "jayleicn/TVQA"
"YunseokJANG/tgif-qa" -> "xudejing/VideoQA"
"YunseokJANG/tgif-qa" -> "SunDoge/L-GCN"
"YunseokJANG/tgif-qa" -> "makarandtapaswi/MovieQA_CVPR2016"
"YunseokJANG/tgif-qa" -> "noagarcia/knowit-rock"
"IsaacChanghau/VSLNet" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"IsaacChanghau/VSLNet" -> "JonghwanMun/LGI4temporalgrounding"
"IsaacChanghau/VSLNet" -> "liudaizong/CSMGAN"
"IsaacChanghau/VSLNet" -> "Alvin-Zeng/DRN"
"IsaacChanghau/VSLNet" -> "jayleicn/TVRetrieval"
"IsaacChanghau/VSLNet" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"IsaacChanghau/VSLNet" -> "jiyanggao/TALL"
"IsaacChanghau/VSLNet" -> "ikuinen/CMIN_moment_retrieval"
"IsaacChanghau/VSLNet" -> "microsoft/2D-TAN"
"IsaacChanghau/VSLNet" -> "JaywongWang/CBP"
"ioanacroi/qb-norm" -> "foolwood/DRL"
"facebookresearch/Ego4d" -> "showlab/EgoVLP"
"facebookresearch/Ego4d" -> "EGO4D/hands-and-objects"
"facebookresearch/Ego4d" -> "EGO4D/forecasting" ["e"=1]
"facebookresearch/Ego4d" -> "EGO4D/episodic-memory"
"salesforce/densecap" -> "jayleicn/recurrent-transformer"
"salesforce/densecap" -> "facebookresearch/grounded-video-description"
"salesforce/densecap" -> "ttengwang/dense-video-captioning-pytorch"
"salesforce/densecap" -> "JaywongWang/DenseVideoCaptioning"
"salesforce/densecap" -> "v-iashin/BMT"
"salesforce/densecap" -> "LuoweiZhou/anet2016-cuhk-feature"
"salesforce/densecap" -> "ranjaykrishna/densevid_eval"
"salesforce/densecap" -> "v-iashin/MDVC"
"salesforce/densecap" -> "vsislab/Controllable_XGating"
"salesforce/densecap" -> "XgDuan/WSDEC"
"salesforce/densecap" -> "gingsi/coot-videotext"
"salesforce/densecap" -> "xiadingZ/video-caption.pytorch"
"salesforce/densecap" -> "syuqings/video-paragraph"
"salesforce/densecap" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"salesforce/densecap" -> "antoine77340/howto100m"
"starmemda/CAMoE" -> "ioanacroi/qb-norm"
"starmemda/CAMoE" -> "CryhanFang/CLIP2Video"
"starmemda/CAMoE" -> "ArrowLuo/CLIP4Clip"
"starmemda/CAMoE" -> "foolwood/DRL"
"v-iashin/BMT" -> "v-iashin/MDVC"
"v-iashin/BMT" -> "v-iashin/video_features"
"v-iashin/BMT" -> "jayleicn/recurrent-transformer"
"v-iashin/BMT" -> "salesforce/densecap"
"v-iashin/BMT" -> "ttengwang/dense-video-captioning-pytorch"
"v-iashin/BMT" -> "JaywongWang/DenseVideoCaptioning"
"v-iashin/BMT" -> "gingsi/coot-videotext"
"v-iashin/BMT" -> "facebookresearch/grounded-video-description"
"v-iashin/BMT" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"v-iashin/BMT" -> "tgc1997/Awesome-Video-Captioning"
"v-iashin/BMT" -> "ttengwang/PDVC"
"WingsBrokenAngel/Semantics-AssistedVideoCaptioning" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"WingsBrokenAngel/Semantics-AssistedVideoCaptioning" -> "hobincar/SGN"
"WingsBrokenAngel/Semantics-AssistedVideoCaptioning" -> "tgc1997/RMN"
"WingsBrokenAngel/Semantics-AssistedVideoCaptioning" -> "SydCaption/SAAT"
"WingsBrokenAngel/Semantics-AssistedVideoCaptioning" -> "jssprz/visual_syntactic_embedding_video_captioning"
"WingsBrokenAngel/Semantics-AssistedVideoCaptioning" -> "tgc1997/Awesome-Video-Captioning"
"facebookresearch/grounded-video-description" -> "facebookresearch/ActivityNet-Entities"
"facebookresearch/grounded-video-description" -> "salesforce/densecap"
"facebookresearch/grounded-video-description" -> "xiadingZ/video-caption.pytorch"
"facebookresearch/grounded-video-description" -> "JaywongWang/DenseVideoCaptioning"
"facebookresearch/grounded-video-description" -> "jayleicn/recurrent-transformer"
"facebookresearch/grounded-video-description" -> "vsislab/Controllable_XGating"
"facebookresearch/grounded-video-description" -> "tgc1997/RMN"
"facebookresearch/grounded-video-description" -> "XgDuan/WSDEC"
"facebookresearch/grounded-video-description" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"facebookresearch/grounded-video-description" -> "vijayvee/video-captioning"
"facebookresearch/grounded-video-description" -> "scopeInfinity/Video2Description"
"facebookresearch/grounded-video-description" -> "v-iashin/BMT"
"facebookresearch/grounded-video-description" -> "hobincar/RecNet"
"facebookresearch/grounded-video-description" -> "ranjaykrishna/densevid_eval"
"facebookresearch/grounded-video-description" -> "tgc1997/Awesome-Video-Captioning"
"xiadingZ/video-caption.pytorch" -> "vijayvee/video-captioning"
"xiadingZ/video-caption.pytorch" -> "facebookresearch/grounded-video-description"
"xiadingZ/video-caption.pytorch" -> "mynlp/cst_captioning"
"xiadingZ/video-caption.pytorch" -> "Sundrops/video-caption.pytorch"
"xiadingZ/video-caption.pytorch" -> "JaywongWang/DenseVideoCaptioning"
"xiadingZ/video-caption.pytorch" -> "CaptainEven/VideoCaption"
"xiadingZ/video-caption.pytorch" -> "vsislab/Controllable_XGating"
"xiadingZ/video-caption.pytorch" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"xiadingZ/video-caption.pytorch" -> "xiadingZ/video-caption-openNMT.pytorch"
"xiadingZ/video-caption.pytorch" -> "salesforce/densecap"
"xiadingZ/video-caption.pytorch" -> "yaoli/arctic-capgen-vid"
"xiadingZ/video-caption.pytorch" -> "zhegan27/SCN_for_video_captioning"
"xiadingZ/video-caption.pytorch" -> "hobincar/SGN"
"xiadingZ/video-caption.pytorch" -> "scopeInfinity/Video2Description"
"xiadingZ/video-caption.pytorch" -> "SydCaption/SAAT"
"zhegan27/SCN_for_video_captioning" -> "mynlp/cst_captioning"
"zhegan27/SCN_for_video_captioning" -> "tuyunbin/Video-Description-with-Spatial-Temporal-Attention"
"zhegan27/SCN_for_video_captioning" -> "zhegan27/Semantic_Compositional_Nets" ["e"=1]
"zhegan27/SCN_for_video_captioning" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"zhegan27/SCN_for_video_captioning" -> "tgc1997/RMN"
"zhegan27/SCN_for_video_captioning" -> "ranjaykrishna/densevid_eval"
"zhegan27/SCN_for_video_captioning" -> "vijayvee/video-captioning"
"jiyanggao/TALL" -> "LisaAnne/LocalizingMoments"
"jiyanggao/TALL" -> "microsoft/2D-TAN"
"jiyanggao/TALL" -> "JonghwanMun/LGI4temporalgrounding"
"jiyanggao/TALL" -> "runzhouge/MAC"
"jiyanggao/TALL" -> "Alvin-Zeng/DRN"
"jiyanggao/TALL" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"jiyanggao/TALL" -> "IsaacChanghau/VSLNet"
"jiyanggao/TALL" -> "yytzsy/ABLR_code"
"jiyanggao/TALL" -> "VisionLearningGroup/Text-to-Clip_Retrieval"
"jiyanggao/TALL" -> "JaywongWang/CBP"
"jiyanggao/TALL" -> "niluthpol/weak_supervised_video_moment"
"jiyanggao/TALL" -> "ikuinen/CMIN_moment_retrieval"
"jiyanggao/TALL" -> "yytzsy/SCDM"
"jiyanggao/TALL" -> "jayleicn/TVRetrieval"
"jiyanggao/TALL" -> "XgDuan/WSDEC"
"niluthpol/multimodal_vtt" -> "danieljf24/dual_encoding"
"niluthpol/multimodal_vtt" -> "cshizhe/hgr_v2t"
"niluthpol/multimodal_vtt" -> "yalesong/pvse"
"ChenJoya/2dtan" -> "microsoft/2D-TAN"
"ChenJoya/2dtan" -> "JonghwanMun/LGI4temporalgrounding"
"ChenJoya/2dtan" -> "JaywongWang/CBP"
"ChenJoya/2dtan" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"ChenJoya/2dtan" -> "MCG-NJU/MMN"
"ChenJoya/2dtan" -> "MichiganCOG/A2CL-PT" ["e"=1]
"ChenJoya/2dtan" -> "jayleicn/moment_detr"
"ChenJoya/2dtan" -> "WuJie1010/Temporally-language-grounding"
"amanchadha/iPerceive" -> "jayleicn/TVQAplus"
"hobincar/SGN" -> "jssprz/visual_syntactic_embedding_video_captioning"
"hobincar/SGN" -> "tgc1997/RMN"
"hobincar/SGN" -> "WingsBrokenAngel/Semantics-AssistedVideoCaptioning"
"hobincar/SGN" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"hobincar/SGN" -> "SydCaption/SAAT"
"hobincar/SGN" -> "yangbang18/Non-Autoregressive-Video-Captioning"
"jayleicn/recurrent-transformer" -> "salesforce/densecap"
"jayleicn/recurrent-transformer" -> "jayleicn/TVCaption"
"jayleicn/recurrent-transformer" -> "SydCaption/SAAT"
"jayleicn/recurrent-transformer" -> "tgc1997/RMN"
"jayleicn/recurrent-transformer" -> "v-iashin/MDVC"
"jayleicn/recurrent-transformer" -> "gingsi/coot-videotext"
"jayleicn/recurrent-transformer" -> "v-iashin/BMT"
"jayleicn/recurrent-transformer" -> "hobincar/SGN"
"jayleicn/recurrent-transformer" -> "syuqings/video-paragraph"
"jayleicn/recurrent-transformer" -> "vsislab/Controllable_XGating"
"jayleicn/recurrent-transformer" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"jayleicn/recurrent-transformer" -> "facebookresearch/grounded-video-description"
"jayleicn/recurrent-transformer" -> "jssprz/visual_syntactic_embedding_video_captioning"
"jayleicn/recurrent-transformer" -> "tgc1997/Awesome-Video-Captioning"
"jayleicn/recurrent-transformer" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"tgc1997/RMN" -> "tgc1997/Awesome-Video-Captioning"
"tgc1997/RMN" -> "vsislab/Controllable_XGating"
"tgc1997/RMN" -> "SydCaption/SAAT"
"tgc1997/RMN" -> "hobincar/SGN"
"tgc1997/RMN" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"tgc1997/RMN" -> "WingsBrokenAngel/Semantics-AssistedVideoCaptioning"
"tgc1997/RMN" -> "yangbang18/Non-Autoregressive-Video-Captioning"
"tgc1997/RMN" -> "StanfordVL/STGraph"
"yangbang18/Non-Autoregressive-Video-Captioning" -> "hobincar/SGN"
"yangbang18/Non-Autoregressive-Video-Captioning" -> "tgc1997/RMN"
"yangbang18/Non-Autoregressive-Video-Captioning" -> "SydCaption/SAAT"
"vsubhashini/caffe" -> "yaoli/arctic-capgen-vid"
"vsubhashini/caffe" -> "chenxinpeng/S2VT"
"vsubhashini/caffe" -> "jazzsaxmafia/video_to_sequence"
"vsubhashini/caffe" -> "vsubhashini/caption-eval"
"vsubhashini/caffe" -> "tsenghungchen/SA-tensorflow"
"vsubhashini/caffe" -> "jeffdonahue/caffe" ["e"=1]
"vsubhashini/caffe" -> "vijayvee/video-captioning"
"vsubhashini/caffe" -> "LisaAnne/lisa-caffe-public" ["e"=1]
"vsubhashini/caffe" -> "ramakanth-pasunuru/video_captioning_rl"
"vsubhashini/caffe" -> "kimiyoung/review_net" ["e"=1]
"vsubhashini/caffe" -> "xiadingZ/video-caption.pytorch"
"vsubhashini/caffe" -> "smallflyingpig/pytorch_video_caption"
"BonnieHuangxin/SLTA" -> "runzhouge/MAC"
"Yugnaynehc/banet" -> "Yugnaynehc/ssta-captioning"
"Yugnaynehc/ssta-captioning" -> "sususushi/reconstruction-network-for-video-captioning"
"chenxinpeng/S2VT" -> "jazzsaxmafia/video_to_sequence"
"chenxinpeng/S2VT" -> "vsubhashini/caffe"
"chenxinpeng/S2VT" -> "vijayvee/video-captioning"
"mynlp/cst_captioning" -> "ramakanth-pasunuru/video_captioning_rl"
"mynlp/cst_captioning" -> "gujiuxiang/Video_Captioning.pytorch"
"mynlp/cst_captioning" -> "zhegan27/SCN_for_video_captioning"
"mynlp/cst_captioning" -> "sususushi/reconstruction-network-for-video-captioning"
"ramakanth-pasunuru/video_captioning_rl" -> "mynlp/cst_captioning"
"ramakanth-pasunuru/video_captioning_rl" -> "gujiuxiang/Video_Captioning.pytorch"
"ramakanth-pasunuru/video_captioning_rl" -> "sususushi/reconstruction-network-for-video-captioning"
"vsislab/Controllable_XGating" -> "tgc1997/RMN"
"vsislab/Controllable_XGating" -> "SydCaption/SAAT"
"vsislab/Controllable_XGating" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"vsislab/Controllable_XGating" -> "hobincar/RecNet"
"vsislab/Controllable_XGating" -> "tgc1997/Awesome-Video-Captioning"
"HaoYang0123/Position-Focused-Attention-Network" -> "yiling2018/saem"
"HaoYang0123/Position-Focused-Attention-Network" -> "CrossmodalGroup/BFAN"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "layumi/Image-Text-Embedding"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "Jarr0d/ViTAA"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "YingZhangDUT/Cross-Modal-Projection-Learning"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "zifyloo/SSAN"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "OrangeYHChen/TIPCB"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "BrandonHanx/TextReID"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "TencentYoutuResearch/PersonReID-NAFS"
"ShuangLI59/Person-Search-with-Natural-Language-Description" -> "labyrinth7x/Deep-Cross-Modal-Projection-Learning-for-Image-Text-Matching"
"TheShadow29/vognet-pytorch" -> "zfchenUnique/WSSTG"
"TheShadow29/vognet-pytorch" -> "Guaranteer/VidSTG-Dataset"
"TheShadow29/vognet-pytorch" -> "JonghwanMun/LGI4temporalgrounding"
"runzhouge/MAC" -> "JaywongWang/TGN"
"runzhouge/MAC" -> "dazhang-cv/MAN"
"runzhouge/MAC" -> "BonnieHuangxin/SLTA"
"antoyang/just-ask" -> "InterDigitalInc/DialogSummary-VideoQA"
"antoyang/just-ask" -> "tsujuifu/pytorch_violet"
"antoyang/just-ask" -> "antoyang/TubeDETR"
"antoyang/just-ask" -> "doc-doc/NExT-QA"
"antoyang/just-ask" -> "thaolmk54/hcrn-videoqa"
"thaolmk54/hcrn-videoqa" -> "fanchenyou/HME-VideoQA"
"thaolmk54/hcrn-videoqa" -> "SunDoge/L-GCN"
"thaolmk54/hcrn-videoqa" -> "jayleicn/TVQAplus"
"thaolmk54/hcrn-videoqa" -> "YunseokJANG/tgif-qa"
"thaolmk54/hcrn-videoqa" -> "xudejing/video-question-answering"
"thaolmk54/hcrn-videoqa" -> "Jumpin2/HGA"
"thaolmk54/hcrn-videoqa" -> "antoyang/just-ask"
"thaolmk54/hcrn-videoqa" -> "SUTDCV/SUTD-TrafficQA"
"thaolmk54/hcrn-videoqa" -> "amanchadha/iPerceive"
"thaolmk54/hcrn-videoqa" -> "doc-doc/NExT-QA"
"thaolmk54/hcrn-videoqa" -> "MILVLG/activitynet-qa"
"thaolmk54/hcrn-videoqa" -> "jayleicn/TVQA"
"thaolmk54/hcrn-videoqa" -> "noagarcia/knowit-rock"
"PKU-ICST-MIPL/CCL_TMM2018" -> "PKU-ICST-MIPL/SSDH_TCSVT2017"
"PKU-ICST-MIPL/CCL_TMM2018" -> "PKU-ICST-MIPL/CMDN_IJCAI2016"
"PKU-ICST-MIPL/UGACH_AAAI2018" -> "PKU-ICST-MIPL/SCHGAN_TCYB2018"
"PKU-ICST-MIPL/UGACH_AAAI2018" -> "KaiserLew/JDSH"
"PKU-ICST-MIPL/UGACH_AAAI2018" -> "zyfsa/cvpr2018-SSAH"
"PKU-ICST-MIPL/UGACH_AAAI2018" -> "PKU-ICST-MIPL/SSDH_TCSVT2017"
"PKU-ICST-MIPL/UGACH_AAAI2018" -> "huhengtong/UKD_CVPR2020"
"Jarr0d/ViTAA" -> "voriarty/Dual-path-CNN-with-Max-Gated-block-for-Text-Based-Person-Re-identification"
"Jarr0d/ViTAA" -> "Jarr0d/Human-Parsing-Network"
"OrangeYHChen/TIPCB" -> "BrandonHanx/TextReID"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/PersonReID-VAAL"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/PersonReID-TSF"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/PedestrianDetection-NohNMS"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/PersonReID-Pyramid"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/SelfSupervisedLearning-DSM"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/PersonReID-NAFS" -> "OrangeYHChen/TIPCB"
"TencentYoutuResearch/PersonReID-NAFS" -> "TencentYoutuResearch/Pruning-PFF"
"TencentYoutuResearch/PersonReID-NAFS" -> "zifyloo/SSAN"
"layumi/Image-Text-Embedding" -> "ShuangLI59/Person-Search-with-Natural-Language-Description"
"layumi/Image-Text-Embedding" -> "YingZhangDUT/Cross-Modal-Projection-Learning"
"layumi/Image-Text-Embedding" -> "kuanghuei/SCAN"
"layumi/Image-Text-Embedding" -> "lwwang/Two_branch_network"
"layumi/Image-Text-Embedding" -> "TencentYoutuResearch/PersonReID-NAFS"
"layumi/Image-Text-Embedding" -> "OrangeYHChen/TIPCB"
"layumi/Image-Text-Embedding" -> "Jarr0d/ViTAA"
"layumi/Image-Text-Embedding" -> "linxd5/VSE_Pytorch"
"layumi/Image-Text-Embedding" -> "ZihaoWang-CV/CAMP_iccv19"
"layumi/Image-Text-Embedding" -> "Yu-Wu/Exploit-Unknown-Gradually" ["e"=1]
"layumi/Image-Text-Embedding" -> "fartashf/vsepp"
"jazzsaxmafia/video_to_sequence" -> "chenxinpeng/S2VT"
"jazzsaxmafia/video_to_sequence" -> "vsubhashini/caffe"
"jazzsaxmafia/video_to_sequence" -> "yaoli/arctic-capgen-vid"
"jazzsaxmafia/video_to_sequence" -> "tsenghungchen/SA-tensorflow"
"jazzsaxmafia/video_to_sequence" -> "vsubhashini/caption-eval"
"jazzsaxmafia/video_to_sequence" -> "seankim902/imageQA"
"jazzsaxmafia/video_to_sequence" -> "jazzsaxmafia/show_attend_and_tell.tensorflow" ["e"=1]
"jazzsaxmafia/video_to_sequence" -> "emansim/text2image" ["e"=1]
"yaoli/arctic-capgen-vid" -> "vsubhashini/caffe"
"yaoli/arctic-capgen-vid" -> "tsenghungchen/SA-tensorflow"
"yaoli/arctic-capgen-vid" -> "jazzsaxmafia/video_to_sequence"
"yaoli/arctic-capgen-vid" -> "xiadingZ/video-caption.pytorch"
"yaoli/arctic-capgen-vid" -> "tuyunbin/Video-Description-with-Spatial-Temporal-Attention"
"yaoli/arctic-capgen-vid" -> "mynlp/cst_captioning"
"yaoli/arctic-capgen-vid" -> "vijayvee/video-captioning"
"yaoli/arctic-capgen-vid" -> "zhegan27/SCN_for_video_captioning"
"yaoli/arctic-capgen-vid" -> "ivendrov/order-embedding"
"yaoli/arctic-capgen-vid" -> "hobincar/RecNet"
"yaoli/arctic-capgen-vid" -> "szq0214/MSR-VTT-Challenge"
"yaoli/arctic-capgen-vid" -> "vsubhashini/caption-eval"
"yaoli/arctic-capgen-vid" -> "xiadingZ/video-caption-openNMT.pytorch"
"yaoli/arctic-capgen-vid" -> "ramakanth-pasunuru/video_captioning_rl"
"yaoli/arctic-capgen-vid" -> "hobincar/SA-LSTM"
"doc-doc/HQGA" -> "doc-doc/NExT-QA"
"doc-doc/HQGA" -> "sail-sg/VGT"
"doc-doc/NExT-QA" -> "doc-doc/HQGA"
"doc-doc/NExT-QA" -> "doc-doc/NExT-OE"
"doc-doc/NExT-QA" -> "sail-sg/VGT"
"doc-doc/NExT-QA" -> "yl3800/IGV"
"sail-sg/VGT" -> "doc-doc/HQGA"
"sail-sg/VGT" -> "doc-doc/NExT-QA"
"albanie/collaborative-experts" -> "gabeur/mmt"
"albanie/collaborative-experts" -> "antoine77340/Mixture-of-Embedding-Experts"
"albanie/collaborative-experts" -> "danieljf24/dual_encoding"
"albanie/collaborative-experts" -> "danieljf24/awesome-video-text-retrieval"
"albanie/collaborative-experts" -> "danieljf24/hybrid_space"
"albanie/collaborative-experts" -> "cshizhe/hgr_v2t"
"albanie/collaborative-experts" -> "CryhanFang/CLIP2Video"
"albanie/collaborative-experts" -> "niluthpol/multimodal_vtt"
"albanie/collaborative-experts" -> "TencentARC/MCQ"
"albanie/collaborative-experts" -> "ArrowLuo/CLIP4Clip"
"albanie/collaborative-experts" -> "gingsi/coot-videotext"
"albanie/collaborative-experts" -> "m-bain/frozen-in-time"
"albanie/collaborative-experts" -> "jayleicn/ClipBERT" ["e"=1]
"albanie/collaborative-experts" -> "xuchaoxi/video-cnn-feat"
"albanie/collaborative-experts" -> "layer6ai-labs/xpool"
"jayleicn/TVQA" -> "jayleicn/TVQAplus"
"jayleicn/TVQA" -> "YunseokJANG/tgif-qa"
"jayleicn/TVQA" -> "thaolmk54/hcrn-videoqa"
"jayleicn/TVQA" -> "xudejing/video-question-answering"
"jayleicn/TVQA" -> "yj-yu/lsmdc"
"jayleicn/TVQA" -> "amanchadha/iPerceive"
"jayleicn/TVQA" -> "fanchenyou/HME-VideoQA"
"showlab/all-in-one" -> "m-bain/frozen-in-time"
"showlab/all-in-one" -> "tsujuifu/pytorch_violet"
"showlab/all-in-one" -> "TencentARC/MCQ"
"showlab/all-in-one" -> "ruiyan1995/Region_Learner"
"showlab/all-in-one" -> "sail-sg/ptp" ["e"=1]
"showlab/all-in-one" -> "rowanz/merlot"
"showlab/all-in-one" -> "showlab/EgoVLP"
"WendellGul/DCMH" -> "jiangqy/DCMH-CVPR2017"
"WendellGul/DCMH" -> "WangGodder/deep-cross-modal-hashing"
"WendellGul/DCMH" -> "lelan-li/SSAH"
"WendellGul/DCMH" -> "WendellGul/AGAH"
"WendellGul/DCMH" -> "zyfsa/cvpr2018-SSAH"
"WendellGul/DCMH" -> "zzs1994/DJSRH"
"WendellGul/DCMH" -> "jiangqy/DPSH-pytorch" ["e"=1]
"v-iashin/video_features" -> "v-iashin/BMT"
"v-iashin/video_features" -> "jayleicn/recurrent-transformer"
"v-iashin/video_features" -> "v-iashin/MDVC"
"v-iashin/video_features" -> "antoine77340/video_feature_extractor"
"v-iashin/video_features" -> "salesforce/densecap"
"v-iashin/video_features" -> "gingsi/coot-videotext"
"v-iashin/video_features" -> "microsoft/UniVL"
"v-iashin/video_features" -> "ttengwang/dense-video-captioning-pytorch"
"v-iashin/video_features" -> "piergiaj/pytorch-i3d" ["e"=1]
"v-iashin/video_features" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"v-iashin/video_features" -> "jayleicn/moment_detr"
"v-iashin/video_features" -> "ArrowLuo/CLIP4Clip"
"v-iashin/video_features" -> "facebookresearch/grounded-video-description"
"v-iashin/video_features" -> "TencentARC/UMT"
"zifyloo/SSAN" -> "ZhiyinShao-H/LGUR"
"zifyloo/SSAN" -> "TencentYoutuResearch/PersonReID-NAFS"
"zifyloo/SSAN" -> "NjtechCVLab/RSTPReid-Dataset"
"zifyloo/SSAN" -> "Suo-Wei/SRCF"
"gabeur/mmt" -> "albanie/collaborative-experts"
"gabeur/mmt" -> "cshizhe/hgr_v2t"
"gabeur/mmt" -> "danieljf24/awesome-video-text-retrieval"
"gabeur/mmt" -> "gingsi/coot-videotext"
"gabeur/mmt" -> "jayleicn/ClipBERT" ["e"=1]
"gabeur/mmt" -> "antoine77340/Mixture-of-Embedding-Experts"
"gabeur/mmt" -> "ArrowLuo/CLIP4Clip"
"gabeur/mmt" -> "linjieli222/HERO"
"gabeur/mmt" -> "niluthpol/multimodal_vtt"
"gabeur/mmt" -> "danieljf24/hybrid_space"
"gabeur/mmt" -> "CryhanFang/CLIP2Video"
"gabeur/mmt" -> "m-bain/frozen-in-time"
"gabeur/mmt" -> "danieljf24/dual_encoding"
"gabeur/mmt" -> "antoine77340/MIL-NCE_HowTo100M"
"TengdaHan/TemporalAlignNet" -> "mengcaopku/LocVTP"
"TengdaHan/TemporalAlignNet" -> "jayleicn/singularity"
"TengdaHan/TemporalAlignNet" -> "MCG-NJU/MMN"
"TengdaHan/TemporalAlignNet" -> "Chuhanxx/Temporal_Query_Networks" ["e"=1]
"TengdaHan/TemporalAlignNet" -> "Chuhanxx/Object_Centric_Video_Transformer"
"TengdaHan/TemporalAlignNet" -> "ju-chen/Efficient-Prompt" ["e"=1]
"antoine77340/S3D_HowTo100M" -> "antoine77340/MIL-NCE_HowTo100M"
"antoine77340/S3D_HowTo100M" -> "antoine77340/howto100m"
"antoine77340/S3D_HowTo100M" -> "antoine77340/video_feature_extractor"
"antoine77340/S3D_HowTo100M" -> "kylemin/S3D" ["e"=1]
"antoine77340/S3D_HowTo100M" -> "TengdaHan/TemporalAlignNet"
"antoine77340/S3D_HowTo100M" -> "moabitcoin/ig65m-pytorch" ["e"=1]
"woodfrog/vse_infty" -> "Paranioar/SGRAF"
"woodfrog/vse_infty" -> "LgQu/CAMERA"
"woodfrog/vse_infty" -> "Paranioar/Cross-modal_Retrieval_Tutorial"
"woodfrog/vse_infty" -> "LgQu/DIME"
"woodfrog/vse_infty" -> "HuiChen24/IMRAM"
"woodfrog/vse_infty" -> "CrossmodalGroup/NAAF"
"woodfrog/vse_infty" -> "BruceW91/CVSE"
"woodfrog/vse_infty" -> "KunpengLi1994/VSRN"
"woodfrog/vse_infty" -> "CrossmodalGroup/CMCAN"
"woodfrog/vse_infty" -> "CrossmodalGroup/GSMN"
"woodfrog/vse_infty" -> "cyh-sj/CGMN"
"YingZhangDUT/Cross-Modal-Projection-Learning" -> "labyrinth7x/Deep-Cross-Modal-Projection-Learning-for-Image-Text-Matching"
"YingZhangDUT/Cross-Modal-Projection-Learning" -> "ShuangLI59/Person-Search-with-Natural-Language-Description"
"YingZhangDUT/Cross-Modal-Projection-Learning" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"CrossmodalGroup/BFAN" -> "sunnychencool/AOQ"
"CrossmodalGroup/BFAN" -> "yiling2018/saem"
"CrossmodalGroup/BFAN" -> "hardyqr/HAL"
"kywen1119/DSRAN" -> "sunnychencool/AOQ"
"kywen1119/DSRAN" -> "BruceW91/CVSE"
"kywen1119/DSRAN" -> "hardyqr/HAL"
"kywen1119/DSRAN" -> "cyh-sj/CGMN"
"kywen1119/DSRAN" -> "HuiChen24/IMRAM"
"zxJohnFly/GCN" -> "lelan-li/DSEH"
"gingsi/coot-videotext" -> "jayleicn/recurrent-transformer"
"gingsi/coot-videotext" -> "cshizhe/hgr_v2t"
"gingsi/coot-videotext" -> "gabeur/mmt"
"gingsi/coot-videotext" -> "microsoft/UniVL"
"gingsi/coot-videotext" -> "antoine77340/MIL-NCE_HowTo100M"
"gingsi/coot-videotext" -> "v-iashin/BMT"
"gingsi/coot-videotext" -> "salesforce/densecap"
"gingsi/coot-videotext" -> "albanie/collaborative-experts"
"gingsi/coot-videotext" -> "linjieli222/HERO"
"gingsi/coot-videotext" -> "v-iashin/MDVC"
"gingsi/coot-videotext" -> "danieljf24/awesome-video-text-retrieval"
"gingsi/coot-videotext" -> "antoine77340/howto100m"
"gingsi/coot-videotext" -> "jimmy646/violin"
"gingsi/coot-videotext" -> "jayleicn/TVRetrieval"
"gingsi/coot-videotext" -> "v-iashin/video_features"
"scopeInfinity/Video2Description" -> "vijayvee/video-captioning"
"scopeInfinity/Video2Description" -> "facebookresearch/grounded-video-description"
"scopeInfinity/Video2Description" -> "JaywongWang/DenseVideoCaptioning"
"scopeInfinity/Video2Description" -> "pochih/Video-Cap"
"scopeInfinity/Video2Description" -> "xiadingZ/video-caption.pytorch"
"scopeInfinity/Video2Description" -> "salesforce/densecap"
"scopeInfinity/Video2Description" -> "v-iashin/BMT"
"scopeInfinity/Video2Description" -> "CaptainEven/VideoCaption"
"scopeInfinity/Video2Description" -> "jayleicn/recurrent-transformer"
"scopeInfinity/Video2Description" -> "tuyunbin/Video-Description-with-Spatial-Temporal-Attention"
"scopeInfinity/Video2Description" -> "ramakanth-pasunuru/video_captioning_rl"
"scopeInfinity/Video2Description" -> "Shreyz-max/Video-Captioning"
"scopeInfinity/Video2Description" -> "lixiangpengcs/Spatial-Temporal-Adaptive-Attention-for-Video-Captioning"
"ttengwang/ESGN" -> "ttengwang/ECHR"
"ttengwang/dense-video-captioning-pytorch" -> "ttengwang/ESGN"
"ttengwang/dense-video-captioning-pytorch" -> "salesforce/densecap"
"ttengwang/dense-video-captioning-pytorch" -> "ttengwang/ECHR"
"BruceW91/CVSE" -> "songdony/gin_go" ["e"=1]
"BruceW91/CVSE" -> "fullStack-feed/joyful-house" ["e"=1]
"BruceW91/CVSE" -> "Bitcoin-Classic-BGH/Bitcoin-Classic" ["e"=1]
"BruceW91/CVSE" -> "zhuxingwan/SynsetsTools" ["e"=1]
"BruceW91/CVSE" -> "lingjye/Flutter-Learning" ["e"=1]
"BruceW91/CVSE" -> "emmeair/go-canal" ["e"=1]
"BruceW91/CVSE" -> "wensiyuanseven/light-virtual-list" ["e"=1]
"BruceW91/CVSE" -> "IAIAE/estime" ["e"=1]
"BruceW91/CVSE" -> "BBLLMYD/netty-stroll" ["e"=1]
"BruceW91/CVSE" -> "kywen1119/DSRAN"
"BruceW91/CVSE" -> "ZhangWei-KUMO/react-dynamic-vector-icons" ["e"=1]
"BruceW91/CVSE" -> "rikochyou/jsonp-good" ["e"=1]
"hardyqr/HAL" -> "sunnychencool/AOQ"
"labyrinth7x/Deep-Cross-Modal-Projection-Learning-for-Image-Text-Matching" -> "YingZhangDUT/Cross-Modal-Projection-Learning"
"antoine77340/Mixture-of-Embedding-Experts" -> "albanie/collaborative-experts"
"antoine77340/Mixture-of-Embedding-Experts" -> "yj-yu/lsmdc"
"antoine77340/Mixture-of-Embedding-Experts" -> "cshizhe/hgr_v2t"
"antoine77340/Mixture-of-Embedding-Experts" -> "gabeur/mmt"
"Atmegal/DGCPN" -> "zs-zhong/DJSRH"
"Atmegal/DGCPN" -> "KaiserLew/JDSH"
"Atmegal/DGCPN" -> "idejie/DSAH"
"TencentYoutuResearch/SelfSupervisedLearning-DSM" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/SelfSupervisedLearning-DSM" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/SelfSupervisedLearning-DSM" -> "TencentYoutuResearch/Pruning-PFF"
"TencentYoutuResearch/SelfSupervisedLearning-DSM" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/SelfSupervisedLearning-DSM" -> "TencentYoutuResearch/PersonReID-Pyramid"
"TencentYoutuResearch/SelfSupervisedLearning-DSM" -> "TencentYoutuResearch/PersonReID-VAAL"
"TencentYoutuResearch/SelfSupervisedLearning-DSM" -> "TencentYoutuResearch/PersonReID-TSF"
"antoyang/TubeDETR" -> "jy0205/STCAT"
"antoyang/TubeDETR" -> "antoyang/just-ask"
"antoyang/TubeDETR" -> "sangminwoo/Explore-And-Match"
"antoyang/TubeDETR" -> "jayleicn/moment_detr"
"antoyang/TubeDETR" -> "TencentARC/UMT"
"antoyang/TubeDETR" -> "MCG-NJU/MMN"
"JaywongWang/DenseVideoCaptioning" -> "ranjaykrishna/densevid_eval"
"JaywongWang/DenseVideoCaptioning" -> "XgDuan/WSDEC"
"JaywongWang/DenseVideoCaptioning" -> "facebookresearch/grounded-video-description"
"JaywongWang/DenseVideoCaptioning" -> "salesforce/densecap"
"JaywongWang/DenseVideoCaptioning" -> "mynlp/cst_captioning"
"JaywongWang/DenseVideoCaptioning" -> "JaywongWang/SST-Tensorflow" ["e"=1]
"JaywongWang/DenseVideoCaptioning" -> "ramakanth-pasunuru/video_captioning_rl"
"JaywongWang/DenseVideoCaptioning" -> "zhegan27/SCN_for_video_captioning"
"JaywongWang/DenseVideoCaptioning" -> "xiadingZ/video-caption.pytorch"
"JaywongWang/DenseVideoCaptioning" -> "v-iashin/MDVC"
"JaywongWang/DenseVideoCaptioning" -> "v-iashin/BMT"
"JaywongWang/DenseVideoCaptioning" -> "vsislab/Controllable_XGating"
"JaywongWang/DenseVideoCaptioning" -> "LuoweiZhou/anet2016-cuhk-feature"
"JaywongWang/DenseVideoCaptioning" -> "escorciav/daps" ["e"=1]
"JaywongWang/DenseVideoCaptioning" -> "ttengwang/dense-video-captioning-pytorch"
"shaohua0116/Group-Normalization-Tensorflow" -> "taokong/group_normalization"
"zhaoyue-zephyrus/TeSTra" -> "amazon-science/long-short-term-transformer"
"facebookresearch/ActivityNet-Entities" -> "facebookresearch/grounded-video-description"
"facebookresearch/ActivityNet-Entities" -> "TheShadow29/vognet-pytorch"
"facebookresearch/ActivityNet-Entities" -> "ranjaykrishna/densevid_eval"
"facebookresearch/ActivityNet-Entities" -> "jayleicn/TVQAplus"
"lwwang/Two_branch_network" -> "BryanPlummer/two_branch_networks"
"IsaacChanghau/ReLoCLNet" -> "houzhijian/CONQUER"
"IsaacChanghau/ReLoCLNet" -> "jayleicn/TVRetrieval"
"IsaacChanghau/ReLoCLNet" -> "yytzsy/grounding_changing_distribution"
"EGO4D/hands-and-objects" -> "facebookresearch/Ego4d"
"jayleicn/singularity" -> "klauscc/VindLU" ["e"=1]
"jayleicn/singularity" -> "microsoft/LAVENDER"
"jayleicn/singularity" -> "TengdaHan/TemporalAlignNet"
"tgc1997/Awesome-Video-Captioning" -> "tgc1997/RMN"
"tgc1997/Awesome-Video-Captioning" -> "SydCaption/SAAT"
"tgc1997/Awesome-Video-Captioning" -> "vsislab/Controllable_XGating"
"tgc1997/Awesome-Video-Captioning" -> "WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning"
"tgc1997/Awesome-Video-Captioning" -> "forence/Awesome-Visual-Captioning" ["e"=1]
"tgc1997/Awesome-Video-Captioning" -> "hobincar/SGN"
"tgc1997/Awesome-Video-Captioning" -> "WingsBrokenAngel/Semantics-AssistedVideoCaptioning"
"tgc1997/Awesome-Video-Captioning" -> "yangbang18/Non-Autoregressive-Video-Captioning"
"tgc1997/Awesome-Video-Captioning" -> "jssprz/visual_syntactic_embedding_video_captioning"
"jimmy646/violin" -> "linjieli222/HERO"
"jimmy646/violin" -> "jayleicn/TVCaption"
"jimmy646/violin" -> "jayleicn/TVRetrieval"
"jimmy646/violin" -> "jayleicn/TVQAplus"
"jimmy646/violin" -> "LuoweiZhou/densecap"
"jimmy646/violin" -> "ych133/How2R-and-How2QA"
"jimmy646/violin" -> "jayleicn/recurrent-transformer"
"mesnico/TERAN" -> "mesnico/TERN"
"mesnico/TERAN" -> "yiling2018/saem"
"facebookresearch/LaViLa" -> "UT-Austin-RPL/FORGE"
"facebookresearch/LaViLa" -> "UT-Austin-RPL/VIOLA"
"facebookresearch/LaViLa" -> "jozhang97/DETA" ["e"=1]
"facebookresearch/LaViLa" -> "showlab/all-in-one"
"facebookresearch/LaViLa" -> "zhaoyue-zephyrus/TeSTra"
"facebookresearch/LaViLa" -> "showlab/EgoVLP"
"ranjaykrishna/densevid_eval" -> "XgDuan/WSDEC"
"ranjaykrishna/densevid_eval" -> "JaywongWang/DenseVideoCaptioning"
"ranjaykrishna/densevid_eval" -> "szq0214/MSR-VTT-Challenge"
"ranjaykrishna/densevid_eval" -> "zhegan27/SCN_for_video_captioning"
"ranjaykrishna/densevid_eval" -> "mynlp/cst_captioning"
"ranjaykrishna/densevid_eval" -> "salesforce/densecap"
"ranjaykrishna/densevid_eval" -> "shyamal-b/sst" ["e"=1]
"Suo-Wei/SRCF" -> "zhangweifeng1218/Text-based-Person-Search"
"XgDuan/WSDEC" -> "ranjaykrishna/densevid_eval"
"XgDuan/WSDEC" -> "JaywongWang/DenseVideoCaptioning"
"XgDuan/WSDEC" -> "jiyanggao/TALL"
"XgDuan/WSDEC" -> "IsaacChanghau/VSLNet"
"jayleicn/TVQAplus" -> "fanchenyou/HME-VideoQA"
"jayleicn/TVQAplus" -> "jayleicn/TVQA"
"jayleicn/TVQAplus" -> "thaolmk54/hcrn-videoqa"
"jayleicn/TVQAplus" -> "amanchadha/iPerceive"
"jayleicn/TVQAplus" -> "YunseokJANG/tgif-qa"
"xudejing/VideoQA" -> "xuehy/videoqa"
"xuehy/videoqa" -> "xudejing/VideoQA"
"makarandtapaswi/MovieQA_CVPR2016" -> "makarandtapaswi/MovieQA_benchmark"
"Sid2697/awesome-egocentric-vision" -> "showlab/EgoVLP"
"Sid2697/awesome-egocentric-vision" -> "facebookresearch/Ego4d"
"Sid2697/awesome-egocentric-vision" -> "EgocentricVision/EgocentricVision"
"Sid2697/awesome-egocentric-vision" -> "EGO4D/episodic-memory"
"ZihaoWang-CV/CAMP_iccv19" -> "HuiChen24/IMRAM"
"ZihaoWang-CV/CAMP_iccv19" -> "CrossmodalGroup/GSMN"
"ZihaoWang-CV/CAMP_iccv19" -> "penghu-cs/DSCMR"
"ZihaoWang-CV/CAMP_iccv19" -> "Wangt-CN/MTFN-RR-PyTorch-Code"
"ZihaoWang-CV/CAMP_iccv19" -> "sunnychencool/AOQ"
"ZihaoWang-CV/CAMP_iccv19" -> "KunpengLi1994/VSRN"
"ZihaoWang-CV/CAMP_iccv19" -> "yiling2018/saem"
"ZihaoWang-CV/CAMP_iccv19" -> "CrossmodalGroup/BFAN"
"ZihaoWang-CV/CAMP_iccv19" -> "BruceW91/CVSE"
"ZihaoWang-CV/CAMP_iccv19" -> "kywen1119/DSRAN"
"ZihaoWang-CV/CAMP_iccv19" -> "kuanghuei/SCAN"
"ZihaoWang-CV/CAMP_iccv19" -> "yalesong/pvse"
"ZihaoWang-CV/CAMP_iccv19" -> "zhongzhh8/Cross-Modal-Retrieval"
"ZihaoWang-CV/CAMP_iccv19" -> "hardyqr/Visual-Semantic-Embeddings-an-incomplete-list"
"cshizhe/hgr_v2t" -> "gabeur/mmt"
"cshizhe/hgr_v2t" -> "JonghwanMun/LGI4temporalgrounding"
"cshizhe/hgr_v2t" -> "niluthpol/multimodal_vtt"
"cshizhe/hgr_v2t" -> "gingsi/coot-videotext"
"cshizhe/hgr_v2t" -> "albanie/collaborative-experts"
"cshizhe/hgr_v2t" -> "danieljf24/awesome-video-text-retrieval"
"cshizhe/hgr_v2t" -> "danieljf24/dual_encoding"
"cshizhe/hgr_v2t" -> "ikuinen/CMIN_moment_retrieval"
"cshizhe/hgr_v2t" -> "CrossmodalGroup/GSMN"
"cshizhe/hgr_v2t" -> "microsoft/2D-TAN"
"cshizhe/hgr_v2t" -> "antoine77340/Mixture-of-Embedding-Experts"
"cshizhe/hgr_v2t" -> "KunpengLi1994/VSRN"
"cshizhe/hgr_v2t" -> "antoine77340/howto100m"
"cshizhe/hgr_v2t" -> "CryhanFang/CLIP2Video"
"cshizhe/hgr_v2t" -> "yytzsy/SCDM"
"mesnico/TERN" -> "mesnico/TERAN"
"sunpeng981712364/ACMR_demo" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"sunpeng981712364/ACMR_demo" -> "niluthpol/multimodal_vtt"
"sunpeng981712364/ACMR_demo" -> "lelan-li/SSAH"
"sunpeng981712364/ACMR_demo" -> "yalesong/pvse"
"sunpeng981712364/ACMR_demo" -> "jiangqy/DCMH-CVPR2017"
"sunpeng981712364/ACMR_demo" -> "zhongzhh8/Cross-Modal-Retrieval"
"yalesong/pvse" -> "niluthpol/multimodal_vtt"
"yalesong/pvse" -> "lelan-li/SSAH"
"yalesong/pvse" -> "fartashf/vsepp"
"yalesong/pvse" -> "KunpengLi1994/VSRN"
"yalesong/pvse" -> "HuiChen24/IMRAM"
"yalesong/pvse" -> "penghu-cs/DSCMR"
"yalesong/pvse" -> "PKU-ICST-MIPL/UGACH_AAAI2018"
"yalesong/pvse" -> "sunpeng981712364/ACMR_demo"
"yalesong/pvse" -> "ZihaoWang-CV/CAMP_iccv19"
"yalesong/pvse" -> "gujiuxiang/Multimodal_Retrieval.pytorch"
"hobincar/RecNet" -> "hobincar/SA-LSTM"
"hobincar/RecNet" -> "vsislab/Controllable_XGating"
"hobincar/RecNet" -> "hobincar/SGN"
"hobincar/RecNet" -> "hobincar/pytorch-video-feature-extractor"
"hobincar/SA-LSTM" -> "hobincar/RecNet"
"raingo/TGIF-Release" -> "YunseokJANG/tgif-qa"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "ikuinen/CMIN_moment_retrieval"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "WuJie1010/Awesome-Temporally-Language-Grounding"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "JonghwanMun/LGI4temporalgrounding"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "JaywongWang/CBP"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "yytzsy/grounding_changing_distribution"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "WuJie1010/Temporally-language-grounding"
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" -> "yytzsy/SCDM"
"Alvin-Zeng/DRN" -> "JonghwanMun/LGI4temporalgrounding"
"Alvin-Zeng/DRN" -> "liudaizong/CSMGAN"
"Alvin-Zeng/DRN" -> "JaywongWang/CBP"
"Alvin-Zeng/DRN" -> "mayu-ot/hidden-challenges-MR"
"JaywongWang/CBP" -> "JaywongWang/TGN"
"JaywongWang/CBP" -> "yytzsy/SCDM"
"JaywongWang/CBP" -> "niluthpol/weak_supervised_video_moment"
"JaywongWang/CBP" -> "dazhang-cv/MAN"
"LisaAnne/LocalizingMoments" -> "jiyanggao/TALL"
"LisaAnne/LocalizingMoments" -> "VisionLearningGroup/Text-to-Clip_Retrieval"
"LisaAnne/LocalizingMoments" -> "BonnieHuangxin/SLTA"
"LisaAnne/LocalizingMoments" -> "ikuinen/CMIN_moment_retrieval"
"LisaAnne/LocalizingMoments" -> "WuJie1010/Awesome-Temporally-Language-Grounding"
"LisaAnne/LocalizingMoments" -> "WuJie1010/Temporally-language-grounding"
"LisaAnne/LocalizingMoments" -> "runzhouge/MAC"
"LisaAnne/LocalizingMoments" -> "yytzsy/ABLR_code"
"LisaAnne/LocalizingMoments" -> "JonghwanMun/LGI4temporalgrounding"
"LisaAnne/LocalizingMoments" -> "niluthpol/weak_supervised_video_moment"
"LisaAnne/LocalizingMoments" -> "Soldelli/VLG-Net"
"LisaAnne/LocalizingMoments" -> "Alvin-Zeng/DRN"
"LisaAnne/LocalizingMoments" -> "JaywongWang/CBP"
"LisaAnne/LocalizingMoments" -> "microsoft/2D-TAN"
"LisaAnne/LocalizingMoments" -> "iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos"
"VisionLearningGroup/Text-to-Clip_Retrieval" -> "dazhang-cv/MAN"
"VisionLearningGroup/Text-to-Clip_Retrieval" -> "runzhouge/MAC"
"taokong/group_normalization" -> "kuangliu/pytorch-groupnorm"
"gujiuxiang/Video_Captioning.pytorch" -> "mynlp/cst_captioning"
"gujiuxiang/Video_Captioning.pytorch" -> "ramakanth-pasunuru/video_captioning_rl"
"tzhhhh123/HC-STVG" -> "Guaranteer/VidSTG-Dataset"
"showlab/EgoVLP" -> "facebookresearch/Ego4d"
"showlab/EgoVLP" -> "jayleicn/singularity"
"showlab/EgoVLP" -> "EGO4D/episodic-memory"
"showlab/EgoVLP" -> "OpenGVLab/ego4d-eccv2022-solutions" ["e"=1]
"showlab/EgoVLP" -> "MikeWangWZHL/VidIL" ["e"=1]
"showlab/EgoVLP" -> "microsoft/LAVENDER"
"jayleicn/moment_detr" -> "TencentARC/UMT"
"jayleicn/moment_detr" -> "linjieli222/HERO_Video_Feature_Extractor"
"jayleicn/moment_detr" -> "ChrisAllenMing/Cross_Category_Video_Highlight"
"jayleicn/moment_detr" -> "JonghwanMun/LGI4temporalgrounding"
"jayleicn/moment_detr" -> "microsoft/2D-TAN"
"jayleicn/moment_detr" -> "MCG-NJU/MMN"
"jayleicn/moment_detr" -> "Soldelli/MAD"
"jayleicn/moment_detr" -> "IsaacChanghau/ReLoCLNet"
"jayleicn/moment_detr" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"jayleicn/moment_detr" -> "antoyang/TubeDETR"
"jayleicn/moment_detr" -> "ChenJoya/2dtan"
"jayleicn/moment_detr" -> "yytzsy/grounding_changing_distribution"
"jayleicn/moment_detr" -> "tsujuifu/pytorch_violet"
"jayleicn/moment_detr" -> "Soldelli/Awesome-Temporal-Language-Grounding-in-Videos"
"jayleicn/moment_detr" -> "yeliudev/nncore"
"TencentARC/UMT" -> "jayleicn/moment_detr"
"TencentARC/UMT" -> "ChrisAllenMing/Cross_Category_Video_Highlight"
"TencentARC/UMT" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"TencentARC/UMT" -> "linjieli222/HERO_Video_Feature_Extractor"
"TencentARC/UMT" -> "mengcaopku/LocVTP"
"TencentARC/UMT" -> "yeliudev/nncore"
"TencentARC/UMT" -> "antoyang/TubeDETR"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "IsaacChanghau/VSLNet"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "ikuinen/CMIN_moment_retrieval"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "JonghwanMun/LGI4temporalgrounding"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "Alvin-Zeng/DRN"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "jiyanggao/TALL"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "WuJie1010/Awesome-Temporally-Language-Grounding"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "JaywongWang/CBP"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "Huntersxsx/TSGV-Learning-List"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "liudaizong/CSMGAN"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "yytzsy/ABLR_code"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "yytzsy/SCDM"
"SCZwangxiao/Temporal-Language-Grounding-in-videos" -> "WuJie1010/Temporally-language-grounding"
"ChrisAllenMing/Cross_Category_Video_Highlight" -> "TencentARC/UMT"
"ChrisAllenMing/Cross_Category_Video_Highlight" -> "aliensunmin/DomainSpecificHighlight" ["e"=1]
"houzhijian/CONQUER" -> "IsaacChanghau/ReLoCLNet"
"jayleicn/TVRetrieval" -> "IsaacChanghau/ReLoCLNet"
"jayleicn/TVRetrieval" -> "IsaacChanghau/VSLNet"
"jayleicn/TVRetrieval" -> "jayleicn/mTVRetrieval"
"jayleicn/TVRetrieval" -> "houzhijian/CONQUER"
"jayleicn/TVRetrieval" -> "WuJie1010/Temporally-language-grounding"
"jayleicn/TVRetrieval" -> "jayleicn/TVCaption"
"jayleicn/TVRetrieval" -> "escorciav/moments-retrieval-page"
"jayleicn/TVRetrieval" -> "linjieli222/HERO_Video_Feature_Extractor"
"jayleicn/TVRetrieval" -> "jiyanggao/TALL"
"jayleicn/TVRetrieval" -> "yytzsy/ABLR_code"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/PersonReID-VAAL"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/PersonReID-TSF"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/PersonReID-Pyramid"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/SelfSupervisedLearning-DSM"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/Pruning-PFF"
"TencentYoutuResearch/PedestrianDetection-NohNMS" -> "TencentYoutuResearch/PersonReID-NAFS"
"BrandonHanx/TextReID" -> "OrangeYHChen/TIPCB"
"m-bain/webvid" -> "m-bain/frozen-in-time"
"m-bain/webvid" -> "microsoft/XPretrain"
"xuchaoxi/video-cnn-feat" -> "li-xirong/avs"
"niluthpol/weak_supervised_video_moment" -> "dingli93/weak_supervised_video_moment"
"niluthpol/weak_supervised_video_moment" -> "tanghaoyu258/ACRM-for-moment-retrieval"
"niluthpol/weak_supervised_video_moment" -> "JaywongWang/CBP"
"niluthpol/weak_supervised_video_moment" -> "yytzsy/grounding_changing_distribution"
"zfchenUnique/WSSTG" -> "zfchenUnique/VID-Sentence"
"Huntersxsx/RaNet" -> "xiaoneil/LPNet"
"liudaizong/CSMGAN" -> "forwchen/HVTG"
"rowanz/merlot_reserve" -> "rowanz/merlot"
"EGO4D/episodic-memory" -> "facebookresearch/vq2d_cvpr"
"EGO4D/episodic-memory" -> "NNNNAI/Ego4d_NLQ_2022_1st_Place_Solution"
"EGO4D/episodic-memory" -> "facebookresearch/Ego4d"
"EGO4D/episodic-memory" -> "showlab/EgoVLP"
"foolwood/DRL" -> "ioanacroi/qb-norm"
"foolwood/DRL" -> "mzhaoshuai/CenterCLIP"
"LgQu/CAMERA" -> "LgQu/DIME"
"LgQu/DIME" -> "LgQu/CAMERA"
"sunnychencool/AOQ" -> "hardyqr/HAL"
"sunnychencool/AOQ" -> "CrossmodalGroup/BFAN"
"yl3800/IGV" -> "yl3800/EIGV"
"fanchenyou/HME-VideoQA" -> "YunseokJANG/tgif-qa"
"fanchenyou/HME-VideoQA" -> "thaolmk54/hcrn-videoqa"
"fanchenyou/HME-VideoQA" -> "jayleicn/TVQAplus"
"Soldelli/Awesome-Temporal-Language-Grounding-in-Videos" -> "Soldelli/MAD"
"jayleicn/TVCaption" -> "jayleicn/recurrent-transformer"
"noagarcia/ROLL-VideoQA" -> "noagarcia/knowit-rock"
"noagarcia/knowit-rock" -> "noagarcia/ROLL-VideoQA"
"noagarcia/knowit-rock" -> "InterDigitalInc/DialogSummary-VideoQA"
"VRU-NExT/VideoQA" -> "sail-sg/VGT"
"daerduoCarey/where2act" -> "daerduoCarey/o2oafford"
"TencentYoutuResearch/PersonReID-ACT" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/PersonReID-ACT" -> "TencentYoutuResearch/PersonReID-VAAL"
"TencentYoutuResearch/PersonReID-ACT" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/PersonReID-ACT" -> "TencentYoutuResearch/Pruning-PFF"
"TencentYoutuResearch/PersonReID-ACT" -> "TencentYoutuResearch/PersonReID-TSF"
"penghu-cs/SDML" -> "penghu-cs/MAN"
"penghu-cs/MAN" -> "penghu-cs/SDML"
"pansanity666/INO_VOS" -> "sxl142/GLoT"
"pansanity666/INO_VOS" -> "FreeformRobotics/Divide-and-Co-training"
"dazhang-cv/MAN" -> "JaywongWang/TGN"
"WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning" -> "WingsBrokenAngel/Semantics-AssistedVideoCaptioning"
"WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning" -> "jssprz/visual_syntactic_embedding_video_captioning"
"WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning" -> "tgc1997/RMN"
"WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning" -> "vsislab/Controllable_XGating"
"WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning" -> "hobincar/SGN"
"TencentYoutuResearch/PersonReID-TSF" -> "TencentYoutuResearch/PersonReID-VAAL"
"TencentYoutuResearch/PersonReID-TSF" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/PersonReID-TSF" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/PersonReID-TSF" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/PersonReID-TSF" -> "TencentYoutuResearch/PersonReID-Pyramid"
"TencentYoutuResearch/PersonReID-TSF" -> "TencentYoutuResearch/Pruning-PFF"
"lelan-li/DSEH" -> "zxJohnFly/GCN"
"Guaranteer/VidSTG-Dataset" -> "tzhhhh123/HC-STVG"
"EgocentricVision/EgocentricVision" -> "EgocentricVision/RNA-TTA"
"EgocentricVision/EgocentricVision" -> "EgocentricVision/N-EPIC-Kitchens"
"TencentYoutuResearch/PersonReID-Pyramid" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/PersonReID-Pyramid" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/PersonReID-Pyramid" -> "TencentYoutuResearch/Pruning-PFF"
"TencentYoutuResearch/PersonReID-Pyramid" -> "TencentYoutuResearch/PersonReID-TSF"
"TencentYoutuResearch/PersonReID-Pyramid" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/PersonReID-Pyramid" -> "TencentYoutuResearch/PersonReID-VAAL"
"sxl142/GLoT" -> "pansanity666/INO_VOS"
"daerduoCarey/o2oafford" -> "evelinehong/FixIt"
"TencentYoutuResearch/PersonReID-CACENET" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/PersonReID-CACENET" -> "TencentYoutuResearch/PersonReID-VAAL"
"TencentYoutuResearch/PersonReID-CACENET" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/PersonReID-CACENET" -> "TencentYoutuResearch/PersonReID-TSF"
"VALUE-Leaderboard/DataRelease" -> "VALUE-Leaderboard/EvaluationTools"
"PKU-ICST-MIPL/CMDN_IJCAI2016" -> "PKU-ICST-MIPL/JRL_TCSVT2014"
"TencentYoutuResearch/PersonReID-VAAL" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/PersonReID-VAAL" -> "TencentYoutuResearch/PersonReID-TSF"
"TencentYoutuResearch/PersonReID-VAAL" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/PersonReID-VAAL" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/PersonReID-VAAL" -> "TencentYoutuResearch/Pruning-PFF"
"TencentYoutuResearch/Pruning-PFF" -> "TencentYoutuResearch/Ensemble-Grafting"
"TencentYoutuResearch/Pruning-PFF" -> "TencentYoutuResearch/PersonReID-ACT"
"NNNNAI/Ego4d_NLQ_2022_1st_Place_Solution" -> "sxl142/GLoT"
"NNNNAI/Ego4d_NLQ_2022_1st_Place_Solution" -> "pansanity666/INO_VOS"
"TencentYoutuResearch/Ensemble-Grafting" -> "TencentYoutuResearch/Pruning-PFF"
"TencentYoutuResearch/Ensemble-Grafting" -> "TencentYoutuResearch/PersonReID-ACT"
"TencentYoutuResearch/Ensemble-Grafting" -> "TencentYoutuResearch/PersonReID-CACENET"
"TencentYoutuResearch/Ensemble-Grafting" -> "TencentYoutuResearch/PersonReID-VAAL"
"elleryqueenhomels/Neural-Style-Transfer-Papers" -> "danieljf24/text2image"
"iboing/CliqueNet" ["l"="32.003,33.845"]
"visinf/dpp" ["l"="31.908,33.813"]
"shaohua0116/Group-Normalization-Tensorflow" ["l"="32.063,33.864"]
"salesforce/ALPRO" ["l"="31.699,33.791"]
"tsujuifu/pytorch_violet" ["l"="31.683,33.805"]
"TencentARC/MCQ" ["l"="31.699,33.763"]
"foolwood/DRL" ["l"="31.724,33.74"]
"jayleicn/moment_detr" ["l"="31.674,33.821"]
"linjieli222/HERO" ["l"="31.712,33.835"]
"mengcaopku/LocVTP" ["l"="31.679,33.778"]
"TengdaHan/TemporalAlignNet" ["l"="31.698,33.78"]
"antoine77340/howto100m" ["l"="31.754,33.829"]
"antoine77340/MIL-NCE_HowTo100M" ["l"="31.734,33.821"]
"antoine77340/S3D_HowTo100M" ["l"="31.747,33.814"]
"antoine77340/video_feature_extractor" ["l"="31.77,33.837"]
"cshizhe/hgr_v2t" ["l"="31.765,33.795"]
"gingsi/coot-videotext" ["l"="31.747,33.84"]
"salesforce/densecap" ["l"="31.778,33.892"]
"jayleicn/TVCaption" ["l"="31.734,33.867"]
"m-bain/frozen-in-time" ["l"="31.712,33.78"]
"microsoft/UniVL" ["l"="31.715,33.812"]
"vijayvee/video-captioning" ["l"="31.822,33.942"]
"xiadingZ/video-caption.pytorch" ["l"="31.809,33.932"]
"zhegan27/SCN_for_video_captioning" ["l"="31.809,33.948"]
"tgc1997/Awesome-Video-Captioning" ["l"="31.771,33.926"]
"tsenghungchen/SA-tensorflow" ["l"="31.839,33.963"]
"scopeInfinity/Video2Description" ["l"="31.818,33.916"]
"facebookresearch/grounded-video-description" ["l"="31.783,33.908"]
"chenxinpeng/S2VT" ["l"="31.853,33.972"]
"xiadingZ/video-caption-openNMT.pytorch" ["l"="31.839,33.949"]
"JaywongWang/DenseVideoCaptioning" ["l"="31.795,33.918"]
"CaptainEven/VideoCaption" ["l"="31.797,33.943"]
"ranjaykrishna/densevid_eval" ["l"="31.785,33.93"]
"vsubhashini/caffe" ["l"="31.86,33.956"]
"yaoli/arctic-capgen-vid" ["l"="31.849,33.939"]
"tgc1997/RMN" ["l"="31.774,33.938"]
"danieljf24/dual_encoding" ["l"="31.778,33.802"]
"niluthpol/multimodal_vtt" ["l"="31.815,33.779"]
"danieljf24/hybrid_space" ["l"="31.773,33.783"]
"albanie/collaborative-experts" ["l"="31.755,33.782"]
"danieljf24/awesome-video-text-retrieval" ["l"="31.742,33.792"]
"xuchaoxi/video-cnn-feat" ["l"="31.791,33.787"]
"danieljf24/w2vv" ["l"="31.83,33.812"]
"niluthpol/weak_supervised_video_moment" ["l"="31.663,33.842"]
"MKLab-ITI/ndvr-dml" ["l"="32.976,34.389"]
"jiyanggao/TALL" ["l"="31.664,33.859"]
"li-xirong/avs" ["l"="31.807,33.799"]
"jazzsaxmafia/video_to_sequence" ["l"="31.876,33.97"]
"Sundrops/video-caption.pytorch" ["l"="31.807,33.971"]
"Yugnaynehc/ssta-captioning" ["l"="31.825,34.007"]
"cgq5/Video-Caption-with-Neuraltalk2" ["l"="31.869,34.001"]
"CryhanFang/CLIP2Video" ["l"="31.739,33.766"]
"ArrowLuo/CLIP4Clip" ["l"="31.728,33.779"]
"starmemda/CAMoE" ["l"="31.747,33.753"]
"mzhaoshuai/CenterCLIP" ["l"="31.715,33.713"]
"jayleicn/ClipBERT" ["l"="31.654,34.705"]
"layer6ai-labs/xpool" ["l"="31.735,33.749"]
"mwray/Semantic-Video-Retrieval" ["l"="31.72,33.793"]
"Deferf/CLIP_Video_Representation" ["l"="31.754,33.73"]
"gabeur/mmt" ["l"="31.75,33.803"]
"sallymmx/ActionCLIP" ["l"="32.407,35.037"]
"TengdaHan/CoCLR" ["l"="31.977,33.093"]
"HumamAlwassel/XDC" ["l"="31.956,33.066"]
"facebookresearch/AVID-CMA" ["l"="31.803,33.829"]
"hobincar/pytorch-video-feature-extractor" ["l"="31.814,33.875"]
"hobincar/RecNet" ["l"="31.811,33.903"]
"nasib-ullah/video-captioning-models-in-Pytorch" ["l"="31.79,33.859"]
"hobincar/SA-LSTM" ["l"="31.838,33.901"]
"ivendrov/order-embedding" ["l"="31.9,33.845"]
"ivendrov/order-embeddings-wordnet" ["l"="31.929,33.859"]
"ryankiros/visual-semantic-embedding" ["l"="31.9,33.781"]
"linxd5/VSE_Pytorch" ["l"="31.96,33.726"]
"josharnoldjosh/Image-Caption-Joint-Embedding" ["l"="31.992,33.72"]
"showlab/all-in-one" ["l"="31.67,33.763"]
"jayleicn/singularity" ["l"="31.683,33.753"]
"m-bain/webvid" ["l"="31.702,33.74"]
"showlab/EgoVLP" ["l"="31.645,33.711"]
"yytzsy/SCDM" ["l"="31.644,33.857"]
"ikuinen/CMIN_moment_retrieval" ["l"="31.644,33.838"]
"JaywongWang/CBP" ["l"="31.633,33.852"]
"runzhouge/MAC" ["l"="31.631,33.879"]
"JaywongWang/TGN" ["l"="31.624,33.873"]
"dazhang-cv/MAN" ["l"="31.613,33.878"]
"BonnieHuangxin/SLTA" ["l"="31.615,33.869"]
"WuJie1010/Awesome-Temporally-Language-Grounding" ["l"="31.616,33.838"]
"WuJie1010/Temporally-language-grounding" ["l"="31.628,33.834"]
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" ["l"="31.624,33.844"]
"WuJie1010/TSP-PRL" ["l"="31.596,33.831"]
"SCZwangxiao/Temporal-Language-Grounding-in-videos" ["l"="31.635,33.844"]
"JonghwanMun/LGI4temporalgrounding" ["l"="31.651,33.842"]
"microsoft/2D-TAN" ["l"="31.663,33.832"]
"LisaAnne/LocalizingMoments" ["l"="31.627,33.86"]
"lelan-li/SSAH" ["l"="31.909,33.756"]
"gujiuxiang/Multimodal_Retrieval.pytorch" ["l"="31.906,33.743"]
"zyfsa/cvpr2018-SSAH" ["l"="31.932,33.761"]
"WendellGul/DCMH" ["l"="31.936,33.746"]
"jiangqy/DCMH-CVPR2017" ["l"="31.924,33.75"]
"zhongzhh8/Cross-Modal-Retrieval" ["l"="31.896,33.731"]
"PKU-ICST-MIPL/UGACH_AAAI2018" ["l"="31.953,33.758"]
"yalesong/pvse" ["l"="31.876,33.751"]
"penghu-cs/DSCMR" ["l"="31.89,33.741"]
"sunpeng981712364/ACMR_demo" ["l"="31.888,33.761"]
"lelan-li/DSEH" ["l"="31.964,33.777"]
"WendellGul/AGAH" ["l"="31.952,33.742"]
"zzs1994/DJSRH" ["l"="31.93,33.735"]
"WangGodder/deep-cross-modal-hashing" ["l"="31.914,33.734"]
"PKU-ICST-MIPL/SCHGAN_TCYB2018" ["l"="31.94,33.77"]
"ammesatyajit/VideoBERT" ["l"="31.624,33.771"]
"MDSKUL/MasterProject" ["l"="31.587,33.755"]
"CrossmodalGroup/GSMN" ["l"="31.835,33.729"]
"CrossmodalGroup/BFAN" ["l"="31.854,33.692"]
"KunpengLi1994/VSRN" ["l"="31.847,33.738"]
"ZihaoWang-CV/CAMP_iccv19" ["l"="31.874,33.72"]
"Paranioar/SGRAF" ["l"="31.842,33.708"]
"BruceW91/CVSE" ["l"="31.846,33.721"]
"sunnychencool/AOQ" ["l"="31.864,33.705"]
"HuiChen24/IMRAM" ["l"="31.86,33.722"]
"kuanghuei/SCAN" ["l"="31.869,33.734"]
"Paranioar/Cross-modal_Retrieval_Tutorial" ["l"="31.829,33.742"]
"kywen1119/DSRAN" ["l"="31.854,33.711"]
"woodfrog/vse_infty" ["l"="31.831,33.715"]
"fartashf/vsepp" ["l"="31.854,33.755"]
"HaoYang0123/Position-Focused-Attention-Network" ["l"="31.843,33.693"]
"Wangt-CN/MTFN-RR-PyTorch-Code" ["l"="31.874,33.704"]
"linjieli222/VQA_ReGAT" ["l"="31.618,34.538"]
"CrossmodalGroup/NAAF" ["l"="31.83,33.677"]
"CrossmodalGroup/CMCAN" ["l"="31.817,33.689"]
"fortunechen/paper-reading_CrossModelGroup-USTC" ["l"="31.818,33.656"]
"WangFei-2019/Image-text-Retrieval" ["l"="31.823,33.643"]
"peteanderson80/bottom-up-attention" ["l"="31.583,34.573"]
"jiasenlu/vilbert_beta" ["l"="31.642,34.607"]
"UT-Austin-RPL/Ditto" ["l"="31.48,33.645"]
"Steve-Tod/utils3d" ["l"="31.472,33.631"]
"UT-Austin-RPL/FORGE" ["l"="31.524,33.672"]
"daerduoCarey/where2act" ["l"="31.446,33.627"]
"danieljf24/text2image" ["l"="31.854,33.82"]
"LgQu/DIME" ["l"="31.818,33.715"]
"ChenJoya/2dtan" ["l"="31.645,33.828"]
"IsaacChanghau/VSLNet" ["l"="31.653,33.851"]
"MCG-NJU/MMN" ["l"="31.69,33.828"]
"yawenzeng/Awesome-Cross-Modal-Video-Moment-Retrieval" ["l"="31.664,33.814"]
"JJBOY/BMN-Boundary-Matching-Network" ["l"="32.38,34.89"]
"hardyqr/Visual-Semantic-Embeddings-an-incomplete-list" ["l"="31.886,33.696"]
"hardyqr/HAL" ["l"="31.866,33.693"]
"LgQu/CAMERA" ["l"="31.823,33.702"]
"mesnico/TERN" ["l"="31.865,33.662"]
"penghu-cs/SDML" ["l"="31.908,33.716"]
"yolo2233/cross-modal-hasing-playground" ["l"="31.926,33.724"]
"SydCaption/SAAT" ["l"="31.758,33.929"]
"vsislab/Controllable_XGating" ["l"="31.781,33.919"]
"hobincar/SGN" ["l"="31.763,33.921"]
"WingsBrokenAngel/delving-deeper-into-the-decoder-for-video-captioning" ["l"="31.763,33.935"]
"WingsBrokenAngel/Semantics-AssistedVideoCaptioning" ["l"="31.759,33.945"]
"yangbang18/Non-Autoregressive-Video-Captioning" ["l"="31.75,33.942"]
"jayleicn/recurrent-transformer" ["l"="31.758,33.893"]
"IsaacChanghau/DL-NLP-Readings" ["l"="31.641,33.815"]
"iwangjian/Paper-Reading" ["l"="32.058,30.073"]
"jayleicn/TVRetrieval" ["l"="31.683,33.86"]
"Alvin-Zeng/Awesome-Temporal-Action-Localization" ["l"="32.37,34.91"]
"Alvin-Zeng/DRN" ["l"="31.62,33.852"]
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" ["l"="32.34,34.912"]
"IsaacChanghau/ReLoCLNet" ["l"="31.679,33.838"]
"salesforce/ALBEF" ["l"="31.703,34.744"]
"KaiyangZhou/CoOp" ["l"="31.718,34.817"]
"chenjoya/2dtan" ["l"="31.561,33.815"]
"sangminwoo/Explore-And-Match" ["l"="31.603,33.819"]
"r-cui/ViGA" ["l"="31.605,33.795"]
"TencentARC/UMT" ["l"="31.687,33.818"]
"Xun-Yang/Causal_Video_Moment_Retrieval" ["l"="31.627,33.788"]
"Soldelli/Awesome-Temporal-Language-Grounding-in-Videos" ["l"="31.619,33.804"]
"VALUE-Leaderboard/StarterCode" ["l"="31.695,33.805"]
"VALUE-Leaderboard/DataRelease" ["l"="31.652,33.781"]
"VALUE-Leaderboard/EvaluationTools" ["l"="31.664,33.785"]
"VisionLearningGroup/caption-guided-saliency" ["l"="31.842,34.01"]
"mynlp/cst_captioning" ["l"="31.817,33.963"]
"jssprz/visual_syntactic_embedding_video_captioning" ["l"="31.746,33.928"]
"ych133/How2R-and-How2QA" ["l"="31.711,33.864"]
"jimmy646/violin" ["l"="31.708,33.88"]
"linjieli222/HERO_Video_Feature_Extractor" ["l"="31.698,33.843"]
"jayleicn/TVQAplus" ["l"="31.666,33.934"]
"microsoft/SwinBERT" ["l"="31.731,33.854"]
"ttengwang/PDVC" ["l"="31.75,33.882"]
"MarcusNerva/HMN" ["l"="31.726,33.883"]
"forence/Awesome-Visual-Captioning" ["l"="31.564,34.63"]
"syuqings/video-paragraph" ["l"="31.747,33.908"]
"v-iashin/MDVC" ["l"="31.766,33.881"]
"ttengwang/dense-video-captioning-pytorch" ["l"="31.795,33.882"]
"zs-zhong/DJSRH" ["l"="32.033,33.775"]
"KaiserLew/JDSH" ["l"="32.011,33.768"]
"Soldelli/MAD" ["l"="31.591,33.807"]
"TengdaHan/AutoAD" ["l"="31.555,33.795"]
"Soldelli/VLG-Net" ["l"="31.581,33.835"]
"dhg-wei/DeCap" ["l"="31.696,33.69"]
"NNNNAI/Ego4d_NLQ_2022_1st_Place_Solution" ["l"="31.688,33.677"]
"liudaizong/CSMGAN" ["l"="31.608,33.847"]
"tanghaoyu258/ACRM-for-moment-retrieval" ["l"="31.619,33.823"]
"pansanity666/INO_VOS" ["l"="31.706,33.672"]
"sxl142/GLoT" ["l"="31.71,33.685"]
"ioanacroi/qb-norm" ["l"="31.734,33.722"]
"CrossmodalGroup/SSL-VQA" ["l"="31.849,33.652"]
"anosorae/IRRA" ["l"="31.98,33.623"]
"OrangeYHChen/TIPCB" ["l"="31.98,33.649"]
"zifyloo/SSAN" ["l"="32,33.622"]
"YingZhangDUT/Cross-Modal-Projection-Learning" ["l"="31.955,33.701"]
"caoyue10/aaai17-cdq" ["l"="32.954,34.24"]
"jiangqy/DPSH-pytorch" ["l"="32.958,34.306"]
"Xuanmeng-Zhang/MVCGAN" ["l"="31.691,33.651"]
"kuangliu/pytorch-groupnorm" ["l"="32.126,33.883"]
"taokong/group_normalization" ["l"="32.103,33.877"]
"tuyunbin/Video-Description-with-Spatial-Temporal-Attention" ["l"="31.834,33.931"]
"v-iashin/video_features" ["l"="31.752,33.855"]
"xyzforever/BEVT" ["l"="31.633,33.73"]
"ruiwang2021/mvd" ["l"="31.607,33.719"]
"v-iashin/BMT" ["l"="31.779,33.879"]
"alexandrosstergiou/SoftPool" ["l"="31.778,33.708"]
"sebgao/LIP" ["l"="31.794,33.76"]
"alexandrosstergiou/adaPool" ["l"="31.773,33.669"]
"rentainhe/pytorch-pooling" ["l"="31.767,33.684"]
"wofmanaf/SA-Net" ["l"="31.582,37.233"]
"microsoft/XPretrain" ["l"="31.712,33.756"]
"microsoft/VideoX" ["l"="32.375,35.078"]
"zengyan-97/X-VLM" ["l"="31.745,34.728"]
"starxliu/MTFH" ["l"="31.983,33.741"]
"penghu-cs/MAN" ["l"="31.908,33.705"]
"penghu-cs/MRL" ["l"="31.925,33.711"]
"kelvinxu/arctic-captions" ["l"="31.538,34.527"]
"emansim/text2image" ["l"="33.732,32.492"]
"s-gupta/visual-concepts" ["l"="31.447,34.6"]
"ryankiros/skip-thoughts" ["l"="30.01,32.741"]
"cesc-park/CRCN" ["l"="31.949,33.807"]
"LuoweiZhou/e2e-gLSTM-sc" ["l"="31.428,34.591"]
"awentzonline/keras-visual-semantic-embedding" ["l"="31.926,33.795"]
"facebook/eyescream" ["l"="33.666,32.473"]
"yytzsy/ABLR_code" ["l"="31.649,33.868"]
"Huntersxsx/RaNet" ["l"="31.684,33.878"]
"haojc/ShufflingVideosForTSG" ["l"="31.703,33.854"]
"yytzsy/grounding_changing_distribution" ["l"="31.656,33.824"]
"ruiyan1995/Region_Learner" ["l"="31.671,33.74"]
"FingerRec/OA-Transformer" ["l"="31.68,33.722"]
"rowanz/merlot" ["l"="31.678,33.79"]
"rowanz/merlot_reserve" ["l"="31.643,33.764"]
"antoyang/just-ask" ["l"="31.647,33.88"]
"MikeWangWZHL/VidIL" ["l"="32.339,35.11"]
"microsoft/LAVENDER" ["l"="31.655,33.748"]
"yyuanad/Pytorch_C3D_Feature_Extractor" ["l"="31.603,33.86"]
"JaywongWang/I3D-Feature-Extractor" ["l"="31.557,33.87"]
"JaywongWang/SST-Tensorflow" ["l"="32.387,34.79"]
"DavideA/c3d-pytorch" ["l"="32.507,34.864"]
"MCG-NJU/BCN" ["l"="32.271,34.795"]
"MCG-NJU/CPD-Video" ["l"="32.387,35.026"]
"MCG-NJU/AdaMixer" ["l"="31.728,35.031"]
"YunseokJANG/tgif-qa" ["l"="31.639,33.975"]
"fanchenyou/HME-VideoQA" ["l"="31.645,33.958"]
"thaolmk54/hcrn-videoqa" ["l"="31.629,33.945"]
"MILVLG/activitynet-qa" ["l"="31.617,33.982"]
"raingo/TGIF-Release" ["l"="31.639,34.001"]
"xudejing/video-question-answering" ["l"="31.631,33.963"]
"jayleicn/TVQA" ["l"="31.659,33.952"]
"xudejing/VideoQA" ["l"="31.604,34.01"]
"SunDoge/L-GCN" ["l"="31.615,33.971"]
"makarandtapaswi/MovieQA_CVPR2016" ["l"="31.631,34.025"]
"noagarcia/knowit-rock" ["l"="31.612,33.958"]
"facebookresearch/Ego4d" ["l"="31.624,33.682"]
"EGO4D/hands-and-objects" ["l"="31.603,33.666"]
"EGO4D/forecasting" ["l"="35.698,35.637"]
"EGO4D/episodic-memory" ["l"="31.647,33.679"]
"LuoweiZhou/anet2016-cuhk-feature" ["l"="31.769,33.908"]
"XgDuan/WSDEC" ["l"="31.736,33.899"]
"facebookresearch/ActivityNet-Entities" ["l"="31.72,33.929"]
"zhegan27/Semantic_Compositional_Nets" ["l"="31.421,34.604"]
"VisionLearningGroup/Text-to-Clip_Retrieval" ["l"="31.623,33.888"]
"MichiganCOG/A2CL-PT" ["l"="32.32,34.868"]
"amanchadha/iPerceive" ["l"="31.647,33.94"]
"StanfordVL/STGraph" ["l"="31.762,33.973"]
"vsubhashini/caption-eval" ["l"="31.888,33.953"]
"jeffdonahue/caffe" ["l"="26.807,34.205"]
"LisaAnne/lisa-caffe-public" ["l"="32.544,34.762"]
"ramakanth-pasunuru/video_captioning_rl" ["l"="31.827,33.955"]
"kimiyoung/review_net" ["l"="31.405,34.585"]
"smallflyingpig/pytorch_video_caption" ["l"="31.9,33.97"]
"Yugnaynehc/banet" ["l"="31.829,34.039"]
"sususushi/reconstruction-network-for-video-captioning" ["l"="31.821,33.988"]
"gujiuxiang/Video_Captioning.pytorch" ["l"="31.826,33.978"]
"yiling2018/saem" ["l"="31.868,33.677"]
"ShuangLI59/Person-Search-with-Natural-Language-Description" ["l"="31.973,33.665"]
"layumi/Image-Text-Embedding" ["l"="31.944,33.686"]
"Jarr0d/ViTAA" ["l"="31.953,33.652"]
"BrandonHanx/TextReID" ["l"="31.995,33.653"]
"TencentYoutuResearch/PersonReID-NAFS" ["l"="32.013,33.64"]
"labyrinth7x/Deep-Cross-Modal-Projection-Learning-for-Image-Text-Matching" ["l"="31.977,33.687"]
"TheShadow29/vognet-pytorch" ["l"="31.629,33.908"]
"zfchenUnique/WSSTG" ["l"="31.589,33.913"]
"Guaranteer/VidSTG-Dataset" ["l"="31.569,33.92"]
"InterDigitalInc/DialogSummary-VideoQA" ["l"="31.623,33.922"]
"antoyang/TubeDETR" ["l"="31.671,33.848"]
"doc-doc/NExT-QA" ["l"="31.58,33.94"]
"Jumpin2/HGA" ["l"="31.601,33.946"]
"SUTDCV/SUTD-TrafficQA" ["l"="31.596,33.961"]
"PKU-ICST-MIPL/CCL_TMM2018" ["l"="32.043,33.744"]
"PKU-ICST-MIPL/SSDH_TCSVT2017" ["l"="32.004,33.751"]
"PKU-ICST-MIPL/CMDN_IJCAI2016" ["l"="32.071,33.741"]
"huhengtong/UKD_CVPR2020" ["l"="31.981,33.761"]
"voriarty/Dual-path-CNN-with-Max-Gated-block-for-Text-Based-Person-Re-identification" ["l"="31.959,33.633"]
"Jarr0d/Human-Parsing-Network" ["l"="31.944,33.631"]
"TencentYoutuResearch/Ensemble-Grafting" ["l"="32.027,33.631"]
"TencentYoutuResearch/PersonReID-VAAL" ["l"="32.037,33.633"]
"TencentYoutuResearch/PersonReID-ACT" ["l"="32.027,33.624"]
"TencentYoutuResearch/PersonReID-TSF" ["l"="32.037,33.625"]
"TencentYoutuResearch/PedestrianDetection-NohNMS" ["l"="32.04,33.642"]
"TencentYoutuResearch/PersonReID-Pyramid" ["l"="32.047,33.633"]
"TencentYoutuResearch/SelfSupervisedLearning-DSM" ["l"="32.047,33.624"]
"TencentYoutuResearch/PersonReID-CACENET" ["l"="32.035,33.618"]
"TencentYoutuResearch/Pruning-PFF" ["l"="32.029,33.639"]
"lwwang/Two_branch_network" ["l"="32.003,33.682"]
"Yu-Wu/Exploit-Unknown-Gradually" ["l"="33.049,36.812"]
"seankim902/imageQA" ["l"="31.904,33.991"]
"jazzsaxmafia/show_attend_and_tell.tensorflow" ["l"="31.5,34.5"]
"szq0214/MSR-VTT-Challenge" ["l"="31.801,33.961"]
"doc-doc/HQGA" ["l"="31.564,33.951"]
"sail-sg/VGT" ["l"="31.556,33.96"]
"doc-doc/NExT-OE" ["l"="31.555,33.941"]
"yl3800/IGV" ["l"="31.54,33.951"]
"antoine77340/Mixture-of-Embedding-Experts" ["l"="31.765,33.817"]
"yj-yu/lsmdc" ["l"="31.707,33.897"]
"sail-sg/ptp" ["l"="31.785,34.684"]
"piergiaj/pytorch-i3d" ["l"="32.495,34.91"]
"ZhiyinShao-H/LGUR" ["l"="32.016,33.603"]
"NjtechCVLab/RSTPReid-Dataset" ["l"="31.993,33.601"]
"Suo-Wei/SRCF" ["l"="32.007,33.592"]
"Chuhanxx/Temporal_Query_Networks" ["l"="32.347,35.024"]
"Chuhanxx/Object_Centric_Video_Transformer" ["l"="31.684,33.762"]
"ju-chen/Efficient-Prompt" ["l"="32.342,35.048"]
"kylemin/S3D" ["l"="32.39,34.812"]
"moabitcoin/ig65m-pytorch" ["l"="32.497,34.951"]
"cyh-sj/CGMN" ["l"="31.83,33.691"]
"zxJohnFly/GCN" ["l"="31.987,33.785"]
"pochih/Video-Cap" ["l"="31.86,33.908"]
"Shreyz-max/Video-Captioning" ["l"="31.881,33.916"]
"lixiangpengcs/Spatial-Temporal-Adaptive-Attention-for-Video-Captioning" ["l"="31.849,33.916"]
"ttengwang/ESGN" ["l"="31.831,33.873"]
"ttengwang/ECHR" ["l"="31.825,33.884"]
"songdony/gin_go" ["l"="21.79,27.235"]
"fullStack-feed/joyful-house" ["l"="21.813,27.276"]
"Bitcoin-Classic-BGH/Bitcoin-Classic" ["l"="21.814,27.304"]
"zhuxingwan/SynsetsTools" ["l"="21.802,27.281"]
"lingjye/Flutter-Learning" ["l"="21.761,27.221"]
"emmeair/go-canal" ["l"="21.806,27.265"]
"wensiyuanseven/light-virtual-list" ["l"="21.817,27.365"]
"IAIAE/estime" ["l"="21.801,27.228"]
"BBLLMYD/netty-stroll" ["l"="21.807,27.289"]
"ZhangWei-KUMO/react-dynamic-vector-icons" ["l"="21.811,27.185"]
"rikochyou/jsonp-good" ["l"="21.774,27.234"]
"Atmegal/DGCPN" ["l"="32.048,33.772"]
"idejie/DSAH" ["l"="32.072,33.774"]
"jy0205/STCAT" ["l"="31.666,33.882"]
"escorciav/daps" ["l"="32.402,34.788"]
"zhaoyue-zephyrus/TeSTra" ["l"="31.555,33.671"]
"amazon-science/long-short-term-transformer" ["l"="31.54,33.653"]
"BryanPlummer/two_branch_networks" ["l"="32.035,33.682"]
"houzhijian/CONQUER" ["l"="31.691,33.852"]
"klauscc/VindLU" ["l"="32.279,35.033"]
"LuoweiZhou/densecap" ["l"="31.695,33.915"]
"mesnico/TERAN" ["l"="31.877,33.647"]
"facebookresearch/LaViLa" ["l"="31.583,33.701"]
"UT-Austin-RPL/VIOLA" ["l"="31.55,33.695"]
"jozhang97/DETA" ["l"="31.757,35.02"]
"shyamal-b/sst" ["l"="32.41,34.8"]
"zhangweifeng1218/Text-based-Person-Search" ["l"="32.015,33.576"]
"xuehy/videoqa" ["l"="31.589,34.025"]
"makarandtapaswi/MovieQA_benchmark" ["l"="31.623,34.051"]
"Sid2697/awesome-egocentric-vision" ["l"="31.627,33.662"]
"EgocentricVision/EgocentricVision" ["l"="31.611,33.631"]
"mayu-ot/hidden-challenges-MR" ["l"="31.58,33.865"]
"tzhhhh123/HC-STVG" ["l"="31.542,33.922"]
"OpenGVLab/ego4d-eccv2022-solutions" ["l"="32.263,35.032"]
"ChrisAllenMing/Cross_Category_Video_Highlight" ["l"="31.664,33.8"]
"yeliudev/nncore" ["l"="31.652,33.799"]
"Huntersxsx/TSGV-Learning-List" ["l"="31.588,33.848"]
"aliensunmin/DomainSpecificHighlight" ["l"="31.401,42.817"]
"jayleicn/mTVRetrieval" ["l"="31.664,33.895"]
"escorciav/moments-retrieval-page" ["l"="31.682,33.893"]
"dingli93/weak_supervised_video_moment" ["l"="31.663,33.87"]
"zfchenUnique/VID-Sentence" ["l"="31.564,33.909"]
"xiaoneil/LPNet" ["l"="31.676,33.904"]
"forwchen/HVTG" ["l"="31.567,33.849"]
"facebookresearch/vq2d_cvpr" ["l"="31.647,33.651"]
"yl3800/EIGV" ["l"="31.517,33.958"]
"noagarcia/ROLL-VideoQA" ["l"="31.593,33.973"]
"VRU-NExT/VideoQA" ["l"="31.533,33.976"]
"daerduoCarey/o2oafford" ["l"="31.422,33.613"]
"FreeformRobotics/Divide-and-Co-training" ["l"="31.712,33.653"]
"EgocentricVision/RNA-TTA" ["l"="31.596,33.618"]
"EgocentricVision/N-EPIC-Kitchens" ["l"="31.608,33.612"]
"evelinehong/FixIt" ["l"="31.403,33.602"]
"PKU-ICST-MIPL/JRL_TCSVT2014" ["l"="32.091,33.739"]
"elleryqueenhomels/Neural-Style-Transfer-Papers" ["l"="31.868,33.827"]
}