digraph G {
"lichengunc/MAttNet" -> "lichengunc/refer"
"lichengunc/MAttNet" -> "sibeiyang/sgmn"
"lichengunc/MAttNet" -> "luogen1996/MCN"
"lichengunc/MAttNet" -> "zyang-ur/ReSC"
"lichengunc/MAttNet" -> "zyang-ur/onestage_grounding"
"lichengunc/MAttNet" -> "lichengunc/speaker_listener_reinforcer"
"lichengunc/MAttNet" -> "TheShadow29/awesome-grounding"
"lichengunc/MAttNet" -> "ronghanghu/lcgn" ["e"=1]
"lichengunc/MAttNet" -> "lichengunc/mask-faster-rcnn"
"lichengunc/MAttNet" -> "mjhucla/Google_Refexp_toolbox"
"lichengunc/MAttNet" -> "yuleiniu/vc"
"lichengunc/MAttNet" -> "youngfly11/LCMCG-PyTorch"
"lichengunc/MAttNet" -> "xh-liu/CM-Erase-REG"
"lichengunc/MAttNet" -> "rowanz/neural-motifs" ["e"=1]
"lichengunc/MAttNet" -> "arunmallya/piggyback" ["e"=1]
"LeapLabTHU/ACmix" -> "LeapLabTHU/DAT" ["e"=1]
"LeapLabTHU/ACmix" -> "LeapLabTHU/AdaFocusV2"
"LeapLabTHU/ACmix" -> "LeapLabTHU/DAT-Jittor"
"LeapLabTHU/ACmix" -> "OSVAI/ODConv" ["e"=1]
"LeapLabTHU/ACmix" -> "LeapLabTHU/EfficientTrain"
"LeapLabTHU/ACmix" -> "OliverRensu/Shunted-Transformer" ["e"=1]
"LeapLabTHU/ACmix" -> "yangle15/RANet-pytorch"
"LeapLabTHU/ACmix" -> "murufeng/EPSANet" ["e"=1]
"LeapLabTHU/ACmix" -> "LeapLabTHU/Pseudo-Q"
"loeweX/Greedy_InfoMax" -> "anokland/local-loss"
"loeweX/Greedy_InfoMax" -> "blackfeather-wang/InfoPro-Pytorch"
"mttr2021/MTTR" -> "wjn922/ReferFormer"
"mttr2021/MTTR" -> "JerryX1110/awesome-rvos"
"mttr2021/MTTR" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"mttr2021/MTTR" -> "yz93/LAVT-RIS"
"mttr2021/MTTR" -> "hkchengrex/STCN" ["e"=1]
"mttr2021/MTTR" -> "henghuiding/Vision-Language-Transformer"
"mttr2021/MTTR" -> "wjf5203/SeqFormer" ["e"=1]
"mttr2021/MTTR" -> "ashkamath/mdetr" ["e"=1]
"mttr2021/MTTR" -> "DerrickWang005/CRIS.pytorch"
"mttr2021/MTTR" -> "microsoft/GLIP" ["e"=1]
"mttr2021/MTTR" -> "wjf5203/VNext" ["e"=1]
"mttr2021/MTTR" -> "raoyongming/DenseCLIP" ["e"=1]
"mttr2021/MTTR" -> "hkchengrex/XMem" ["e"=1]
"mttr2021/MTTR" -> "hkchengrex/MiVOS" ["e"=1]
"mttr2021/MTTR" -> "microsoft/X-Decoder" ["e"=1]
"taoyang1122/MutualNet" -> "d-li14/SAN"
"taoyang1122/MutualNet" -> "yangle15/RANet-pytorch"
"liruiyu/referseg_rrn" -> "chenxi116/TF-phrasecut-public"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "yz93/LAVT-RIS"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "lichengunc/refer"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "wjn922/ReferFormer"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "zichengsaber/LAVT-pytorch"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "DerrickWang005/CRIS.pytorch"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "henghuiding/Vision-Language-Transformer"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "JerryX1110/awesome-rvos"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "BCV-Uniandes/DMS"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "luogen1996/MCN"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "spyflying/CMPC-Refseg"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "TheShadow29/awesome-grounding"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "lichengunc/MAttNet"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "sean-zhuh/SeqTR"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "ChenyunWu/PhraseCutDataset"
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "isl-org/lang-seg" ["e"=1]
"yangle15/RANet-pytorch" -> "kalviny/MSDNet-PyTorch"
"yangle15/RANet-pytorch" -> "yangle15/ModelReproduce_Pytorch"
"yangle15/RANet-pytorch" -> "LeapLabTHU/DAT-Jittor"
"yangle15/RANet-pytorch" -> "blackfeather-wang/GFNet-Pytorch"
"yangle15/RANet-pytorch" -> "LeapLabTHU/L2W-DEN"
"yangle15/RANet-pytorch" -> "LeapLabTHU/AdaFocusV2"
"yangle15/RANet-pytorch" -> "blackfeather-wang/InfoPro-Pytorch"
"yangle15/RANet-pytorch" -> "jianghaojun/CondenseNetV2"
"yangle15/RANet-pytorch" -> "yizenghan/sarNet"
"blackfeather-wang/GFNet-Pytorch" -> "LeapLabTHU/AdaFocusV2"
"blackfeather-wang/GFNet-Pytorch" -> "LeapLabTHU/DAT-Jittor"
"blackfeather-wang/GFNet-Pytorch" -> "yangle15/RANet-pytorch"
"blackfeather-wang/GFNet-Pytorch" -> "blackfeather-wang/InfoPro-Pytorch"
"blackfeather-wang/GFNet-Pytorch" -> "yangle15/ModelReproduce_Pytorch"
"blackfeather-wang/GFNet-Pytorch" -> "blackfeather-wang/Dynamic-Vision-Transformer"
"blackfeather-wang/GFNet-Pytorch" -> "jianghaojun/CondenseNetV2"
"blackfeather-wang/GFNet-Pytorch" -> "blackfeather-wang/AdaFocus"
"blackfeather-wang/GFNet-Pytorch" -> "LeapLabTHU/EfficientTrain"
"blackfeather-wang/GFNet-Pytorch" -> "kalviny/MSDNet-PyTorch"
"blackfeather-wang/GFNet-Pytorch" -> "LeapLabTHU/CheckpointKD"
"blackfeather-wang/GFNet-Pytorch" -> "LeapLabTHU/L2W-DEN"
"blackfeather-wang/GFNet-Pytorch" -> "LeapLabTHU/Cross-Modal-Adapter"
"blackfeather-wang/GFNet-Pytorch" -> "LeapLabTHU/Pseudo-Q"
"blackfeather-wang/InfoPro-Pytorch" -> "yangle15/ModelReproduce_Pytorch"
"blackfeather-wang/InfoPro-Pytorch" -> "LeapLabTHU/DAT-Jittor"
"blackfeather-wang/InfoPro-Pytorch" -> "LeapLabTHU/L2W-DEN"
"yz93/LAVT-RIS" -> "zichengsaber/LAVT-pytorch"
"yz93/LAVT-RIS" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"yz93/LAVT-RIS" -> "DerrickWang005/CRIS.pytorch"
"yz93/LAVT-RIS" -> "henghuiding/Vision-Language-Transformer"
"yz93/LAVT-RIS" -> "wjn922/ReferFormer"
"yz93/LAVT-RIS" -> "sean-zhuh/SeqTR"
"BCV-Uniandes/DMS" -> "liruiyu/referseg_rrn"
"BCV-Uniandes/DMS" -> "wenz116/lang2seg"
"BCV-Uniandes/DMS" -> "spyflying/CMPC-Refseg"
"spyflying/CMPC-Refseg" -> "liruiyu/referseg_rrn"
"spyflying/CMPC-Refseg" -> "lwye/CMSA-Net"
"spyflying/CMPC-Refseg" -> "fengguang94/CVPR2020-BRINet"
"kunglab/branchynet" -> "kunglab/ddnn"
"kunglab/branchynet" -> "librahfacebook/BranchyNet_chainer"
"kunglab/branchynet" -> "biggsbenjamin/earlyexitnet"
"TheShadow29/awesome-grounding" -> "ashkamath/mdetr" ["e"=1]
"TheShadow29/awesome-grounding" -> "lichengunc/refer"
"TheShadow29/awesome-grounding" -> "lichengunc/MAttNet"
"TheShadow29/awesome-grounding" -> "yuewang-cuhk/awesome-vision-language-pretraining-papers" ["e"=1]
"TheShadow29/awesome-grounding" -> "jokieleung/awesome-visual-question-answering" ["e"=1]
"TheShadow29/awesome-grounding" -> "djiajunustc/TransVG"
"TheShadow29/awesome-grounding" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"TheShadow29/awesome-grounding" -> "microsoft/2D-TAN" ["e"=1]
"TheShadow29/awesome-grounding" -> "zyang-ur/onestage_grounding"
"TheShadow29/awesome-grounding" -> "WuJie1010/Awesome-Temporally-Language-Grounding" ["e"=1]
"TheShadow29/awesome-grounding" -> "JonghwanMun/LGI4temporalgrounding" ["e"=1]
"TheShadow29/awesome-grounding" -> "facebookresearch/grounded-video-description" ["e"=1]
"TheShadow29/awesome-grounding" -> "SCZwangxiao/Temporal-Language-Grounding-in-videos" ["e"=1]
"TheShadow29/awesome-grounding" -> "iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" ["e"=1]
"TheShadow29/awesome-grounding" -> "microsoft/GLIP" ["e"=1]
"djiajunustc/TransVG" -> "nku-shengzheliu/Pytorch-TransVG"
"djiajunustc/TransVG" -> "zyang-ur/ReSC"
"djiajunustc/TransVG" -> "djiajunustc/H-23D_R-CNN"
"djiajunustc/TransVG" -> "ubc-vision/RefTR"
"djiajunustc/TransVG" -> "yangli18/VLTVG"
"djiajunustc/TransVG" -> "LeapLabTHU/Pseudo-Q"
"lichengunc/refer" -> "lichengunc/MAttNet"
"lichengunc/refer" -> "mjhucla/Google_Refexp_toolbox"
"lichengunc/refer" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"lichengunc/refer" -> "TheShadow29/awesome-grounding"
"lichengunc/refer" -> "zyang-ur/onestage_grounding"
"lichengunc/refer" -> "BryanPlummer/flickr30k_entities"
"lichengunc/refer" -> "djiajunustc/TransVG"
"lichengunc/refer" -> "zyang-ur/ReSC"
"lichengunc/refer" -> "yz93/LAVT-RIS"
"lichengunc/refer" -> "sean-zhuh/SeqTR"
"lichengunc/refer" -> "zichengsaber/LAVT-pytorch"
"lichengunc/refer" -> "henghuiding/Vision-Language-Transformer"
"lichengunc/refer" -> "BCV-Uniandes/DMS"
"lichengunc/refer" -> "DerrickWang005/CRIS.pytorch"
"lichengunc/refer" -> "spyflying/CMPC-Refseg"
"LeapLabTHU/Pseudo-Q" -> "LeapLabTHU/DAT-Jittor"
"LeapLabTHU/Pseudo-Q" -> "LeapLabTHU/AdaFocusV2"
"LeapLabTHU/Pseudo-Q" -> "LeapLabTHU/EfficientTrain"
"LeapLabTHU/Pseudo-Q" -> "sean-zhuh/SeqTR"
"LeapLabTHU/Pseudo-Q" -> "jianghaojun/CondenseNetV2"
"LeapLabTHU/Pseudo-Q" -> "LeapLabTHU/L2W-DEN"
"LeapLabTHU/Pseudo-Q" -> "yangli18/VLTVG"
"LeapLabTHU/Pseudo-Q" -> "LeapLabTHU/Model-Assembling"
"LeapLabTHU/Pseudo-Q" -> "djiajunustc/TransVG"
"LeapLabTHU/Pseudo-Q" -> "LeapLabTHU/Cross-Modal-Adapter"
"mjhucla/Google_Refexp_toolbox" -> "lichengunc/refer"
"mjhucla/Google_Refexp_toolbox" -> "lichengunc/MAttNet"
"mjhucla/Google_Refexp_toolbox" -> "ronghanghu/cmn" ["e"=1]
"lichengunc/mask-faster-rcnn" -> "lichengunc/speaker_listener_reinforcer"
"luogen1996/MCN" -> "lichengunc/MAttNet"
"luogen1996/MCN" -> "spyflying/CMPC-Refseg"
"luogen1996/MCN" -> "luogen1996/Real-time-Global-Inference-Network"
"luogen1996/MCN" -> "zyang-ur/ReSC"
"luogen1996/MCN" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"luogen1996/MCN" -> "xh-liu/CM-Erase-REG"
"luogen1996/MCN" -> "sibeiyang/sgmn"
"luogen1996/MCN" -> "ChenyunWu/PhraseCutDataset"
"zyang-ur/ReSC" -> "zyang-ur/onestage_grounding"
"zyang-ur/ReSC" -> "ChopinSharp/ref-nms"
"zyang-ur/ReSC" -> "svip-lab/LBYLNet"
"zyang-ur/ReSC" -> "BigRedT/info-ground"
"zyang-ur/ReSC" -> "daqingliu/awesome-rec"
"zyang-ur/ReSC" -> "qinzzz/Multimodal-Alignment-Framework"
"zyang-ur/ReSC" -> "nku-shengzheliu/Pytorch-TransVG"
"zyang-ur/onestage_grounding" -> "zyang-ur/ReSC"
"zyang-ur/onestage_grounding" -> "nku-shengzheliu/Pytorch-TransVG"
"zyang-ur/onestage_grounding" -> "ChopinSharp/ref-nms"
"zyang-ur/onestage_grounding" -> "svip-lab/LBYLNet"
"zyang-ur/onestage_grounding" -> "lichengunc/MAttNet"
"zyang-ur/onestage_grounding" -> "lichengunc/refer"
"BryanPlummer/flickr30k_entities" -> "lichengunc/refer"
"BryanPlummer/flickr30k_entities" -> "zyang-ur/ReSC"
"blackfeather-wang/AdaFocus" -> "LeapLabTHU/AdaFocusV2"
"blackfeather-wang/AdaFocus" -> "IBM/AdaMML"
"blackfeather-wang/AdaFocus" -> "mengyuest/AR-Net"
"jianghaojun/CondenseNetV2" -> "LeapLabTHU/DAT-Jittor"
"jianghaojun/CondenseNetV2" -> "yangle15/ModelReproduce_Pytorch"
"jianghaojun/CondenseNetV2" -> "LeapLabTHU/EfficientTrain"
"jianghaojun/CondenseNetV2" -> "LeapLabTHU/L2W-DEN"
"jianghaojun/CondenseNetV2" -> "LeapLabTHU/AdaFocusV2"
"jianghaojun/CondenseNetV2" -> "LeapLabTHU/Model-Assembling"
"jianghaojun/CondenseNetV2" -> "yizenghan/sarNet"
"kalviny/MSDNet-PyTorch" -> "gaohuang/MSDNet" ["e"=1]
"kalviny/MSDNet-PyTorch" -> "yangle15/RANet-pytorch"
"kalviny/MSDNet-PyTorch" -> "kalviny/IMTA"
"kalviny/MSDNet-PyTorch" -> "blackfeather-wang/GFNet-Pytorch"
"kalviny/MSDNet-PyTorch" -> "ucbdrive/skipnet"
"kalviny/MSDNet-PyTorch" -> "thomasverelst/dynconv"
"ucbdrive/skipnet" -> "andreasveit/convnet-aig"
"ucbdrive/skipnet" -> "Tushar-N/blockdrop"
"ucbdrive/skipnet" -> "kalviny/MSDNet-PyTorch"
"ucbdrive/skipnet" -> "mfigurnov/sact"
"ucbdrive/skipnet" -> "changlin31/DS-Net" ["e"=1]
"ucbdrive/skipnet" -> "cornell-zhang/dnn-gating" ["e"=1]
"djiajunustc/H-23D_R-CNN" -> "caiqi/Cascasde-3D"
"thomasverelst/dynconv" -> "thomasverelst/blockcopy-video-processing-pytorch"
"Tushar-N/blockdrop" -> "ucbdrive/skipnet"
"Tushar-N/blockdrop" -> "mfigurnov/sact"
"yangli18/VLTVG" -> "LukeForeverYoung/QRNet"
"yangli18/VLTVG" -> "ubc-vision/RefTR"
"yangli18/VLTVG" -> "zyang-ur/ReSC"
"mfigurnov/sact" -> "Tushar-N/blockdrop"
"mfigurnov/sact" -> "ucbdrive/skipnet"
"mfigurnov/sact" -> "thomasverelst/dynconv"
"mfigurnov/sact" -> "kunglab/branchynet"
"mfigurnov/sact" -> "uber-research/sbnet"
"mfigurnov/sact" -> "kalviny/MSDNet-PyTorch"
"mfigurnov/sact" -> "andreasveit/convnet-aig"
"mfigurnov/sact" -> "mfigurnov/perforated-cnn-caffe"
"LeapLabTHU/Model-Assembling" -> "LeapLabTHU/EfficientTrain"
"LeapLabTHU/Model-Assembling" -> "LeapLabTHU/DAT-Jittor"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "LeapLabTHU/AdaFocusV2"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "LeapLabTHU/DAT-Jittor"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "jianghaojun/CondenseNetV2"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "raoyongming/DynamicViT" ["e"=1]
"blackfeather-wang/Dynamic-Vision-Transformer" -> "blackfeather-wang/GFNet-Pytorch"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "LeapLabTHU/Pseudo-Q"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "yangle15/RANet-pytorch"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "yangle15/ModelReproduce_Pytorch"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "LeapLabTHU/L2W-DEN"
"blackfeather-wang/Dynamic-Vision-Transformer" -> "nnizhang/VST" ["e"=1]
"blackfeather-wang/Dynamic-Vision-Transformer" -> "LeapLabTHU/EfficientTrain"
"wjn922/ReferFormer" -> "JerryX1110/awesome-rvos"
"wjn922/ReferFormer" -> "yz93/LAVT-RIS"
"wjn922/ReferFormer" -> "mttr2021/MTTR"
"wjn922/ReferFormer" -> "henghuiding/Vision-Language-Transformer"
"wjn922/ReferFormer" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"wjn922/ReferFormer" -> "wjf5203/SeqFormer" ["e"=1]
"wjn922/ReferFormer" -> "DerrickWang005/CRIS.pytorch"
"wjn922/ReferFormer" -> "hustvl/TeViT" ["e"=1]
"wjn922/ReferFormer" -> "leonnnop/Locater"
"wjn922/ReferFormer" -> "wjf5203/VNext" ["e"=1]
"wjn922/ReferFormer" -> "zichengsaber/LAVT-pytorch"
"wjn922/ReferFormer" -> "dzh19990407/LBDT"
"wjn922/ReferFormer" -> "skynbe/Refer-Youtube-VOS"
"wjn922/ReferFormer" -> "davisvideochallenge/davis2017-evaluation" ["e"=1]
"wjn922/ReferFormer" -> "miriambellver/refvos"
"JerryX1110/awesome-rvos" -> "dzh19990407/LBDT"
"JerryX1110/awesome-rvos" -> "miriambellver/refvos"
"JerryX1110/awesome-rvos" -> "wjn922/ReferFormer"
"miriambellver/refvos" -> "skynbe/Refer-Youtube-VOS"
"anokland/local-loss" -> "blackfeather-wang/InfoPro-Pytorch"
"anokland/local-loss" -> "eugenium/DGL"
"kunglab/ddnn" -> "kunglab/branchynet"
"librahfacebook/BranchyNet_chainer" -> "biggsbenjamin/earlyexitnet"
"skynbe/Refer-Youtube-VOS" -> "miriambellver/refvos"
"henghuiding/MOSE-api" -> "henghuiding/Vision-Language-Transformer"
"andreasveit/convnet-aig" -> "ucbdrive/skipnet"
"mengyuest/AR-Net" -> "mengyuest/AdaFuse"
"henghuiding/Vision-Language-Transformer" -> "yz93/LAVT-RIS"
"henghuiding/Vision-Language-Transformer" -> "wjn922/ReferFormer"
"henghuiding/Vision-Language-Transformer" -> "henghuiding/MOSE-api"
"henghuiding/Vision-Language-Transformer" -> "zichengsaber/LAVT-pytorch"
"henghuiding/Vision-Language-Transformer" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"henghuiding/Vision-Language-Transformer" -> "DerrickWang005/CRIS.pytorch"
"henghuiding/Vision-Language-Transformer" -> "lichengunc/refer"
"henghuiding/Vision-Language-Transformer" -> "JerryX1110/awesome-rvos"
"LeapLabTHU/ActiveNeRF" -> "yangle15/ModelReproduce_Pytorch"
"LeapLabTHU/ActiveNeRF" -> "LeapLabTHU/DAT-Jittor"
"LeapLabTHU/ActiveNeRF" -> "LeapLabTHU/L2W-DEN"
"LeapLabTHU/AdaFocusV2" -> "LeapLabTHU/DAT-Jittor"
"LeapLabTHU/AdaFocusV2" -> "blackfeather-wang/AdaFocus"
"LeapLabTHU/AdaFocusV2" -> "LeapLabTHU/EfficientTrain"
"LeapLabTHU/AdaFocusV2" -> "LeapLabTHU/L2W-DEN"
"LeapLabTHU/AdaFocusV2" -> "LeapLabTHU/Cross-Modal-Adapter"
"LeapLabTHU/AdaFocusV2" -> "LeapLabTHU/Model-Assembling"
"LeapLabTHU/AdaFocusV2" -> "yangle15/ModelReproduce_Pytorch"
"LeapLabTHU/AdaFocusV2" -> "jianghaojun/CondenseNetV2"
"LeapLabTHU/AdaFocusV2" -> "blackfeather-wang/GFNet-Pytorch"
"LeapLabTHU/Cross-Modal-Adapter" -> "LeapLabTHU/DAT-Jittor"
"LeapLabTHU/DAT-Jittor" -> "LeapLabTHU/EfficientTrain"
"LeapLabTHU/DAT-Jittor" -> "yangle15/ModelReproduce_Pytorch"
"ChenyunWu/PhraseCutDataset" -> "spyflying/CMPC-Refseg"
"sibeiyang/sgmn" -> "lichengunc/MAttNet"
"sibeiyang/sgmn" -> "ronghanghu/lcgn" ["e"=1]
"sibeiyang/sgmn" -> "zyang-ur/ReSC"
"sibeiyang/sgmn" -> "GingL/ARN"
"sibeiyang/sgmn" -> "youngfly11/LCMCG-PyTorch"
"BigRedT/info-ground" -> "zyang-ur/ReSC"
"BigRedT/info-ground" -> "youngfly11/ReIR-WeaklyGrounding.pytorch"
"BigRedT/info-ground" -> "qinzzz/Multimodal-Alignment-Framework"
"BigRedT/info-ground" -> "GingL/ARN"
"BigRedT/info-ground" -> "svip-lab/LBYLNet"
"chenxi116/TF-phrasecut-public" -> "liruiyu/referseg_rrn"
"DerrickWang005/CRIS.pytorch" -> "yz93/LAVT-RIS"
"DerrickWang005/CRIS.pytorch" -> "zichengsaber/LAVT-pytorch"
"DerrickWang005/CRIS.pytorch" -> "MarkMoHR/Awesome-Referring-Image-Segmentation"
"DerrickWang005/CRIS.pytorch" -> "wjn922/ReferFormer"
"DerrickWang005/CRIS.pytorch" -> "allenai/reclip"
"DerrickWang005/CRIS.pytorch" -> "henghuiding/Vision-Language-Transformer"
"DerrickWang005/CRIS.pytorch" -> "JerryX1110/awesome-rvos"
"DerrickWang005/CRIS.pytorch" -> "sean-zhuh/SeqTR"
"DerrickWang005/CRIS.pytorch" -> "lichengunc/refer"
"DerrickWang005/CRIS.pytorch" -> "chongzhou96/MaskCLIP" ["e"=1]
"DerrickWang005/CRIS.pytorch" -> "raoyongming/DenseCLIP" ["e"=1]
"leonnnop/Locater" -> "dzh19990407/LBDT"
"svip-lab/LBYLNet" -> "hbb1/landmarkconv"
"svip-lab/LBYLNet" -> "zyang-ur/ReSC"
"ubc-vision/RefTR" -> "fengguang94/CEFNet"
"lwye/CMSA-Net" -> "spyflying/CMPC-Refseg"
"zichengsaber/LAVT-pytorch" -> "yz93/LAVT-RIS"
"zichengsaber/LAVT-pytorch" -> "DerrickWang005/CRIS.pytorch"
"qinzzz/Multimodal-Alignment-Framework" -> "youngfly11/ReIR-WeaklyGrounding.pytorch"
"LeapLabTHU/EfficientTrain" -> "LeapLabTHU/DAT-Jittor"
"LeapLabTHU/EfficientTrain" -> "yizenghan/sarNet"
"mfigurnov/perforated-cnn-caffe" -> "mfigurnov/perforated-cnn-matconvnet"
"lichengunc/MAttNet" ["l"="31.293,33.934"]
"lichengunc/refer" ["l"="31.252,33.928"]
"sibeiyang/sgmn" ["l"="31.316,33.923"]
"luogen1996/MCN" ["l"="31.275,33.941"]
"zyang-ur/ReSC" ["l"="31.295,33.897"]
"zyang-ur/onestage_grounding" ["l"="31.287,33.912"]
"lichengunc/speaker_listener_reinforcer" ["l"="31.318,33.952"]
"TheShadow29/awesome-grounding" ["l"="31.265,33.915"]
"ronghanghu/lcgn" ["l"="31.554,34.467"]
"lichengunc/mask-faster-rcnn" ["l"="31.327,33.965"]
"mjhucla/Google_Refexp_toolbox" ["l"="31.28,33.953"]
"yuleiniu/vc" ["l"="31.331,33.947"]
"youngfly11/LCMCG-PyTorch" ["l"="31.335,33.934"]
"xh-liu/CM-Erase-REG" ["l"="31.303,33.954"]
"rowanz/neural-motifs" ["l"="31.452,34.541"]
"arunmallya/piggyback" ["l"="28.195,32.675"]
"LeapLabTHU/ACmix" ["l"="31.207,33.802"]
"LeapLabTHU/DAT" ["l"="34.768,35.93"]
"LeapLabTHU/AdaFocusV2" ["l"="31.213,33.786"]
"LeapLabTHU/DAT-Jittor" ["l"="31.223,33.783"]
"OSVAI/ODConv" ["l"="31.415,37.262"]
"LeapLabTHU/EfficientTrain" ["l"="31.229,33.794"]
"OliverRensu/Shunted-Transformer" ["l"="34.801,35.972"]
"yangle15/RANet-pytorch" ["l"="31.236,33.758"]
"murufeng/EPSANet" ["l"="31.567,37.241"]
"LeapLabTHU/Pseudo-Q" ["l"="31.236,33.817"]
"loeweX/Greedy_InfoMax" ["l"="31.168,33.725"]
"anokland/local-loss" ["l"="31.15,33.739"]
"blackfeather-wang/InfoPro-Pytorch" ["l"="31.197,33.754"]
"mttr2021/MTTR" ["l"="31.184,33.956"]
"wjn922/ReferFormer" ["l"="31.19,33.932"]
"JerryX1110/awesome-rvos" ["l"="31.193,33.944"]
"MarkMoHR/Awesome-Referring-Image-Segmentation" ["l"="31.235,33.939"]
"yz93/LAVT-RIS" ["l"="31.208,33.926"]
"hkchengrex/STCN" ["l"="31.849,33.277"]
"henghuiding/Vision-Language-Transformer" ["l"="31.213,33.949"]
"wjf5203/SeqFormer" ["l"="31.825,33.377"]
"ashkamath/mdetr" ["l"="31.697,34.805"]
"DerrickWang005/CRIS.pytorch" ["l"="31.216,33.937"]
"microsoft/GLIP" ["l"="31.754,34.849"]
"wjf5203/VNext" ["l"="31.842,33.341"]
"raoyongming/DenseCLIP" ["l"="31.722,34.855"]
"hkchengrex/XMem" ["l"="31.866,33.313"]
"hkchengrex/MiVOS" ["l"="31.83,33.27"]
"microsoft/X-Decoder" ["l"="31.782,34.908"]
"taoyang1122/MutualNet" ["l"="31.284,33.747"]
"d-li14/SAN" ["l"="31.312,33.741"]
"liruiyu/referseg_rrn" ["l"="31.24,33.997"]
"chenxi116/TF-phrasecut-public" ["l"="31.233,34.016"]
"zichengsaber/LAVT-pytorch" ["l"="31.223,33.924"]
"BCV-Uniandes/DMS" ["l"="31.243,33.974"]
"spyflying/CMPC-Refseg" ["l"="31.26,33.971"]
"sean-zhuh/SeqTR" ["l"="31.224,33.899"]
"ChenyunWu/PhraseCutDataset" ["l"="31.253,33.957"]
"isl-org/lang-seg" ["l"="31.729,34.875"]
"kalviny/MSDNet-PyTorch" ["l"="31.239,33.721"]
"yangle15/ModelReproduce_Pytorch" ["l"="31.213,33.771"]
"blackfeather-wang/GFNet-Pytorch" ["l"="31.223,33.765"]
"LeapLabTHU/L2W-DEN" ["l"="31.22,33.776"]
"jianghaojun/CondenseNetV2" ["l"="31.233,33.785"]
"yizenghan/sarNet" ["l"="31.253,33.779"]
"blackfeather-wang/Dynamic-Vision-Transformer" ["l"="31.243,33.775"]
"blackfeather-wang/AdaFocus" ["l"="31.18,33.782"]
"LeapLabTHU/CheckpointKD" ["l"="31.217,33.743"]
"LeapLabTHU/Cross-Modal-Adapter" ["l"="31.241,33.795"]
"wenz116/lang2seg" ["l"="31.253,34.003"]
"lwye/CMSA-Net" ["l"="31.277,33.986"]
"fengguang94/CVPR2020-BRINet" ["l"="31.269,33.996"]
"kunglab/branchynet" ["l"="31.289,33.626"]
"kunglab/ddnn" ["l"="31.288,33.604"]
"librahfacebook/BranchyNet_chainer" ["l"="31.316,33.624"]
"biggsbenjamin/earlyexitnet" ["l"="31.308,33.613"]
"yuewang-cuhk/awesome-vision-language-pretraining-papers" ["l"="31.663,34.667"]
"jokieleung/awesome-visual-question-answering" ["l"="31.647,34.581"]
"djiajunustc/TransVG" ["l"="31.259,33.867"]
"microsoft/2D-TAN" ["l"="31.663,33.832"]
"WuJie1010/Awesome-Temporally-Language-Grounding" ["l"="31.616,33.838"]
"JonghwanMun/LGI4temporalgrounding" ["l"="31.651,33.842"]
"facebookresearch/grounded-video-description" ["l"="31.783,33.908"]
"SCZwangxiao/Temporal-Language-Grounding-in-videos" ["l"="31.635,33.844"]
"iworldtong/Awesome-Temporal-Sentence-Grounding-in-Videos" ["l"="31.624,33.844"]
"nku-shengzheliu/Pytorch-TransVG" ["l"="31.283,33.881"]
"djiajunustc/H-23D_R-CNN" ["l"="31.228,33.858"]
"ubc-vision/RefTR" ["l"="31.288,33.849"]
"yangli18/VLTVG" ["l"="31.269,33.849"]
"BryanPlummer/flickr30k_entities" ["l"="31.256,33.898"]
"LeapLabTHU/Model-Assembling" ["l"="31.227,33.804"]
"ronghanghu/cmn" ["l"="31.615,34.372"]
"luogen1996/Real-time-Global-Inference-Network" ["l"="31.291,33.965"]
"ChopinSharp/ref-nms" ["l"="31.28,33.892"]
"svip-lab/LBYLNet" ["l"="31.315,33.899"]
"BigRedT/info-ground" ["l"="31.33,33.892"]
"daqingliu/awesome-rec" ["l"="31.31,33.874"]
"qinzzz/Multimodal-Alignment-Framework" ["l"="31.33,33.878"]
"IBM/AdaMML" ["l"="31.153,33.776"]
"mengyuest/AR-Net" ["l"="31.14,33.791"]
"gaohuang/MSDNet" ["l"="34.412,35.197"]
"kalviny/IMTA" ["l"="31.265,33.713"]
"ucbdrive/skipnet" ["l"="31.241,33.682"]
"thomasverelst/dynconv" ["l"="31.225,33.694"]
"andreasveit/convnet-aig" ["l"="31.223,33.664"]
"Tushar-N/blockdrop" ["l"="31.243,33.656"]
"mfigurnov/sact" ["l"="31.259,33.668"]
"changlin31/DS-Net" ["l"="28.431,34.452"]
"cornell-zhang/dnn-gating" ["l"="-8.082,47.275"]
"caiqi/Cascasde-3D" ["l"="31.204,33.855"]
"thomasverelst/blockcopy-video-processing-pytorch" ["l"="31.201,33.687"]
"LukeForeverYoung/QRNet" ["l"="31.283,33.831"]
"uber-research/sbnet" ["l"="31.292,33.663"]
"mfigurnov/perforated-cnn-caffe" ["l"="31.255,33.637"]
"raoyongming/DynamicViT" ["l"="34.708,35.981"]
"nnizhang/VST" ["l"="32.045,32.729"]
"hustvl/TeViT" ["l"="31.814,33.364"]
"leonnnop/Locater" ["l"="31.16,33.915"]
"dzh19990407/LBDT" ["l"="31.17,33.928"]
"skynbe/Refer-Youtube-VOS" ["l"="31.153,33.933"]
"davisvideochallenge/davis2017-evaluation" ["l"="31.869,33.232"]
"miriambellver/refvos" ["l"="31.164,33.942"]
"eugenium/DGL" ["l"="31.125,33.733"]
"henghuiding/MOSE-api" ["l"="31.197,33.978"]
"mengyuest/AdaFuse" ["l"="31.114,33.792"]
"LeapLabTHU/ActiveNeRF" ["l"="31.197,33.772"]
"GingL/ARN" ["l"="31.344,33.912"]
"youngfly11/ReIR-WeaklyGrounding.pytorch" ["l"="31.351,33.879"]
"allenai/reclip" ["l"="31.215,33.971"]
"chongzhou96/MaskCLIP" ["l"="31.734,34.909"]
"hbb1/landmarkconv" ["l"="31.343,33.898"]
"fengguang94/CEFNet" ["l"="31.31,33.838"]
"mfigurnov/perforated-cnn-matconvnet" ["l"="31.245,33.619"]
}