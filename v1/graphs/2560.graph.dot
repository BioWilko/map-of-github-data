digraph G {
"rohitgirdhar/AttentionalPoolingAction" -> "rohitgirdhar/ActionVLAD"
"rohitgirdhar/AttentionalPoolingAction" -> "jeffreyhuang1/two-stream-action-recognition"
"rohitgirdhar/AttentionalPoolingAction" -> "frankgu/3d-DenseNet"
"rohitgirdhar/AttentionalPoolingAction" -> "gsig/charades-algorithms"
"rohitgirdhar/AttentionalPoolingAction" -> "kracwarlock/action-recognition-visual-attention"
"rohitgirdhar/AttentionalPoolingAction" -> "gsig/actions-for-actions"
"rohitgirdhar/AttentionalPoolingAction" -> "gurkirt/realtime-action-detection"
"rohitgirdhar/AttentionalPoolingAction" -> "wanglimin/UntrimmedNet"
"rohitgirdhar/AttentionalPoolingAction" -> "qijiezhao/Video-Classification-Action-Recognition"
"rohitgirdhar/AttentionalPoolingAction" -> "feichtenhofer/st-resnet"
"rohitgirdhar/AttentionalPoolingAction" -> "metalbubble/moments_models"
"rohitgirdhar/AttentionalPoolingAction" -> "wanglimin/ARTNet"
"rohitgirdhar/AttentionalPoolingAction" -> "VisionLearningGroup/R-C3D"
"rohitgirdhar/AttentionalPoolingAction" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"rohitgirdhar/AttentionalPoolingAction" -> "gsig/temporal-fields"
"yysijie/st-gcn" -> "open-mmlab/mmskeleton"
"yysijie/st-gcn" -> "lshiwjx/2s-AGCN"
"yysijie/st-gcn" -> "shahroudy/NTURGB-D"
"yysijie/st-gcn" -> "jinwchoi/awesome-action-recognition"
"yysijie/st-gcn" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"yysijie/st-gcn" -> "limaosen0/AS-GCN"
"yysijie/st-gcn" -> "yjxiong/temporal-segment-networks"
"yysijie/st-gcn" -> "kenziyuliu/MS-G3D"
"yysijie/st-gcn" -> "MVIG-SJTU/AlphaPose" ["e"=1]
"yysijie/st-gcn" -> "open-mmlab/mmaction"
"yysijie/st-gcn" -> "kenshohara/3D-ResNets-PyTorch"
"yysijie/st-gcn" -> "leoxiaobin/deep-high-resolution-net.pytorch" ["e"=1]
"yysijie/st-gcn" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"yysijie/st-gcn" -> "yjxiong/tsn-pytorch"
"yysijie/st-gcn" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"google-research/scenic" -> "microsoft/GLIP" ["e"=1]
"google-research/scenic" -> "rishikksh20/ViViT-pytorch"
"google-research/scenic" -> "SwinTransformer/Video-Swin-Transformer"
"google-research/scenic" -> "MCG-NJU/VideoMAE"
"google-research/scenic" -> "facebookresearch/TimeSformer"
"google-research/scenic" -> "mlfoundations/open_clip" ["e"=1]
"google-research/scenic" -> "open-mmlab/mmaction2"
"google-research/scenic" -> "facebookresearch/Mask2Former" ["e"=1]
"google-research/scenic" -> "google/flax" ["e"=1]
"google-research/scenic" -> "google-research/vision_transformer" ["e"=1]
"google-research/scenic" -> "google-research/big_vision" ["e"=1]
"google-research/scenic" -> "facebookresearch/Detic" ["e"=1]
"google-research/scenic" -> "facebookresearch/SlowFast"
"google-research/scenic" -> "facebookresearch/pytorchvideo"
"google-research/scenic" -> "OFA-Sys/OFA" ["e"=1]
"MCG-NJU/VideoMAE" -> "facebookresearch/TimeSformer"
"MCG-NJU/VideoMAE" -> "SwinTransformer/Video-Swin-Transformer"
"MCG-NJU/VideoMAE" -> "OpenGVLab/InternVideo"
"MCG-NJU/VideoMAE" -> "cvdfoundation/kinetics-dataset"
"MCG-NJU/VideoMAE" -> "Sense-X/UniFormer"
"MCG-NJU/VideoMAE" -> "open-mmlab/mmaction2"
"MCG-NJU/VideoMAE" -> "facebookresearch/omnivore"
"MCG-NJU/VideoMAE" -> "sallymmx/ActionCLIP"
"MCG-NJU/VideoMAE" -> "MCG-NJU/TDN"
"MCG-NJU/VideoMAE" -> "facebookresearch/mae_st"
"MCG-NJU/VideoMAE" -> "happyharrycn/actionformer_release"
"MCG-NJU/VideoMAE" -> "facebookresearch/mae" ["e"=1]
"MCG-NJU/VideoMAE" -> "google-research/scenic"
"MCG-NJU/VideoMAE" -> "microsoft/VideoX"
"MCG-NJU/VideoMAE" -> "facebookresearch/pytorchvideo"
"OpenGVLab/UniFormerV2" -> "OpenGVLab/InternVideo"
"OpenGVLab/UniFormerV2" -> "OpenGVLab/unmasked_teacher"
"OpenGVLab/UniFormerV2" -> "OpenGVLab/VideoMAEv2"
"ZFTurbo/volumentations" -> "ZFTurbo/classification_models_3D"
"ZFTurbo/volumentations" -> "ZFTurbo/segmentation_models_3D"
"ZFTurbo/volumentations" -> "ZFTurbo/efficientnet_3D"
"MVIG-SJTU/AlphAction" -> "Siyu-C/ACAR-Net"
"MVIG-SJTU/AlphAction" -> "NVlabs/STEP"
"MVIG-SJTU/AlphAction" -> "wei-tim/YOWO"
"MVIG-SJTU/AlphAction" -> "MCG-NJU/MOC-Detector"
"MVIG-SJTU/AlphAction" -> "Alpha-Video/AlphaVideo"
"MVIG-SJTU/AlphAction" -> "facebookresearch/video-long-term-feature-banks"
"MVIG-SJTU/AlphAction" -> "DirtyHarryLYL/HAKE-Action"
"MVIG-SJTU/AlphAction" -> "decisionforce/TPN"
"MVIG-SJTU/AlphAction" -> "DirtyHarryLYL/HAKE-Action-Torch"
"MVIG-SJTU/AlphAction" -> "DirtyHarryLYL/HAKE"
"MVIG-SJTU/AlphAction" -> "cvdfoundation/ava-dataset"
"MVIG-SJTU/AlphAction" -> "MCG-NJU/TDN"
"MVIG-SJTU/AlphAction" -> "oulutan/ACAM_Demo"
"MVIG-SJTU/AlphAction" -> "gurkirt/realtime-action-detection"
"MVIG-SJTU/AlphAction" -> "frostinassiky/gtad"
"abhiTronix/vidgear" -> "aminyazdanpanah/python-ffmpeg-video-streaming"
"abhiTronix/vidgear" -> "kkroening/ffmpeg-python" ["e"=1]
"abhiTronix/vidgear" -> "jeffbass/imagezmq" ["e"=1]
"abhiTronix/vidgear" -> "videoflow/videoflow"
"abhiTronix/vidgear" -> "aiortc/aiortc" ["e"=1]
"abhiTronix/vidgear" -> "AdamSpannbauer/python_video_stab" ["e"=1]
"abhiTronix/vidgear" -> "PyAV-Org/PyAV"
"abhiTronix/vidgear" -> "NVIDIA/VideoProcessingFramework" ["e"=1]
"abhiTronix/vidgear" -> "Zulko/moviepy" ["e"=1]
"abhiTronix/vidgear" -> "Breakthrough/PySceneDetect"
"abhiTronix/vidgear" -> "tryolabs/norfair" ["e"=1]
"abhiTronix/vidgear" -> "NVIDIA-AI-IOT/deepstream_python_apps" ["e"=1]
"abhiTronix/vidgear" -> "mifi/editly" ["e"=1]
"abhiTronix/vidgear" -> "wmuron/motpy" ["e"=1]
"abhiTronix/vidgear" -> "sudheerachary/Mesh-Flow-Video-Stabilization" ["e"=1]
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "YuxinZhaozyx/pytorch-VideoDataset"
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "IBM/action-recognition-pytorch"
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "hassony2/torch_videovision"
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "open-mmlab/denseflow" ["e"=1]
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "xiaobai1217/Awesome-Video-Datasets"
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "dmlc/decord"
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "okankop/vidaug"
"RaivoKoot/Video-Dataset-Loading-Pytorch" -> "rishikksh20/ViViT-pytorch"
"facebookresearch/SlowFast" -> "open-mmlab/mmaction2"
"facebookresearch/SlowFast" -> "mit-han-lab/temporal-shift-module"
"facebookresearch/SlowFast" -> "facebookresearch/pytorchvideo"
"facebookresearch/SlowFast" -> "open-mmlab/mmaction"
"facebookresearch/SlowFast" -> "kenshohara/3D-ResNets-PyTorch"
"facebookresearch/SlowFast" -> "jinwchoi/awesome-action-recognition"
"facebookresearch/SlowFast" -> "facebookresearch/detr" ["e"=1]
"facebookresearch/SlowFast" -> "yjxiong/temporal-segment-networks"
"facebookresearch/SlowFast" -> "facebookresearch/TimeSformer"
"facebookresearch/SlowFast" -> "microsoft/Swin-Transformer" ["e"=1]
"facebookresearch/SlowFast" -> "facebookresearch/moco" ["e"=1]
"facebookresearch/SlowFast" -> "xingyizhou/CenterNet" ["e"=1]
"facebookresearch/SlowFast" -> "facebookresearch/detectron2" ["e"=1]
"facebookresearch/SlowFast" -> "facebookresearch/video-nonlocal-net"
"facebookresearch/SlowFast" -> "lucidrains/vit-pytorch" ["e"=1]
"facebookresearch/TimeSformer" -> "lucidrains/TimeSformer-pytorch"
"facebookresearch/TimeSformer" -> "SwinTransformer/Video-Swin-Transformer"
"facebookresearch/TimeSformer" -> "MCG-NJU/VideoMAE"
"facebookresearch/TimeSformer" -> "cvdfoundation/kinetics-dataset"
"facebookresearch/TimeSformer" -> "open-mmlab/mmaction2"
"facebookresearch/TimeSformer" -> "facebookresearch/SlowFast"
"facebookresearch/TimeSformer" -> "rishikksh20/ViViT-pytorch"
"facebookresearch/TimeSformer" -> "facebookresearch/pytorchvideo"
"facebookresearch/TimeSformer" -> "mit-han-lab/temporal-shift-module"
"facebookresearch/TimeSformer" -> "ArrowLuo/CLIP4Clip" ["e"=1]
"facebookresearch/TimeSformer" -> "jayleicn/ClipBERT" ["e"=1]
"facebookresearch/TimeSformer" -> "facebookresearch/Motionformer"
"facebookresearch/TimeSformer" -> "google-research/scenic"
"facebookresearch/TimeSformer" -> "Sense-X/UniFormer"
"facebookresearch/TimeSformer" -> "sallymmx/ActionCLIP"
"piergiaj/representation-flow-cvpr19" -> "craston/MARS"
"piergiaj/representation-flow-cvpr19" -> "noureldien/timeception"
"piergiaj/representation-flow-cvpr19" -> "chaoyuaw/pytorch-coviar"
"piergiaj/representation-flow-cvpr19" -> "decisionforce/TPN"
"piergiaj/representation-flow-cvpr19" -> "mzolfaghari/ECO-pytorch"
"piergiaj/representation-flow-cvpr19" -> "cypw/PyTorch-MFNet"
"piergiaj/representation-flow-cvpr19" -> "LijieFan/tvnet"
"piergiaj/representation-flow-cvpr19" -> "coderSkyChen/Action_Recognition_Zoo"
"piergiaj/representation-flow-cvpr19" -> "dukebw/lintel"
"piergiaj/representation-flow-cvpr19" -> "r1ch88/SlowFastNetworks"
"piergiaj/representation-flow-cvpr19" -> "irhum/R2Plus1D-PyTorch"
"piergiaj/representation-flow-cvpr19" -> "yjxiong/tsn-pytorch"
"piergiaj/representation-flow-cvpr19" -> "qijiezhao/s3d.pytorch"
"piergiaj/representation-flow-cvpr19" -> "facebookresearch/VMZ"
"piergiaj/representation-flow-cvpr19" -> "wzmsltw/BSN-boundary-sensitive-network"
"ppriyank/Video-Action-Transformer-Network-Pytorch-" -> "joaanna/something_else"
"InwoongLee/TS-LSTM" -> "shuangshuangguo/skeleton-based-action-recognition-review"
"InwoongLee/TS-LSTM" -> "fandulu/Keras-for-Co-occurrence-Feature-Learning-from-Skeleton-Data-for-Action-Recognition"
"InwoongLee/TS-LSTM" -> "kinect59/Spatio-Temporal-LSTM"
"InwoongLee/TS-LSTM" -> "FesianXu/PLSTM"
"InwoongLee/TS-LSTM" -> "TaeSoo-Kim/TCNActionRecognition"
"InwoongLee/TS-LSTM" -> "yfsong0709/RA-GCNv1"
"InwoongLee/TS-LSTM" -> "huguyuehuhu/HCN-pytorch"
"InwoongLee/TS-LSTM" -> "limaosen0/AS-GCN"
"InwoongLee/TS-LSTM" -> "XiaoCode-er/Two-Stream-CNN"
"LijieFan/tvnet" -> "piergiaj/representation-flow-cvpr19"
"LijieFan/tvnet" -> "Gasoonjia/tvnet_pytorch"
"LijieFan/tvnet" -> "wanglimin/ARTNet"
"LijieFan/tvnet" -> "VisionLearningGroup/R-C3D"
"LijieFan/tvnet" -> "bryanyzhu/two-stream-pytorch"
"LijieFan/tvnet" -> "cypw/PyTorch-MFNet"
"LijieFan/tvnet" -> "zhengshou/scnn"
"LijieFan/tvnet" -> "yjxiong/action-detection"
"LijieFan/tvnet" -> "metalbubble/TRN-pytorch"
"LijieFan/tvnet" -> "rohitgirdhar/ActionVLAD"
"LijieFan/tvnet" -> "hbilen/dynamic-image-nets"
"LijieFan/tvnet" -> "coderSkyChen/Action_Recognition_Zoo"
"LijieFan/tvnet" -> "kevin-ssy/Optical-Flow-Guided-Feature"
"facebookresearch/video-nonlocal-net" -> "AlexHex7/Non-local_pytorch" ["e"=1]
"facebookresearch/video-nonlocal-net" -> "deepmind/kinetics-i3d"
"facebookresearch/video-nonlocal-net" -> "yjxiong/temporal-segment-networks"
"facebookresearch/video-nonlocal-net" -> "yjxiong/tsn-pytorch"
"facebookresearch/video-nonlocal-net" -> "activitynet/ActivityNet"
"facebookresearch/video-nonlocal-net" -> "mit-han-lab/temporal-shift-module"
"facebookresearch/video-nonlocal-net" -> "open-mmlab/mmaction"
"facebookresearch/video-nonlocal-net" -> "kenshohara/3D-ResNets-PyTorch"
"facebookresearch/video-nonlocal-net" -> "xvjiarui/GCNet" ["e"=1]
"facebookresearch/video-nonlocal-net" -> "yjxiong/action-detection"
"facebookresearch/video-nonlocal-net" -> "piergiaj/pytorch-i3d"
"facebookresearch/video-nonlocal-net" -> "hassony2/kinetics_i3d_pytorch"
"facebookresearch/video-nonlocal-net" -> "msracver/Deformable-ConvNets" ["e"=1]
"facebookresearch/video-nonlocal-net" -> "facebookresearch/SlowFast"
"facebookresearch/video-nonlocal-net" -> "facebookresearch/VMZ"
"yjxiong/temporal-segment-networks" -> "yjxiong/tsn-pytorch"
"yjxiong/temporal-segment-networks" -> "open-mmlab/mmaction"
"yjxiong/temporal-segment-networks" -> "mit-han-lab/temporal-shift-module"
"yjxiong/temporal-segment-networks" -> "deepmind/kinetics-i3d"
"yjxiong/temporal-segment-networks" -> "yjxiong/action-detection"
"yjxiong/temporal-segment-networks" -> "feichtenhofer/twostreamfusion"
"yjxiong/temporal-segment-networks" -> "activitynet/ActivityNet"
"yjxiong/temporal-segment-networks" -> "kenshohara/3D-ResNets-PyTorch"
"yjxiong/temporal-segment-networks" -> "jinwchoi/awesome-action-recognition"
"yjxiong/temporal-segment-networks" -> "wzmsltw/BSN-boundary-sensitive-network"
"yjxiong/temporal-segment-networks" -> "facebookresearch/video-nonlocal-net"
"yjxiong/temporal-segment-networks" -> "piergiaj/pytorch-i3d"
"yjxiong/temporal-segment-networks" -> "bryanyzhu/two-stream-pytorch"
"yjxiong/temporal-segment-networks" -> "facebook/C3D"
"yjxiong/temporal-segment-networks" -> "yjxiong/anet2016-cuhk"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "taufeeque9/HumanFallDetection"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "open-mmlab/mmskeleton"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "cwlroda/falldetection_openpifpaf"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "felixchenfy/Realtime-Action-Recognition"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "yysijie/st-gcn"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "Amanbhandula/AlphaPose"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "kennymckormick/pyskl"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "xqZhang-Strong/Human-Falling-Detect-Tracks-master"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "Daniil-Osokin/lightweight-human-pose-estimation.pytorch" ["e"=1]
"GajuuzZ/Human-Falling-Detect-Tracks" -> "AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "lshiwjx/2s-AGCN"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "BlackFeatherQQ/openpose_fall_detect"
"GajuuzZ/Human-Falling-Detect-Tracks" -> "JJN123/Fall-Detection"
"HHTseng/video-classification" -> "kenshohara/video-classification-3d-cnn-pytorch"
"HHTseng/video-classification" -> "feichtenhofer/twostreamfusion"
"HHTseng/video-classification" -> "jeffreyyihuang/two-stream-action-recognition"
"HHTseng/video-classification" -> "jfzhang95/pytorch-video-recognition"
"HHTseng/video-classification" -> "harvitronix/five-video-classification-methods"
"HHTseng/video-classification" -> "sagarvegad/Video-Classification-CNN-and-LSTM-"
"HHTseng/video-classification" -> "kenshohara/3D-ResNets-PyTorch"
"HHTseng/video-classification" -> "woodfrog/ActionRecognition"
"HHTseng/video-classification" -> "pranoyr/cnn-lstm"
"HHTseng/video-classification" -> "sujiongming/UCF-101_video_classification"
"HHTseng/video-classification" -> "jinwchoi/awesome-action-recognition"
"HHTseng/video-classification" -> "deepmind/kinetics-i3d"
"HHTseng/video-classification" -> "okankop/Efficient-3DCNNs"
"HHTseng/video-classification" -> "eriklindernoren/Action-Recognition"
"HHTseng/video-classification" -> "bryanyzhu/two-stream-pytorch"
"chonyy/AI-basketball-analysis" -> "chonyy/basketball-shot-detection"
"chonyy/AI-basketball-analysis" -> "stephanj/basketballVideoAnalysis"
"chonyy/AI-basketball-analysis" -> "simonefrancia/SpaceJam"
"chonyy/AI-basketball-analysis" -> "browlm13/Basketball-Shot-Detection"
"chonyy/AI-basketball-analysis" -> "chonyy/ML-auto-baseball-pitching-overlay"
"chonyy/AI-basketball-analysis" -> "homerchen19/nba-go"
"chonyy/AI-basketball-analysis" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"chonyy/AI-basketball-analysis" -> "dluvizon/deephar"
"chonyy/AI-basketball-analysis" -> "neeilan/DeepPlayByPlay" ["e"=1]
"chonyy/AI-basketball-analysis" -> "ry-werth/nba-automation"
"chonyy/AI-basketball-analysis" -> "Daniil-Osokin/lightweight-human-pose-estimation.pytorch" ["e"=1]
"chonyy/AI-basketball-analysis" -> "OwlTing/AI_basketball_games_video_editor"
"chonyy/AI-basketball-analysis" -> "danchyy/Basketball_Analytics" ["e"=1]
"chonyy/AI-basketball-analysis" -> "augmentedstartups/Pose-Estimation"
"chonyy/AI-basketball-analysis" -> "Guanghan/lighttrack" ["e"=1]
"facebookresearch/pytorchvideo" -> "facebookresearch/SlowFast"
"facebookresearch/pytorchvideo" -> "open-mmlab/mmaction2"
"facebookresearch/pytorchvideo" -> "facebookresearch/TimeSformer"
"facebookresearch/pytorchvideo" -> "facebookresearch/vissl" ["e"=1]
"facebookresearch/pytorchvideo" -> "dmlc/decord"
"facebookresearch/pytorchvideo" -> "mit-han-lab/temporal-shift-module"
"facebookresearch/pytorchvideo" -> "kenshohara/3D-ResNets-PyTorch"
"facebookresearch/pytorchvideo" -> "SwinTransformer/Video-Swin-Transformer"
"facebookresearch/pytorchvideo" -> "facebookresearch/deit" ["e"=1]
"facebookresearch/pytorchvideo" -> "MCG-NJU/VideoMAE"
"facebookresearch/pytorchvideo" -> "cvdfoundation/kinetics-dataset"
"facebookresearch/pytorchvideo" -> "activitynet/ActivityNet"
"facebookresearch/pytorchvideo" -> "open-mmlab/mmaction"
"facebookresearch/pytorchvideo" -> "facebookresearch/dino" ["e"=1]
"facebookresearch/pytorchvideo" -> "facebookresearch/mae" ["e"=1]
"fredzzhang/upt" -> "cjw2021/QAHOI"
"fredzzhang/upt" -> "hitachi-rd-cv/qpic"
"fredzzhang/upt" -> "YueLiao/gen-vlkt"
"fredzzhang/upt" -> "fredzzhang/spatially-conditioned-graphs"
"fredzzhang/upt" -> "zyong812/STIP"
"fredzzhang/upt" -> "YueLiao/CDN"
"fredzzhang/upt" -> "yoyomimi/AS-Net"
"fredzzhang/upt" -> "zhihou7/HOI-CL"
"fredzzhang/upt" -> "kakaobrain/HOTR"
"fredzzhang/upt" -> "fredzzhang/hicodet"
"fredzzhang/upt" -> "bbepoch/HoiTransformer"
"fredzzhang/upt" -> "YueLiao/PPDM"
"fredzzhang/upt" -> "vt-vl-lab/DRG"
"jfzhang95/pytorch-video-recognition" -> "kenshohara/3D-ResNets-PyTorch"
"jfzhang95/pytorch-video-recognition" -> "piergiaj/pytorch-i3d"
"jfzhang95/pytorch-video-recognition" -> "facebookresearch/VMZ"
"jfzhang95/pytorch-video-recognition" -> "DavideA/c3d-pytorch"
"jfzhang95/pytorch-video-recognition" -> "yjxiong/tsn-pytorch"
"jfzhang95/pytorch-video-recognition" -> "kenshohara/video-classification-3d-cnn-pytorch"
"jfzhang95/pytorch-video-recognition" -> "qijiezhao/pseudo-3d-pytorch"
"jfzhang95/pytorch-video-recognition" -> "bryanyzhu/two-stream-pytorch"
"jfzhang95/pytorch-video-recognition" -> "open-mmlab/mmaction"
"jfzhang95/pytorch-video-recognition" -> "yjxiong/temporal-segment-networks"
"jfzhang95/pytorch-video-recognition" -> "jeffreyyihuang/two-stream-action-recognition"
"jfzhang95/pytorch-video-recognition" -> "sunnyxiaohu/R-C3D.pytorch"
"jfzhang95/pytorch-video-recognition" -> "deepmind/kinetics-i3d"
"jfzhang95/pytorch-video-recognition" -> "hassony2/kinetics_i3d_pytorch"
"jfzhang95/pytorch-video-recognition" -> "jinwchoi/awesome-action-recognition"
"kennymckormick/pyskl" -> "Uason-Chen/CTR-GCN"
"kennymckormick/pyskl" -> "open-mmlab/mmaction2"
"kennymckormick/pyskl" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"kennymckormick/pyskl" -> "lshiwjx/2s-AGCN"
"kennymckormick/pyskl" -> "kenziyuliu/MS-G3D"
"kennymckormick/pyskl" -> "shahroudy/NTURGB-D"
"kennymckormick/pyskl" -> "open-mmlab/mmskeleton"
"kennymckormick/pyskl" -> "Chiaraplizz/ST-TR"
"kennymckormick/pyskl" -> "microsoft/SGN"
"kennymckormick/pyskl" -> "yysijie/st-gcn"
"kennymckormick/pyskl" -> "kchengiva/Shift-GCN"
"kennymckormick/pyskl" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"kennymckormick/pyskl" -> "limaosen0/AS-GCN"
"kennymckormick/pyskl" -> "stnoah1/infogcn"
"kennymckormick/pyskl" -> "Jho-Yonsei/HD-GCN" ["e"=1]
"limaosen0/AS-GCN" -> "lshiwjx/2s-AGCN"
"limaosen0/AS-GCN" -> "kchengiva/Shift-GCN"
"limaosen0/AS-GCN" -> "kenziyuliu/MS-G3D"
"limaosen0/AS-GCN" -> "yfsong0709/RA-GCNv1"
"limaosen0/AS-GCN" -> "xiaoiker/GCN-NAS"
"limaosen0/AS-GCN" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"limaosen0/AS-GCN" -> "shahroudy/NTURGB-D"
"limaosen0/AS-GCN" -> "kenziyuliu/DGNN-PyTorch"
"limaosen0/AS-GCN" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"limaosen0/AS-GCN" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"limaosen0/AS-GCN" -> "cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes"
"limaosen0/AS-GCN" -> "microsoft/SGN"
"limaosen0/AS-GCN" -> "huguyuehuhu/HCN-pytorch"
"limaosen0/AS-GCN" -> "InwoongLee/TS-LSTM"
"limaosen0/AS-GCN" -> "shuangshuangguo/skeleton-based-action-recognition-review"
"lshiwjx/2s-AGCN" -> "kenziyuliu/MS-G3D"
"lshiwjx/2s-AGCN" -> "limaosen0/AS-GCN"
"lshiwjx/2s-AGCN" -> "shahroudy/NTURGB-D"
"lshiwjx/2s-AGCN" -> "yysijie/st-gcn"
"lshiwjx/2s-AGCN" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"lshiwjx/2s-AGCN" -> "kchengiva/Shift-GCN"
"lshiwjx/2s-AGCN" -> "open-mmlab/mmskeleton"
"lshiwjx/2s-AGCN" -> "kenziyuliu/DGNN-PyTorch"
"lshiwjx/2s-AGCN" -> "microsoft/SGN"
"lshiwjx/2s-AGCN" -> "xiaoiker/GCN-NAS"
"lshiwjx/2s-AGCN" -> "Uason-Chen/CTR-GCN"
"lshiwjx/2s-AGCN" -> "Chiaraplizz/ST-TR"
"lshiwjx/2s-AGCN" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"lshiwjx/2s-AGCN" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"lshiwjx/2s-AGCN" -> "huguyuehuhu/HCN-pytorch"
"open-mmlab/mmaction2" -> "facebookresearch/SlowFast"
"open-mmlab/mmaction2" -> "open-mmlab/mmaction"
"open-mmlab/mmaction2" -> "SwinTransformer/Video-Swin-Transformer"
"open-mmlab/mmaction2" -> "facebookresearch/pytorchvideo"
"open-mmlab/mmaction2" -> "mit-han-lab/temporal-shift-module"
"open-mmlab/mmaction2" -> "open-mmlab/mmpose" ["e"=1]
"open-mmlab/mmaction2" -> "kennymckormick/pyskl"
"open-mmlab/mmaction2" -> "open-mmlab/mmskeleton"
"open-mmlab/mmaction2" -> "facebookresearch/TimeSformer"
"open-mmlab/mmaction2" -> "jinwchoi/awesome-action-recognition"
"open-mmlab/mmaction2" -> "MCG-NJU/VideoMAE"
"open-mmlab/mmaction2" -> "open-mmlab/mmcv" ["e"=1]
"open-mmlab/mmaction2" -> "PaddlePaddle/PaddleVideo" ["e"=1]
"open-mmlab/mmaction2" -> "cvdfoundation/kinetics-dataset"
"open-mmlab/mmaction2" -> "yjxiong/temporal-segment-networks"
"open-mmlab/mmskeleton" -> "yysijie/st-gcn"
"open-mmlab/mmskeleton" -> "lshiwjx/2s-AGCN"
"open-mmlab/mmskeleton" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"open-mmlab/mmskeleton" -> "shahroudy/NTURGB-D"
"open-mmlab/mmskeleton" -> "kenziyuliu/MS-G3D"
"open-mmlab/mmskeleton" -> "open-mmlab/mmaction"
"open-mmlab/mmskeleton" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"open-mmlab/mmskeleton" -> "open-mmlab/mmaction2"
"open-mmlab/mmskeleton" -> "felixchenfy/Realtime-Action-Recognition"
"open-mmlab/mmskeleton" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"open-mmlab/mmskeleton" -> "limaosen0/AS-GCN"
"open-mmlab/mmskeleton" -> "jinwchoi/awesome-action-recognition"
"open-mmlab/mmskeleton" -> "microsoft/human-pose-estimation.pytorch" ["e"=1]
"open-mmlab/mmskeleton" -> "open-mmlab/mmpose" ["e"=1]
"open-mmlab/mmskeleton" -> "kennymckormick/pyskl"
"scivision/PyLivestream" -> "aminyazdanpanah/python-ffmpeg-video-streaming"
"scivision/PyLivestream" -> "317070/python-twitch-stream"
"scivision/PyLivestream" -> "torch2424/live-stream-radio"
"scivision/PyLivestream" -> "MD3XTER/Twitch-Farmer" ["e"=1]
"scivision/PyLivestream" -> "jprjr/multistreamer" ["e"=1]
"scivision/PyLivestream" -> "Niek/obs-web" ["e"=1]
"scivision/PyLivestream" -> "jprjr/docker-multistreamer" ["e"=1]
"scivision/PyLivestream" -> "Xingtao/FFdynamic" ["e"=1]
"eriklindernoren/Action-Recognition" -> "IDKiro/action-recognition"
"eriklindernoren/Action-Recognition" -> "woodfrog/ActionRecognition"
"eriklindernoren/Action-Recognition" -> "Keiku/Action-Recognition-CNN-LSTM"
"eriklindernoren/Action-Recognition" -> "peachman05/action-recognition-tutorial"
"eriklindernoren/Action-Recognition" -> "jeffreyyihuang/two-stream-action-recognition"
"OValery16/Tutorial-about-3D-convolutional-network" -> "kcct-fujimotolab/3DCNN"
"OValery16/Tutorial-about-3D-convolutional-network" -> "ms3001/DeepHandGestureRecognition" ["e"=1]
"OValery16/Tutorial-about-3D-convolutional-network" -> "tomrunia/PyTorchConv3D"
"kenshohara/3D-ResNets-PyTorch" -> "kenshohara/video-classification-3d-cnn-pytorch"
"kenshohara/3D-ResNets-PyTorch" -> "jinwchoi/awesome-action-recognition"
"kenshohara/3D-ResNets-PyTorch" -> "deepmind/kinetics-i3d"
"kenshohara/3D-ResNets-PyTorch" -> "yjxiong/temporal-segment-networks"
"kenshohara/3D-ResNets-PyTorch" -> "facebookresearch/SlowFast"
"kenshohara/3D-ResNets-PyTorch" -> "open-mmlab/mmaction"
"kenshohara/3D-ResNets-PyTorch" -> "yjxiong/tsn-pytorch"
"kenshohara/3D-ResNets-PyTorch" -> "jfzhang95/pytorch-video-recognition"
"kenshohara/3D-ResNets-PyTorch" -> "mit-han-lab/temporal-shift-module"
"kenshohara/3D-ResNets-PyTorch" -> "facebookresearch/video-nonlocal-net"
"kenshohara/3D-ResNets-PyTorch" -> "piergiaj/pytorch-i3d"
"kenshohara/3D-ResNets-PyTorch" -> "activitynet/ActivityNet"
"kenshohara/3D-ResNets-PyTorch" -> "facebookresearch/VMZ"
"kenshohara/3D-ResNets-PyTorch" -> "hassony2/kinetics_i3d_pytorch"
"kenshohara/3D-ResNets-PyTorch" -> "yysijie/st-gcn"
"facebook/C3D" -> "hx173149/C3D-tensorflow"
"facebook/C3D" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"facebook/C3D" -> "yjxiong/temporal-segment-networks"
"facebook/C3D" -> "chuckcho/video-caffe"
"facebook/C3D" -> "feichtenhofer/twostreamfusion"
"facebook/C3D" -> "deepmind/kinetics-i3d"
"facebook/C3D" -> "yjxiong/action-detection"
"facebook/C3D" -> "activitynet/ActivityNet"
"facebook/C3D" -> "yjxiong/caffe"
"facebook/C3D" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"facebook/C3D" -> "yjxiong/tsn-pytorch"
"facebook/C3D" -> "VisionLearningGroup/R-C3D"
"facebook/C3D" -> "qijiezhao/pseudo-3d-pytorch"
"facebook/C3D" -> "facebookresearch/VMZ"
"facebook/C3D" -> "jeffreyhuang1/two-stream-action-recognition"
"facebookresearch/R2Plus1D" -> "irhumshafkat/R2Plus1D-PyTorch"
"facebookresearch/R2Plus1D" -> "wanglimin/ARTNet"
"facebookresearch/R2Plus1D" -> "hassony2/inflated_convnets_pytorch"
"facebookresearch/R2Plus1D" -> "shyamal-b/sst"
"facebookresearch/R2Plus1D" -> "metalbubble/TRN-pytorch"
"facebookresearch/R2Plus1D" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"facebookresearch/R2Plus1D" -> "yjxiong/action-detection"
"facebookresearch/R2Plus1D" -> "metalbubble/moments_models"
"facebookresearch/R2Plus1D" -> "facebook/C3D"
"facebookresearch/R2Plus1D" -> "starsdeep/R2Plus1D-MXNet"
"facebookresearch/R2Plus1D" -> "mzolfaghari/ECO-efficient-video-understanding"
"facebookresearch/R2Plus1D" -> "roytseng-tw/mask-rcnn.pytorch" ["e"=1]
"facebookresearch/R2Plus1D" -> "VisionLearningGroup/R-C3D"
"facebookresearch/R2Plus1D" -> "qijiezhao/pseudo-3d-pytorch"
"facebookresearch/R2Plus1D" -> "ignacio-rocco/detectorch" ["e"=1]
"MCG-NJU/MultiSports" -> "MCG-NJU/SportsMOT"
"huguyuehuhu/HCN-pytorch" -> "fandulu/Keras-for-Co-occurrence-Feature-Learning-from-Skeleton-Data-for-Action-Recognition"
"huguyuehuhu/HCN-pytorch" -> "shuangshuangguo/skeleton-based-action-recognition-review"
"huguyuehuhu/HCN-pytorch" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"huguyuehuhu/HCN-pytorch" -> "TaeSoo-Kim/TCNActionRecognition"
"huguyuehuhu/HCN-pytorch" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"huguyuehuhu/HCN-pytorch" -> "limaosen0/AS-GCN"
"huguyuehuhu/HCN-pytorch" -> "InwoongLee/TS-LSTM"
"huguyuehuhu/HCN-pytorch" -> "shahroudy/NTURGB-D"
"huguyuehuhu/HCN-pytorch" -> "cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes"
"huguyuehuhu/HCN-pytorch" -> "maxstrobel/HCN-PrototypeLoss-PyTorch"
"huguyuehuhu/HCN-pytorch" -> "kchengiva/Shift-GCN"
"huguyuehuhu/HCN-pytorch" -> "lshiwjx/2s-AGCN"
"huguyuehuhu/HCN-pytorch" -> "yfsong0709/RA-GCNv1"
"huguyuehuhu/HCN-pytorch" -> "kenziyuliu/MS-G3D"
"huguyuehuhu/HCN-pytorch" -> "microsoft/SGN"
"facebookarchive/C3D" -> "jfzhang95/pytorch-video-recognition"
"facebookarchive/C3D" -> "DavideA/c3d-pytorch"
"facebookarchive/C3D" -> "hx173149/C3D-tensorflow"
"facebookarchive/C3D" -> "WaqasSultani/AnomalyDetectionCVPR2018" ["e"=1]
"facebookarchive/C3D" -> "jeffreyyihuang/two-stream-action-recognition"
"facebookarchive/C3D" -> "feichtenhofer/twostreamfusion"
"facebookarchive/C3D" -> "TianzhongSong/C3D-keras"
"facebookarchive/C3D" -> "zhoubolei/TRN-pytorch"
"facebookarchive/C3D" -> "deepmind/kinetics-i3d"
"facebookarchive/C3D" -> "MCG-NJU/TDN"
"facebookarchive/C3D" -> "rajanjitenpatel/C3D_feature_extraction" ["e"=1]
"facebookarchive/C3D" -> "irhum/R2Plus1D-PyTorch"
"facebookarchive/C3D" -> "piergiaj/pytorch-i3d"
"kenshohara/video-classification-3d-cnn-pytorch" -> "kenshohara/3D-ResNets-PyTorch"
"kenshohara/video-classification-3d-cnn-pytorch" -> "jfzhang95/pytorch-video-recognition"
"kenshohara/video-classification-3d-cnn-pytorch" -> "HHTseng/video-classification"
"kenshohara/video-classification-3d-cnn-pytorch" -> "yjxiong/tsn-pytorch"
"kenshohara/video-classification-3d-cnn-pytorch" -> "deepmind/kinetics-i3d"
"kenshohara/video-classification-3d-cnn-pytorch" -> "yjxiong/temporal-segment-networks"
"kenshohara/video-classification-3d-cnn-pytorch" -> "hassony2/kinetics_i3d_pytorch"
"kenshohara/video-classification-3d-cnn-pytorch" -> "bryanyzhu/two-stream-pytorch"
"kenshohara/video-classification-3d-cnn-pytorch" -> "piergiaj/pytorch-i3d"
"kenshohara/video-classification-3d-cnn-pytorch" -> "harvitronix/five-video-classification-methods"
"kenshohara/video-classification-3d-cnn-pytorch" -> "qijiezhao/pseudo-3d-pytorch"
"kenshohara/video-classification-3d-cnn-pytorch" -> "activitynet/ActivityNet"
"kenshohara/video-classification-3d-cnn-pytorch" -> "DavideA/c3d-pytorch"
"kenshohara/video-classification-3d-cnn-pytorch" -> "xiadingZ/video-caption.pytorch" ["e"=1]
"kenshohara/video-classification-3d-cnn-pytorch" -> "facebookresearch/VMZ"
"TianzhongSong/3D-ConvNets-for-Action-Recognition" -> "gudongfeng/3d-DenseNet"
"bryanyzhu/two-stream-pytorch" -> "jeffreyhuang1/two-stream-action-recognition"
"bryanyzhu/two-stream-pytorch" -> "jeffreyyihuang/two-stream-action-recognition"
"bryanyzhu/two-stream-pytorch" -> "feichtenhofer/twostreamfusion"
"bryanyzhu/two-stream-pytorch" -> "bryanyzhu/Hidden-Two-Stream"
"bryanyzhu/two-stream-pytorch" -> "yjxiong/tsn-pytorch"
"bryanyzhu/two-stream-pytorch" -> "yjxiong/temporal-segment-networks"
"bryanyzhu/two-stream-pytorch" -> "yjxiong/dense_flow"
"bryanyzhu/two-stream-pytorch" -> "feichtenhofer/gpu_flow"
"bryanyzhu/two-stream-pytorch" -> "qijiezhao/pseudo-3d-pytorch"
"bryanyzhu/two-stream-pytorch" -> "tomar840/two-stream-fusion-for-action-recognition-in-videos"
"bryanyzhu/two-stream-pytorch" -> "hassony2/kinetics_i3d_pytorch"
"bryanyzhu/two-stream-pytorch" -> "jfzhang95/pytorch-video-recognition"
"bryanyzhu/two-stream-pytorch" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"bryanyzhu/two-stream-pytorch" -> "kenshohara/video-classification-3d-cnn-pytorch"
"bryanyzhu/two-stream-pytorch" -> "qijiezhao/Video-Classification-Action-Recognition"
"jeffreyyihuang/two-stream-action-recognition" -> "bryanyzhu/two-stream-pytorch"
"jeffreyyihuang/two-stream-action-recognition" -> "feichtenhofer/twostreamfusion"
"jeffreyyihuang/two-stream-action-recognition" -> "jfzhang95/pytorch-video-recognition"
"jeffreyyihuang/two-stream-action-recognition" -> "HHTseng/video-classification"
"jeffreyyihuang/two-stream-action-recognition" -> "yjxiong/tsn-pytorch"
"jeffreyyihuang/two-stream-action-recognition" -> "tomar840/two-stream-fusion-for-action-recognition-in-videos"
"jeffreyyihuang/two-stream-action-recognition" -> "feichtenhofer/gpu_flow"
"jeffreyyihuang/two-stream-action-recognition" -> "wushidonguc/two-stream-action-recognition-keras"
"jeffreyyihuang/two-stream-action-recognition" -> "woodfrog/ActionRecognition"
"jeffreyyihuang/two-stream-action-recognition" -> "mohammed-elkomy/two-stream-action-recognition"
"jeffreyyihuang/two-stream-action-recognition" -> "decisionforce/TPN"
"jeffreyyihuang/two-stream-action-recognition" -> "TianzhongSong/Real-Time-Action-Recognition"
"jeffreyyihuang/two-stream-action-recognition" -> "yjxiong/temporal-segment-networks"
"jeffreyyihuang/two-stream-action-recognition" -> "MRzzm/action-recognition-models-pytorch"
"jeffreyyihuang/two-stream-action-recognition" -> "jinwchoi/awesome-action-recognition"
"open-mmlab/mmaction" -> "yjxiong/temporal-segment-networks"
"open-mmlab/mmaction" -> "yjxiong/tsn-pytorch"
"open-mmlab/mmaction" -> "mit-han-lab/temporal-shift-module"
"open-mmlab/mmaction" -> "facebookresearch/SlowFast"
"open-mmlab/mmaction" -> "jinwchoi/awesome-action-recognition"
"open-mmlab/mmaction" -> "open-mmlab/mmaction2"
"open-mmlab/mmaction" -> "kenshohara/3D-ResNets-PyTorch"
"open-mmlab/mmaction" -> "activitynet/ActivityNet"
"open-mmlab/mmaction" -> "gsig/PyVideoResearch"
"open-mmlab/mmaction" -> "decisionforce/TPN"
"open-mmlab/mmaction" -> "piergiaj/pytorch-i3d"
"open-mmlab/mmaction" -> "facebookresearch/VMZ"
"open-mmlab/mmaction" -> "facebookresearch/video-nonlocal-net"
"open-mmlab/mmaction" -> "deepmind/kinetics-i3d"
"open-mmlab/mmaction" -> "open-mmlab/mmskeleton"
"yjxiong/tsn-pytorch" -> "yjxiong/temporal-segment-networks"
"yjxiong/tsn-pytorch" -> "open-mmlab/mmaction"
"yjxiong/tsn-pytorch" -> "mit-han-lab/temporal-shift-module"
"yjxiong/tsn-pytorch" -> "bryanyzhu/two-stream-pytorch"
"yjxiong/tsn-pytorch" -> "deepmind/kinetics-i3d"
"yjxiong/tsn-pytorch" -> "yjxiong/action-detection"
"yjxiong/tsn-pytorch" -> "activitynet/ActivityNet"
"yjxiong/tsn-pytorch" -> "metalbubble/TRN-pytorch"
"yjxiong/tsn-pytorch" -> "kenshohara/3D-ResNets-PyTorch"
"yjxiong/tsn-pytorch" -> "piergiaj/pytorch-i3d"
"yjxiong/tsn-pytorch" -> "hassony2/kinetics_i3d_pytorch"
"yjxiong/tsn-pytorch" -> "feichtenhofer/twostreamfusion"
"yjxiong/tsn-pytorch" -> "wzmsltw/BSN-boundary-sensitive-network"
"yjxiong/tsn-pytorch" -> "facebookresearch/video-nonlocal-net"
"yjxiong/tsn-pytorch" -> "jfzhang95/pytorch-video-recognition"
"zhoubolei/TRN-pytorch" -> "decisionforce/TPN"
"zhoubolei/TRN-pytorch" -> "arunos728/MotionSqueeze"
"zhoubolei/TRN-pytorch" -> "Phoenix1327/tea-action-recognition"
"zhoubolei/TRN-pytorch" -> "MCG-NJU/TDN"
"zhoubolei/TRN-pytorch" -> "swathikirans/GSM"
"zhoubolei/TRN-pytorch" -> "mzolfaghari/ECO-pytorch"
"zhoubolei/TRN-pytorch" -> "facebookresearch/video-long-term-feature-banks"
"zhoubolei/TRN-pytorch" -> "mit-han-lab/temporal-shift-module"
"zhoubolei/TRN-pytorch" -> "yjxiong/temporal-segment-networks"
"zhoubolei/TRN-pytorch" -> "V-Sense/ACTION-Net"
"zhoubolei/TRN-pytorch" -> "mengyuest/AR-Net" ["e"=1]
"zhoubolei/TRN-pytorch" -> "xhl-video/SmallBigNet"
"zhoubolei/TRN-pytorch" -> "yjxiong/tsn-pytorch"
"ortegatron/liveposetracker" -> "hugozanini/openPoseTracking"
"sujiongming/UCF-101_video_classification" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"sujiongming/UCF-101_video_classification" -> "harvitronix/five-video-classification-methods"
"sujiongming/UCF-101_video_classification" -> "qijiezhao/Video-Classification-Action-Recognition"
"sujiongming/UCF-101_video_classification" -> "sagarvegad/Video-Classification-CNN-and-LSTM-"
"sujiongming/UCF-101_video_classification" -> "jeffreyhuang1/two-stream-action-recognition"
"sujiongming/UCF-101_video_classification" -> "feichtenhofer/twostreamfusion"
"sujiongming/UCF-101_video_classification" -> "zhuzhuxia1994/CK-TensorFlow"
"sujiongming/UCF-101_video_classification" -> "sujiongming/awesome-video-understanding"
"sujiongming/UCF-101_video_classification" -> "rohitgirdhar/ActionVLAD"
"sujiongming/UCF-101_video_classification" -> "woodfrog/ActionRecognition"
"sujiongming/UCF-101_video_classification" -> "bryanyzhu/two-stream-pytorch"
"sujiongming/UCF-101_video_classification" -> "HHTseng/video-classification"
"sujiongming/UCF-101_video_classification" -> "kenshohara/video-classification-3d-cnn-pytorch"
"sujiongming/UCF-101_video_classification" -> "hx173149/C3D-tensorflow"
"sujiongming/UCF-101_video_classification" -> "anenbergb/CS221_Project"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "feichtenhofer/twostreamfusion"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "sujiongming/UCF-101_video_classification"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "bryanyzhu/two-stream-pytorch"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "rohitgirdhar/ActionVLAD"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "feichtenhofer/gpu_flow"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "harvitronix/five-video-classification-methods"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "jeffreyhuang1/two-stream-action-recognition"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "kracwarlock/action-recognition-visual-attention"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "qijiezhao/Video-Classification-Action-Recognition"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "facebook/C3D"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "yjxiong/caffe"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "imatge-upc/activitynet-2016-cvprw"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "hx173149/C3D-tensorflow"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"wadhwasahil/Video-Classification-2-Stream-CNN" -> "wanglimin/dense_flow"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "JJN123/Fall-Detection"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "qiaoguan/Fall-detection"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "cwlroda/falldetection_openpifpaf"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "taufeeque9/HumanFallDetection"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "chizhanyuefeng/FD-CNN"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "chizhanyuefeng/Realtime-Fall-Detection-for-RNN"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "harishrithish7/Fall-Detection"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "kasakun/Fall-Detection"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "vietdzung/fall-detection-two-stream-cnn"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "yjxiong/dense_flow"
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"DirtyHarryLYL/HAKE-Action-Torch" -> "DirtyHarryLYL/HAKE-Action"
"DirtyHarryLYL/HAKE-Action-Torch" -> "DirtyHarryLYL/DJ-RN"
"DirtyHarryLYL/HAKE-Action-Torch" -> "DirtyHarryLYL/HAKE"
"DirtyHarryLYL/HAKE-Action-Torch" -> "DirtyHarryLYL/HOI-Learning-List"
"DirtyHarryLYL/HAKE-Action-Torch" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"DirtyHarryLYL/HAKE-Action-Torch" -> "vt-vl-lab/DRG"
"DirtyHarryLYL/HAKE-Action-Torch" -> "vaesl/IP-Net"
"DirtyHarryLYL/HAKE-Action-Torch" -> "BigRedT/no_frills_hoi_det"
"DirtyHarryLYL/HAKE-Action-Torch" -> "chinancheng/awesome-human-object-interaction"
"DirtyHarryLYL/HAKE-Action-Torch" -> "hitachi-rd-cv/qpic"
"DirtyHarryLYL/HAKE-Action-Torch" -> "DirtyHarryLYL/SymNet"
"DirtyHarryLYL/HAKE-Action-Torch" -> "s-gupta/v-coco"
"DirtyHarryLYL/HAKE-Action-Torch" -> "fredzzhang/spatio-attentive-graphs"
"DirtyHarryLYL/HAKE-Action-Torch" -> "cjw2021/QAHOI"
"DirtyHarryLYL/HAKE-Action-Torch" -> "bobwan1995/PMFNet"
"IBM/action-recognition-pytorch" -> "Phoenix1327/tea-action-recognition"
"IBM/action-recognition-pytorch" -> "swathikirans/GSM"
"IBM/action-recognition-pytorch" -> "decisionforce/TPN"
"IBM/action-recognition-pytorch" -> "MCG-NJU/TDN"
"IBM/action-recognition-pytorch" -> "Chuhanxx/Temporal_Query_Networks"
"IBM/action-recognition-pytorch" -> "arunos728/MotionSqueeze"
"IBM/action-recognition-pytorch" -> "joaanna/something_else"
"IBM/action-recognition-pytorch" -> "zhang-can/PAN-PyTorch"
"IBM/action-recognition-pytorch" -> "s9xie/Mini-Kinetics-200"
"IBM/action-recognition-pytorch" -> "kkahatapitiya/X3D-Multigrid"
"IBM/action-recognition-pytorch" -> "laura-wang/video-pace" ["e"=1]
"IBM/action-recognition-pytorch" -> "V-Sense/ACTION-Net"
"MCG-NJU/TDN" -> "Phoenix1327/tea-action-recognition"
"MCG-NJU/TDN" -> "V-Sense/ACTION-Net"
"MCG-NJU/TDN" -> "liu-zhy/temporal-adaptive-module"
"MCG-NJU/TDN" -> "decisionforce/TPN"
"MCG-NJU/TDN" -> "zhang-can/PAN-PyTorch"
"MCG-NJU/TDN" -> "mit-han-lab/temporal-shift-module"
"MCG-NJU/TDN" -> "arunos728/MotionSqueeze"
"MCG-NJU/TDN" -> "MCG-NJU/MOC-Detector"
"MCG-NJU/TDN" -> "swathikirans/GSM"
"MCG-NJU/TDN" -> "IBM/action-recognition-pytorch"
"MCG-NJU/TDN" -> "zhoubolei/TRN-pytorch"
"MCG-NJU/TDN" -> "MCG-NJU/CPD-Video"
"MCG-NJU/TDN" -> "SwinTransformer/Video-Swin-Transformer"
"MCG-NJU/TDN" -> "yjxiong/tsn-pytorch"
"MCG-NJU/TDN" -> "sallymmx/ActionCLIP"
"Phoenix1327/tea-action-recognition" -> "MCG-NJU/TDN"
"Phoenix1327/tea-action-recognition" -> "V-Sense/ACTION-Net"
"Phoenix1327/tea-action-recognition" -> "arunos728/MotionSqueeze"
"Phoenix1327/tea-action-recognition" -> "decisionforce/TPN"
"Phoenix1327/tea-action-recognition" -> "zhang-can/PAN-PyTorch"
"Phoenix1327/tea-action-recognition" -> "liu-zhy/temporal-adaptive-module"
"Phoenix1327/tea-action-recognition" -> "swathikirans/GSM"
"Phoenix1327/tea-action-recognition" -> "deepcs233/TIN"
"Phoenix1327/tea-action-recognition" -> "IBM/action-recognition-pytorch"
"Phoenix1327/tea-action-recognition" -> "joaanna/something_else"
"Phoenix1327/tea-action-recognition" -> "MCG-NJU/MOC-Detector"
"Phoenix1327/tea-action-recognition" -> "zhoubolei/TRN-pytorch"
"Phoenix1327/tea-action-recognition" -> "StanfordVL/RubiksNet"
"PyAV-Org/PyAV" -> "dmlc/decord"
"PyAV-Org/PyAV" -> "NVIDIA/VideoProcessingFramework" ["e"=1]
"PyAV-Org/PyAV" -> "aiortc/aiortc" ["e"=1]
"PyAV-Org/PyAV" -> "kkroening/ffmpeg-python" ["e"=1]
"PyAV-Org/PyAV" -> "abhiTronix/vidgear"
"PyAV-Org/PyAV" -> "aminyazdanpanah/python-ffmpeg-video-streaming"
"PyAV-Org/PyAV" -> "facebookresearch/pytorchvideo"
"PyAV-Org/PyAV" -> "imageio/imageio-ffmpeg"
"PyAV-Org/PyAV" -> "facebookresearch/TimeSformer"
"PyAV-Org/PyAV" -> "Breakthrough/PySceneDetect"
"PyAV-Org/PyAV" -> "imageio/imageio"
"PyAV-Org/PyAV" -> "jeffbass/imagezmq" ["e"=1]
"PyAV-Org/PyAV" -> "vadimkantorov/mpegflow"
"PyAV-Org/PyAV" -> "abhiTronix/deffcode"
"Showmax/kinetics-downloader" -> "piaxar/kinetics-downloader"
"Showmax/kinetics-downloader" -> "activitynet/ActivityNet"
"Showmax/kinetics-downloader" -> "dancelogue/kinetics-datasets-downloader"
"Showmax/kinetics-downloader" -> "arunos728/MotionSqueeze"
"Showmax/kinetics-downloader" -> "qijiezhao/py-denseflow"
"Showmax/kinetics-downloader" -> "decisionforce/TPN"
"Showmax/kinetics-downloader" -> "cvdfoundation/kinetics-dataset"
"Showmax/kinetics-downloader" -> "hassony2/inflated_convnets_pytorch"
"Showmax/kinetics-downloader" -> "gsig/PyVideoResearch"
"Showmax/kinetics-downloader" -> "chaoyuaw/pytorch-coviar"
"Showmax/kinetics-downloader" -> "qijiezhao/s3d.pytorch"
"Showmax/kinetics-downloader" -> "antoine77340/MIL-NCE_HowTo100M" ["e"=1]
"Showmax/kinetics-downloader" -> "r1ch88/SlowFastNetworks"
"Showmax/kinetics-downloader" -> "piergiaj/pytorch-i3d"
"Showmax/kinetics-downloader" -> "hassony2/kinetics_i3d_pytorch"
"StanfordVL/RubiksNet" -> "arunos728/MotionSqueeze"
"StanfordVL/RubiksNet" -> "deepcs233/TIN"
"SwinTransformer/Video-Swin-Transformer" -> "facebookresearch/TimeSformer"
"SwinTransformer/Video-Swin-Transformer" -> "open-mmlab/mmaction2"
"SwinTransformer/Video-Swin-Transformer" -> "haofanwang/video-swin-transformer-pytorch"
"SwinTransformer/Video-Swin-Transformer" -> "MCG-NJU/VideoMAE"
"SwinTransformer/Video-Swin-Transformer" -> "cvdfoundation/kinetics-dataset"
"SwinTransformer/Video-Swin-Transformer" -> "rishikksh20/ViViT-pytorch"
"SwinTransformer/Video-Swin-Transformer" -> "lucidrains/TimeSformer-pytorch"
"SwinTransformer/Video-Swin-Transformer" -> "mit-han-lab/temporal-shift-module"
"SwinTransformer/Video-Swin-Transformer" -> "Sense-X/UniFormer"
"SwinTransformer/Video-Swin-Transformer" -> "MCG-NJU/TDN"
"SwinTransformer/Video-Swin-Transformer" -> "sallymmx/ActionCLIP"
"SwinTransformer/Video-Swin-Transformer" -> "facebookresearch/SlowFast"
"SwinTransformer/Video-Swin-Transformer" -> "google-research/scenic"
"SwinTransformer/Video-Swin-Transformer" -> "piergiaj/pytorch-i3d"
"SwinTransformer/Video-Swin-Transformer" -> "jayleicn/ClipBERT" ["e"=1]
"Tushar-N/pytorch-resnet3d" -> "tomrunia/PyTorchConv3D"
"Tushar-N/pytorch-resnet3d" -> "piergiaj/pytorch-i3d"
"Tushar-N/pytorch-resnet3d" -> "seominseok0429/Real-world-Anomaly-Detection-in-Surveillance-Videos-pytorch" ["e"=1]
"Tushar-N/pytorch-resnet3d" -> "Roc-Ng/XDVioDet" ["e"=1]
"Tushar-N/pytorch-resnet3d" -> "GowthamGottimukkala/I3D_Feature_Extraction_resnet"
"Tushar-N/pytorch-resnet3d" -> "tianyu0207/RTFM" ["e"=1]
"Tushar-N/pytorch-resnet3d" -> "hassony2/kinetics_i3d_pytorch"
"Tushar-N/pytorch-resnet3d" -> "feiyunzhang/i3d-non-local-pytorch"
"Tushar-N/pytorch-resnet3d" -> "louisYen/S3R" ["e"=1]
"Tushar-N/pytorch-resnet3d" -> "jx-zhong-for-academic-purpose/GCN-Anomaly-Detection" ["e"=1]
"Tushar-N/pytorch-resnet3d" -> "s9xie/Mini-Kinetics-200"
"Tushar-N/pytorch-resnet3d" -> "fjchange/MIST_VAD" ["e"=1]
"Tushar-N/pytorch-resnet3d" -> "joaanna/something_else"
"Tushar-N/pytorch-resnet3d" -> "USTC-Video-Understanding/I3D_Finetune"
"Tushar-N/pytorch-resnet3d" -> "hassony2/torch_videovision"
"V-Sense/ACTION-Net" -> "Phoenix1327/tea-action-recognition"
"V-Sense/ACTION-Net" -> "MCG-NJU/TDN"
"V-Sense/ACTION-Net" -> "liu-zhy/temporal-adaptive-module"
"V-Sense/ACTION-Net" -> "arunos728/MotionSqueeze"
"V-Sense/ACTION-Net" -> "tianyuan168326/EAN-Pytorch"
"V-Sense/ACTION-Net" -> "decisionforce/TPN"
"V-Sense/ACTION-Net" -> "zhang-can/PAN-PyTorch"
"V-Sense/ACTION-Net" -> "swathikirans/GSM"
"V-Sense/ACTION-Net" -> "artest08/LateTemporalModeling3DCNN"
"activitynet/ActivityNet" -> "yjxiong/action-detection"
"activitynet/ActivityNet" -> "yjxiong/temporal-segment-networks"
"activitynet/ActivityNet" -> "deepmind/kinetics-i3d"
"activitynet/ActivityNet" -> "yjxiong/tsn-pytorch"
"activitynet/ActivityNet" -> "wzmsltw/BSN-boundary-sensitive-network"
"activitynet/ActivityNet" -> "open-mmlab/mmaction"
"activitynet/ActivityNet" -> "facebookresearch/video-nonlocal-net"
"activitynet/ActivityNet" -> "facebookresearch/VMZ"
"activitynet/ActivityNet" -> "feichtenhofer/twostreamfusion"
"activitynet/ActivityNet" -> "piergiaj/pytorch-i3d"
"activitynet/ActivityNet" -> "mit-han-lab/temporal-shift-module"
"activitynet/ActivityNet" -> "kenshohara/3D-ResNets-PyTorch"
"activitynet/ActivityNet" -> "metalbubble/TRN-pytorch"
"activitynet/ActivityNet" -> "hassony2/kinetics_i3d_pytorch"
"activitynet/ActivityNet" -> "cvdfoundation/ava-dataset"
"arunos728/MotionSqueeze" -> "Phoenix1327/tea-action-recognition"
"arunos728/MotionSqueeze" -> "StanfordVL/RubiksNet"
"arunos728/MotionSqueeze" -> "deepcs233/TIN"
"arunos728/MotionSqueeze" -> "zhang-can/PAN-PyTorch"
"arunos728/MotionSqueeze" -> "KimManjin/RSA"
"arunos728/MotionSqueeze" -> "swathikirans/GSM"
"arunos728/MotionSqueeze" -> "arunos728/SELFY"
"arunos728/MotionSqueeze" -> "xhl-video/SmallBigNet"
"arunos728/MotionSqueeze" -> "decisionforce/TPN"
"arunos728/MotionSqueeze" -> "Andy1621/CT-Net"
"arunos728/MotionSqueeze" -> "V-Sense/ACTION-Net"
"arunos728/MotionSqueeze" -> "mengyuest/AR-Net" ["e"=1]
"arunos728/MotionSqueeze" -> "MCG-NJU/TDN"
"arunos728/MotionSqueeze" -> "chenxuluo/GST-video"
"bomri/SlowFast" -> "elb3k/vtn"
"chaoyuaw/pytorch-coviar" -> "yjxiong/tsn-pytorch"
"chaoyuaw/pytorch-coviar" -> "piergiaj/representation-flow-cvpr19"
"chaoyuaw/pytorch-coviar" -> "facebookresearch/dmc-net"
"chaoyuaw/pytorch-coviar" -> "wanglimin/ARTNet"
"chaoyuaw/pytorch-coviar" -> "mzolfaghari/ECO-efficient-video-understanding"
"chaoyuaw/pytorch-coviar" -> "cypw/PyTorch-MFNet"
"chaoyuaw/pytorch-coviar" -> "metalbubble/TRN-pytorch"
"chaoyuaw/pytorch-coviar" -> "feichtenhofer/twostreamfusion"
"chaoyuaw/pytorch-coviar" -> "gsig/PyVideoResearch"
"chaoyuaw/pytorch-coviar" -> "wzmsltw/BSN-boundary-sensitive-network"
"chaoyuaw/pytorch-coviar" -> "yjxiong/action-detection"
"chaoyuaw/pytorch-coviar" -> "open-mmlab/mmaction"
"chaoyuaw/pytorch-coviar" -> "jeffreyhuang1/two-stream-action-recognition"
"chaoyuaw/pytorch-coviar" -> "yjxiong/temporal-segment-networks"
"chaoyuaw/pytorch-coviar" -> "yoosan/video-understanding-dataset"
"decisionforce/TPN" -> "zhoubolei/TRN-pytorch"
"decisionforce/TPN" -> "Phoenix1327/tea-action-recognition"
"decisionforce/TPN" -> "swathikirans/GSM"
"decisionforce/TPN" -> "MCG-NJU/TDN"
"decisionforce/TPN" -> "r1ch88/SlowFastNetworks"
"decisionforce/TPN" -> "arunos728/MotionSqueeze"
"decisionforce/TPN" -> "open-mmlab/mmaction"
"decisionforce/TPN" -> "Rheelt/Materials-Temporal-Action-Detection"
"decisionforce/TPN" -> "craston/MARS"
"decisionforce/TPN" -> "Sense-X/X-Temporal" ["e"=1]
"decisionforce/TPN" -> "mit-han-lab/temporal-shift-module"
"decisionforce/TPN" -> "Alvin-Zeng/PGCN"
"decisionforce/TPN" -> "yjxiong/tsn-pytorch"
"decisionforce/TPN" -> "piergiaj/representation-flow-cvpr19"
"decisionforce/TPN" -> "mzolfaghari/ECO-pytorch"
"deepcs233/TIN" -> "swathikirans/GSM"
"deepcs233/TIN" -> "xhl-video/SmallBigNet"
"deepcs233/TIN" -> "chenxuluo/GST-video"
"deepcs233/TIN" -> "arunos728/MotionSqueeze"
"deepcs233/TIN" -> "zhang-can/PAN-PyTorch"
"deepcs233/TIN" -> "Phoenix1327/tea-action-recognition"
"deepmind/kinetics-i3d" -> "piergiaj/pytorch-i3d"
"deepmind/kinetics-i3d" -> "hassony2/kinetics_i3d_pytorch"
"deepmind/kinetics-i3d" -> "yjxiong/temporal-segment-networks"
"deepmind/kinetics-i3d" -> "yjxiong/tsn-pytorch"
"deepmind/kinetics-i3d" -> "activitynet/ActivityNet"
"deepmind/kinetics-i3d" -> "kenshohara/3D-ResNets-PyTorch"
"deepmind/kinetics-i3d" -> "facebookresearch/video-nonlocal-net"
"deepmind/kinetics-i3d" -> "jinwchoi/awesome-action-recognition"
"deepmind/kinetics-i3d" -> "facebookresearch/VMZ"
"deepmind/kinetics-i3d" -> "open-mmlab/mmaction"
"deepmind/kinetics-i3d" -> "feichtenhofer/twostreamfusion"
"deepmind/kinetics-i3d" -> "yjxiong/action-detection"
"deepmind/kinetics-i3d" -> "kenshohara/video-classification-3d-cnn-pytorch"
"deepmind/kinetics-i3d" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"deepmind/kinetics-i3d" -> "feichtenhofer/gpu_flow"
"dukebw/lintel" -> "piergiaj/representation-flow-cvpr19"
"dukebw/lintel" -> "chaoyuaw/pytorch-coviar"
"dukebw/lintel" -> "NVIDIA/nvvl"
"dukebw/lintel" -> "cypw/PyTorch-MFNet"
"facebookresearch/Motionformer" -> "sallymmx/ActionCLIP"
"facebookresearch/Motionformer" -> "airsplay/vimpac"
"facebookresearch/Motionformer" -> "fpv-iplab/rulstm" ["e"=1]
"facebookresearch/VMZ" -> "moabitcoin/ig65m-pytorch"
"facebookresearch/VMZ" -> "jfzhang95/pytorch-video-recognition"
"facebookresearch/VMZ" -> "deepmind/kinetics-i3d"
"facebookresearch/VMZ" -> "yjxiong/temporal-segment-networks"
"facebookresearch/VMZ" -> "irhum/R2Plus1D-PyTorch"
"facebookresearch/VMZ" -> "activitynet/ActivityNet"
"facebookresearch/VMZ" -> "open-mmlab/mmaction"
"facebookresearch/VMZ" -> "mit-han-lab/temporal-shift-module"
"facebookresearch/VMZ" -> "piergiaj/pytorch-i3d"
"facebookresearch/VMZ" -> "qijiezhao/pseudo-3d-pytorch"
"facebookresearch/VMZ" -> "gsig/PyVideoResearch"
"facebookresearch/VMZ" -> "yjxiong/tsn-pytorch"
"facebookresearch/VMZ" -> "kenshohara/3D-ResNets-PyTorch"
"facebookresearch/VMZ" -> "metalbubble/TRN-pytorch"
"facebookresearch/VMZ" -> "facebookresearch/video-nonlocal-net"
"feichtenhofer/twostreamfusion" -> "bryanyzhu/two-stream-pytorch"
"feichtenhofer/twostreamfusion" -> "feichtenhofer/gpu_flow"
"feichtenhofer/twostreamfusion" -> "jeffreyhuang1/two-stream-action-recognition"
"feichtenhofer/twostreamfusion" -> "jeffreyyihuang/two-stream-action-recognition"
"feichtenhofer/twostreamfusion" -> "yjxiong/temporal-segment-networks"
"feichtenhofer/twostreamfusion" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"feichtenhofer/twostreamfusion" -> "yjxiong/tsn-pytorch"
"feichtenhofer/twostreamfusion" -> "activitynet/ActivityNet"
"feichtenhofer/twostreamfusion" -> "deepmind/kinetics-i3d"
"feichtenhofer/twostreamfusion" -> "facebook/C3D"
"feichtenhofer/twostreamfusion" -> "hx173149/C3D-tensorflow"
"feichtenhofer/twostreamfusion" -> "HHTseng/video-classification"
"feichtenhofer/twostreamfusion" -> "yjxiong/caffe"
"feichtenhofer/twostreamfusion" -> "feichtenhofer/st-resnet"
"feichtenhofer/twostreamfusion" -> "kracwarlock/action-recognition-visual-attention"
"hx173149/C3D-tensorflow" -> "facebook/C3D"
"hx173149/C3D-tensorflow" -> "axon-research/c3d-keras"
"hx173149/C3D-tensorflow" -> "qijiezhao/pseudo-3d-pytorch"
"hx173149/C3D-tensorflow" -> "feichtenhofer/twostreamfusion"
"hx173149/C3D-tensorflow" -> "deepmind/kinetics-i3d"
"hx173149/C3D-tensorflow" -> "yjxiong/temporal-segment-networks"
"hx173149/C3D-tensorflow" -> "jeffreyhuang1/two-stream-action-recognition"
"hx173149/C3D-tensorflow" -> "VisionLearningGroup/R-C3D"
"hx173149/C3D-tensorflow" -> "DavideA/c3d-pytorch"
"hx173149/C3D-tensorflow" -> "jfzhang95/pytorch-video-recognition"
"hx173149/C3D-tensorflow" -> "TianzhongSong/C3D-keras"
"hx173149/C3D-tensorflow" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"hx173149/C3D-tensorflow" -> "2012013382/C3D-Tensorflow-slim"
"hx173149/C3D-tensorflow" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"hx173149/C3D-tensorflow" -> "feichtenhofer/gpu_flow"
"irhum/R2Plus1D-PyTorch" -> "leftthomas/R2Plus1D-C3D"
"irhum/R2Plus1D-PyTorch" -> "facebookresearch/VMZ"
"irhum/R2Plus1D-PyTorch" -> "r1ch88/SlowFastNetworks"
"irhum/R2Plus1D-PyTorch" -> "piergiaj/representation-flow-cvpr19"
"irhum/R2Plus1D-PyTorch" -> "jfzhang95/pytorch-video-recognition"
"irhum/R2Plus1D-PyTorch" -> "qijiezhao/pseudo-3d-pytorch"
"irhum/R2Plus1D-PyTorch" -> "craston/MARS"
"irhum/R2Plus1D-PyTorch" -> "moabitcoin/ig65m-pytorch"
"irhum/R2Plus1D-PyTorch" -> "swathikirans/GSM"
"irhum/R2Plus1D-PyTorch" -> "juenkhaw/action_recognition_project"
"joaanna/something_else" -> "gorjanradevski/revisiting-spatial-temporal-layouts"
"joaanna/something_else" -> "JingweiJ/ActionGenome" ["e"=1]
"joaanna/something_else" -> "Phoenix1327/tea-action-recognition"
"ju-chen/Efficient-Prompt" -> "TengdaHan/TemporalAlignNet" ["e"=1]
"ju-chen/Efficient-Prompt" -> "OpenGVLab/efficient-video-recognition"
"ju-chen/Efficient-Prompt" -> "sauradip/STALE"
"ju-chen/Efficient-Prompt" -> "sallymmx/ActionCLIP"
"ju-chen/Efficient-Prompt" -> "ttlmh/Bridge-Prompt"
"ju-chen/Efficient-Prompt" -> "jayleicn/singularity" ["e"=1]
"kylemin/S3D" -> "qijiezhao/s3d.pytorch"
"kylemin/S3D" -> "antoine77340/S3D_HowTo100M" ["e"=1]
"kylemin/S3D" -> "sjenni/temporal-ssl" ["e"=1]
"kylemin/S3D" -> "MichiganCOG/TASED-Net" ["e"=1]
"lucidrains/TimeSformer-pytorch" -> "facebookresearch/TimeSformer"
"lucidrains/TimeSformer-pytorch" -> "SwinTransformer/Video-Swin-Transformer"
"lucidrains/TimeSformer-pytorch" -> "Alibaba-MIIL/STAM"
"lucidrains/TimeSformer-pytorch" -> "decisionforce/TPN"
"lucidrains/TimeSformer-pytorch" -> "MCG-NJU/TDN"
"lucidrains/TimeSformer-pytorch" -> "rishikksh20/ViViT-pytorch"
"lucidrains/TimeSformer-pytorch" -> "davide-coccomini/TimeSformer-Video-Classification"
"lucidrains/TimeSformer-pytorch" -> "sallymmx/ActionCLIP"
"lucidrains/TimeSformer-pytorch" -> "V-Sense/ACTION-Net"
"lucidrains/TimeSformer-pytorch" -> "mit-han-lab/temporal-shift-module"
"lucidrains/TimeSformer-pytorch" -> "lucidrains/STAM-pytorch"
"lucidrains/TimeSformer-pytorch" -> "facebookresearch/pytorchvideo"
"lucidrains/TimeSformer-pytorch" -> "yitu-opensource/T2T-ViT" ["e"=1]
"lucidrains/TimeSformer-pytorch" -> "antoine77340/MIL-NCE_HowTo100M" ["e"=1]
"lucidrains/TimeSformer-pytorch" -> "swathikirans/GSM"
"metalbubble/TRN-pytorch" -> "mzolfaghari/ECO-efficient-video-understanding"
"metalbubble/TRN-pytorch" -> "yjxiong/action-detection"
"metalbubble/TRN-pytorch" -> "yjxiong/tsn-pytorch"
"metalbubble/TRN-pytorch" -> "mzolfaghari/ECO-pytorch"
"metalbubble/TRN-pytorch" -> "metalbubble/moments_models"
"metalbubble/TRN-pytorch" -> "qijiezhao/pseudo-3d-pytorch"
"metalbubble/TRN-pytorch" -> "wanglimin/ARTNet"
"metalbubble/TRN-pytorch" -> "cypw/PyTorch-MFNet"
"metalbubble/TRN-pytorch" -> "yjxiong/temporal-segment-networks"
"metalbubble/TRN-pytorch" -> "wzmsltw/BSN-boundary-sensitive-network"
"metalbubble/TRN-pytorch" -> "gurkirt/realtime-action-detection"
"metalbubble/TRN-pytorch" -> "hassony2/kinetics_i3d_pytorch"
"metalbubble/TRN-pytorch" -> "activitynet/ActivityNet"
"metalbubble/TRN-pytorch" -> "jeffreyhuang1/two-stream-action-recognition"
"metalbubble/TRN-pytorch" -> "facebookresearch/VMZ"
"mit-han-lab/temporal-shift-module" -> "yjxiong/temporal-segment-networks"
"mit-han-lab/temporal-shift-module" -> "open-mmlab/mmaction"
"mit-han-lab/temporal-shift-module" -> "yjxiong/tsn-pytorch"
"mit-han-lab/temporal-shift-module" -> "facebookresearch/SlowFast"
"mit-han-lab/temporal-shift-module" -> "facebookresearch/video-nonlocal-net"
"mit-han-lab/temporal-shift-module" -> "open-mmlab/mmaction2"
"mit-han-lab/temporal-shift-module" -> "kenshohara/3D-ResNets-PyTorch"
"mit-han-lab/temporal-shift-module" -> "facebookresearch/VMZ"
"mit-han-lab/temporal-shift-module" -> "MCG-NJU/TDN"
"mit-han-lab/temporal-shift-module" -> "decisionforce/TPN"
"mit-han-lab/temporal-shift-module" -> "activitynet/ActivityNet"
"mit-han-lab/temporal-shift-module" -> "piergiaj/pytorch-i3d"
"mit-han-lab/temporal-shift-module" -> "jinwchoi/awesome-action-recognition"
"mit-han-lab/temporal-shift-module" -> "deepmind/kinetics-i3d"
"mit-han-lab/temporal-shift-module" -> "jfzhang95/pytorch-video-recognition"
"moabitcoin/ig65m-pytorch" -> "facebookresearch/VMZ"
"moabitcoin/ig65m-pytorch" -> "antoine77340/S3D_HowTo100M" ["e"=1]
"moabitcoin/ig65m-pytorch" -> "antoine77340/MIL-NCE_HowTo100M" ["e"=1]
"moabitcoin/ig65m-pytorch" -> "irhum/R2Plus1D-PyTorch"
"moabitcoin/ig65m-pytorch" -> "artest08/LateTemporalModeling3DCNN"
"moabitcoin/ig65m-pytorch" -> "decisionforce/TPN"
"moabitcoin/ig65m-pytorch" -> "leftthomas/R2Plus1D-C3D"
"moabitcoin/ig65m-pytorch" -> "m-bain/frozen-in-time" ["e"=1]
"mx-mark/VideoTransformer-pytorch" -> "rishikksh20/ViViT-pytorch"
"mx-mark/VideoTransformer-pytorch" -> "haofanwang/video-swin-transformer-pytorch"
"mx-mark/VideoTransformer-pytorch" -> "facebookresearch/Motionformer"
"noureldien/timeception" -> "piergiaj/tgm-icml19"
"noureldien/timeception" -> "facebookresearch/video-long-term-feature-banks"
"noureldien/timeception" -> "piergiaj/representation-flow-cvpr19"
"noureldien/timeception" -> "cypw/PyTorch-MFNet"
"piergiaj/pytorch-i3d" -> "hassony2/kinetics_i3d_pytorch"
"piergiaj/pytorch-i3d" -> "deepmind/kinetics-i3d"
"piergiaj/pytorch-i3d" -> "yjxiong/temporal-segment-networks"
"piergiaj/pytorch-i3d" -> "yjxiong/tsn-pytorch"
"piergiaj/pytorch-i3d" -> "jfzhang95/pytorch-video-recognition"
"piergiaj/pytorch-i3d" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"piergiaj/pytorch-i3d" -> "open-mmlab/mmaction"
"piergiaj/pytorch-i3d" -> "tomrunia/PyTorchConv3D"
"piergiaj/pytorch-i3d" -> "facebookresearch/VMZ"
"piergiaj/pytorch-i3d" -> "activitynet/ActivityNet"
"piergiaj/pytorch-i3d" -> "kenshohara/3D-ResNets-PyTorch"
"piergiaj/pytorch-i3d" -> "mit-han-lab/temporal-shift-module"
"piergiaj/pytorch-i3d" -> "Alvin-Zeng/PGCN"
"piergiaj/pytorch-i3d" -> "Finspire13/CMCS-Temporal-Action-Localization"
"piergiaj/pytorch-i3d" -> "kenshohara/video-classification-3d-cnn-pytorch"
"piergiaj/tgm-icml19" -> "Rheelt/Materials-Temporal-Action-Detection"
"piergiaj/tgm-icml19" -> "JiaHeeeee/Deep_Learning_Temporal_Action_Detection"
"piergiaj/tgm-icml19" -> "Finspire13/CMCS-Temporal-Action-Localization"
"piergiaj/tgm-icml19" -> "JunLi-Galios/CDFL"
"piergiaj/tgm-icml19" -> "demianzhang/weakly-action-localization"
"piergiaj/tgm-icml19" -> "sujoyp/wtalc-pytorch"
"piergiaj/tgm-icml19" -> "HYPJUDY/Decouple-SSAD"
"piergiaj/tgm-icml19" -> "jiyanggao/CTAP"
"piergiaj/tgm-icml19" -> "bellos1203/STPN"
"qijiezhao/pseudo-3d-pytorch" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"qijiezhao/pseudo-3d-pytorch" -> "hassony2/kinetics_i3d_pytorch"
"qijiezhao/pseudo-3d-pytorch" -> "yjxiong/tsn-pytorch"
"qijiezhao/pseudo-3d-pytorch" -> "metalbubble/TRN-pytorch"
"qijiezhao/pseudo-3d-pytorch" -> "bryanyzhu/two-stream-pytorch"
"qijiezhao/pseudo-3d-pytorch" -> "hx173149/C3D-tensorflow"
"qijiezhao/pseudo-3d-pytorch" -> "facebookresearch/VMZ"
"qijiezhao/pseudo-3d-pytorch" -> "jfzhang95/pytorch-video-recognition"
"qijiezhao/pseudo-3d-pytorch" -> "kenshohara/video-classification-3d-cnn-pytorch"
"qijiezhao/pseudo-3d-pytorch" -> "mzolfaghari/ECO-efficient-video-understanding"
"qijiezhao/pseudo-3d-pytorch" -> "deepmind/kinetics-i3d"
"qijiezhao/pseudo-3d-pytorch" -> "yjxiong/temporal-segment-networks"
"qijiezhao/pseudo-3d-pytorch" -> "activitynet/ActivityNet"
"qijiezhao/pseudo-3d-pytorch" -> "qijiezhao/s3d.pytorch"
"qijiezhao/pseudo-3d-pytorch" -> "feichtenhofer/twostreamfusion"
"qijiezhao/s3d.pytorch" -> "kylemin/S3D"
"qijiezhao/s3d.pytorch" -> "qijiezhao/py-denseflow"
"qijiezhao/s3d.pytorch" -> "irhumshafkat/R2Plus1D-PyTorch"
"qijiezhao/s3d.pytorch" -> "coderSkyChen/Action_Recognition_Zoo"
"r1ch88/SlowFastNetworks" -> "decisionforce/TPN"
"r1ch88/SlowFastNetworks" -> "JJBOY/SlowFast-Network"
"r1ch88/SlowFastNetworks" -> "Guocode/SlowFast-Networks"
"r1ch88/SlowFastNetworks" -> "xuzheyuan624/slowfast-keras"
"r1ch88/SlowFastNetworks" -> "irhum/R2Plus1D-PyTorch"
"r1ch88/SlowFastNetworks" -> "piergiaj/representation-flow-cvpr19"
"r1ch88/SlowFastNetworks" -> "jfzhang95/pytorch-video-recognition"
"r1ch88/SlowFastNetworks" -> "noureldien/timeception"
"r1ch88/SlowFastNetworks" -> "mzolfaghari/ECO-pytorch"
"r1ch88/SlowFastNetworks" -> "ZhaofanQiu/local-and-global-diffusion-networks"
"r1ch88/SlowFastNetworks" -> "yjxiong/tsn-pytorch"
"r1ch88/SlowFastNetworks" -> "facebookresearch/video-long-term-feature-banks"
"r1ch88/SlowFastNetworks" -> "HYPJUDY/Decouple-SSAD"
"r1ch88/SlowFastNetworks" -> "facebookresearch/VMZ"
"rishikksh20/ViViT-pytorch" -> "mx-mark/VideoTransformer-pytorch"
"rishikksh20/ViViT-pytorch" -> "drv-agwl/ViViT-pytorch"
"rishikksh20/ViViT-pytorch" -> "lucidrains/STAM-pytorch"
"rishikksh20/ViViT-pytorch" -> "facebookresearch/TimeSformer"
"rishikksh20/ViViT-pytorch" -> "SwinTransformer/Video-Swin-Transformer"
"rishikksh20/ViViT-pytorch" -> "bomri/SlowFast"
"rishikksh20/ViViT-pytorch" -> "google-research/scenic"
"rishikksh20/ViViT-pytorch" -> "lucidrains/TimeSformer-pytorch"
"rishikksh20/ViViT-pytorch" -> "antoine77340/MIL-NCE_HowTo100M" ["e"=1]
"rishikksh20/ViViT-pytorch" -> "haofanwang/video-swin-transformer-pytorch"
"rishikksh20/ViViT-pytorch" -> "facebookresearch/Motionformer"
"rishikksh20/ViViT-pytorch" -> "Alibaba-MIIL/STAM"
"rishikksh20/ViViT-pytorch" -> "sallymmx/ActionCLIP"
"rishikksh20/ViViT-pytorch" -> "facebookresearch/AVT" ["e"=1]
"rishikksh20/ViViT-pytorch" -> "wangxiang1230/OadTR"
"sallymmx/ActionCLIP" -> "ju-chen/Efficient-Prompt"
"sallymmx/ActionCLIP" -> "microsoft/VideoX"
"sallymmx/ActionCLIP" -> "ArrowLuo/CLIP4Clip" ["e"=1]
"sallymmx/ActionCLIP" -> "raoyongming/DenseCLIP" ["e"=1]
"sallymmx/ActionCLIP" -> "CryhanFang/CLIP2Video" ["e"=1]
"sallymmx/ActionCLIP" -> "ttlmh/Bridge-Prompt"
"sallymmx/ActionCLIP" -> "facebookresearch/Motionformer"
"sallymmx/ActionCLIP" -> "HumamAlwassel/TSP"
"sallymmx/ActionCLIP" -> "KaiyangZhou/CoOp" ["e"=1]
"sallymmx/ActionCLIP" -> "OpenGVLab/efficient-video-recognition"
"sallymmx/ActionCLIP" -> "m-bain/frozen-in-time" ["e"=1]
"sallymmx/ActionCLIP" -> "SwinTransformer/Video-Swin-Transformer"
"sallymmx/ActionCLIP" -> "MCG-NJU/TDN"
"sallymmx/ActionCLIP" -> "MCG-NJU/VideoMAE"
"sallymmx/ActionCLIP" -> "jayleicn/singularity" ["e"=1]
"scikit-video/scikit-video" -> "lidq92/VSFA" ["e"=1]
"scikit-video/scikit-video" -> "vztu/BVQA_Benchmark" ["e"=1]
"scikit-video/scikit-video" -> "vadimkantorov/mpegflow"
"scikit-video/scikit-video" -> "yoosan/video-understanding-dataset"
"scikit-video/scikit-video" -> "rohitgirdhar/ActionVLAD"
"scikit-video/scikit-video" -> "phoenix104104/fast_blind_video_consistency" ["e"=1]
"smellslikeml/ActionAI" -> "felixchenfy/Realtime-Action-Recognition"
"smellslikeml/ActionAI" -> "dronefreak/human-action-classification"
"smellslikeml/ActionAI" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"smellslikeml/ActionAI" -> "TianzhongSong/Real-Time-Action-Recognition"
"smellslikeml/ActionAI" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"smellslikeml/ActionAI" -> "stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
"smellslikeml/ActionAI" -> "NVIDIA-AI-IOT/trt_pose" ["e"=1]
"smellslikeml/ActionAI" -> "dluvizon/deephar"
"smellslikeml/ActionAI" -> "noboevbo/ehpi_action_recognition"
"smellslikeml/ActionAI" -> "cwlroda/falldetection_openpifpaf"
"smellslikeml/ActionAI" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"smellslikeml/ActionAI" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"smellslikeml/ActionAI" -> "NVIDIA-AI-IOT/deepstream_pose_estimation" ["e"=1]
"smellslikeml/ActionAI" -> "open-mmlab/mmskeleton"
"smellslikeml/ActionAI" -> "taufeeque9/HumanFallDetection"
"swathikirans/GSM" -> "deepcs233/TIN"
"swathikirans/GSM" -> "chenxuluo/GST-video"
"swathikirans/GSM" -> "decisionforce/TPN"
"swathikirans/GSM" -> "zhang-can/PAN-PyTorch"
"swathikirans/GSM" -> "Phoenix1327/tea-action-recognition"
"swathikirans/GSM" -> "arunos728/MotionSqueeze"
"swathikirans/GSM" -> "IBM/bLVNet-TAM"
"swathikirans/GSM" -> "xhl-video/SmallBigNet"
"swathikirans/GSM" -> "MCG-NJU/TDN"
"swathikirans/GSM" -> "craston/MARS"
"wanglimin/ARTNet" -> "wanglimin/UntrimmedNet"
"wanglimin/ARTNet" -> "metalbubble/TRN-pytorch"
"wanglimin/ARTNet" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"wanglimin/ARTNet" -> "facebookresearch/R2Plus1D"
"wanglimin/ARTNet" -> "rohitgirdhar/ActionVLAD"
"wanglimin/ARTNet" -> "feichtenhofer/st-resnet"
"wanglimin/ARTNet" -> "yjxiong/action-detection"
"wanglimin/ARTNet" -> "mzolfaghari/ECO-efficient-video-understanding"
"wanglimin/ARTNet" -> "VisionLearningGroup/R-C3D"
"wanglimin/ARTNet" -> "bryanyzhu/Hidden-Two-Stream"
"wanglimin/ARTNet" -> "chaoyuaw/pytorch-coviar"
"wanglimin/ARTNet" -> "yjxiong/anet2016-cuhk"
"wanglimin/ARTNet" -> "cypw/PyTorch-MFNet"
"wanglimin/ARTNet" -> "qijiezhao/py-denseflow"
"xhl-video/SmallBigNet" -> "deepcs233/TIN"
"yoosan/video-understanding-dataset" -> "metalbubble/moments_models"
"yoosan/video-understanding-dataset" -> "mzolfaghari/ECO-efficient-video-understanding"
"yoosan/video-understanding-dataset" -> "yjxiong/tsn-pytorch"
"yoosan/video-understanding-dataset" -> "activitynet/ActivityNet"
"yoosan/video-understanding-dataset" -> "hassony2/kinetics_i3d_pytorch"
"yoosan/video-understanding-dataset" -> "yjxiong/action-detection"
"yoosan/video-understanding-dataset" -> "LisaAnne/LocalizingMoments" ["e"=1]
"yoosan/video-understanding-dataset" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"yoosan/video-understanding-dataset" -> "chaoyuaw/pytorch-coviar"
"yoosan/video-understanding-dataset" -> "feichtenhofer/gpu_flow"
"yoosan/video-understanding-dataset" -> "antoine77340/Youtube-8M-WILLOW"
"yoosan/video-understanding-dataset" -> "deepmind/kinetics-i3d"
"yoosan/video-understanding-dataset" -> "gsig/PyVideoResearch"
"yoosan/video-understanding-dataset" -> "wanglimin/ARTNet"
"yoosan/video-understanding-dataset" -> "wzmsltw/BSN-boundary-sensitive-network"
"zhang-can/PAN-PyTorch" -> "Phoenix1327/tea-action-recognition"
"zhang-can/PAN-PyTorch" -> "swathikirans/GSM"
"zhang-can/PAN-PyTorch" -> "deepcs233/TIN"
"zhang-can/PAN-PyTorch" -> "arunos728/MotionSqueeze"
"zhang-can/PAN-PyTorch" -> "chenxuluo/GST-video"
"microsoft/VideoX" -> "sallymmx/ActionCLIP"
"microsoft/VideoX" -> "OpenGVLab/efficient-video-recognition"
"microsoft/VideoX" -> "microsoft/XPretrain" ["e"=1]
"microsoft/VideoX" -> "MikeWangWZHL/VidIL"
"microsoft/VideoX" -> "MCG-NJU/VideoMAE"
"microsoft/VideoX" -> "ArrowLuo/CLIP4Clip" ["e"=1]
"microsoft/VideoX" -> "muzairkhattak/ViFi-CLIP" ["e"=1]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "gsig/PyVideoResearch"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "antoine77340/video_feature_extractor" ["e"=1]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "Rheelt/Materials-Temporal-Action-Detection"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "kenshohara/video-classification-3d-cnn-pytorch"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "danieljf24/awesome-video-text-retrieval" ["e"=1]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "xiaobai1217/Awesome-Video-Datasets"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "decisionforce/TPN"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "open-mmlab/mmaction"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "krantiparida/awesome-audio-visual" ["e"=1]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "Sense-X/X-Temporal" ["e"=1]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "alexandonian/pretorched-x"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "HHTseng/video-classification"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "pliang279/awesome-multimodal-ml" ["e"=1]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "MichiganCOG/ViP" ["e"=1]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "Alvin-Zeng/PGCN"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "scivision/PyLivestream"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "abhiTronix/vidgear"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "aminyazdanpanah/PHP-FFmpeg-video-streaming"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "krzemienski/awesome-video" ["e"=1]
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "PyAV-Org/PyAV"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "vincentbernat/video2hls"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "kkroening/ffmpeg-python" ["e"=1]
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "axiomatic-systems/Bento4" ["e"=1]
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "jeffbass/imagezmq" ["e"=1]
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "escaped/django-video-encoding"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "kaltura/nginx-vod-module" ["e"=1]
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "Viblast/dash-proxy"
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "bbc/brave" ["e"=1]
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "globocom/m3u8" ["e"=1]
"aminyazdanpanah/python-ffmpeg-video-streaming" -> "just-work/django-video-transcoding"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "harvitronix/five-video-classification-methods"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "chen0040/keras-video-classifier"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "sujiongming/UCF-101_video_classification"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "SBoyNumber1/LSTM-video-classification"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "woodfrog/ActionRecognition"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "HHTseng/video-classification"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "harvitronix/continuous-online-video-classification-blog"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "vighneshvnkt/keras-deep-learning"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "kenshohara/video-classification-3d-cnn-pytorch"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "talhasaruhan/video-action-classification"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "alxcnwy/Deep-Neural-Networks-for-Video-Classification"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "pranoyr/cnn-lstm"
"sagarvegad/Video-Classification-CNN-and-LSTM-" -> "rohitgirdhar/ActionVLAD"
"videoflow/videoflow" -> "abhiTronix/vidgear"
"videoflow/videoflow" -> "chris104957/maildown"
"videoflow/videoflow" -> "perone/euclidesdb"
"videoflow/videoflow" -> "RedisGears/EdgeRealtimeVideoAnalytics"
"videoflow/videoflow" -> "bomquote/transistor"
"videoflow/videoflow" -> "videoflow/videoflow-contrib"
"videoflow/videoflow" -> "facebookresearch/pythia" ["e"=1]
"videoflow/videoflow" -> "codeforequity-at/botium-speech-processing" ["e"=1]
"videoflow/videoflow" -> "HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis"
"yjxiong/dense_flow" -> "feichtenhofer/gpu_flow"
"yjxiong/dense_flow" -> "wanglimin/dense_flow"
"yjxiong/dense_flow" -> "bryanyzhu/two-stream-pytorch"
"yjxiong/dense_flow" -> "qijiezhao/py-denseflow"
"yjxiong/dense_flow" -> "yjxiong/tsn-pytorch"
"yjxiong/dense_flow" -> "yjxiong/temporal-segment-networks"
"yjxiong/dense_flow" -> "yjxiong/action-detection"
"yjxiong/dense_flow" -> "jeffreyhuang1/two-stream-action-recognition"
"yjxiong/dense_flow" -> "feichtenhofer/twostreamfusion"
"yjxiong/dense_flow" -> "wzmsltw/BSN-boundary-sensitive-network"
"yjxiong/dense_flow" -> "hassony2/kinetics_i3d_pytorch"
"yjxiong/dense_flow" -> "open-mmlab/denseflow" ["e"=1]
"yjxiong/dense_flow" -> "yjxiong/caffe"
"yjxiong/dense_flow" -> "qijiezhao/pseudo-3d-pytorch"
"yjxiong/dense_flow" -> "USTC-Video-Understanding/I3D_Finetune"
"Sense-X/UniFormer" -> "MCG-NJU/VideoMAE"
"Sense-X/UniFormer" -> "SwinTransformer/Video-Swin-Transformer"
"Sense-X/UniFormer" -> "facebookresearch/omnivore"
"Sense-X/UniFormer" -> "sail-sg/poolformer" ["e"=1]
"Sense-X/UniFormer" -> "OpenGVLab/UniFormerV2"
"Sense-X/UniFormer" -> "facebookresearch/TimeSformer"
"Sense-X/UniFormer" -> "xxxnell/how-do-vits-work" ["e"=1]
"Sense-X/UniFormer" -> "dingmyu/davit" ["e"=1]
"Sense-X/UniFormer" -> "OpenGVLab/InternVideo"
"Sense-X/UniFormer" -> "SHI-Labs/Neighborhood-Attention-Transformer" ["e"=1]
"Sense-X/UniFormer" -> "sallymmx/ActionCLIP"
"Sense-X/UniFormer" -> "NVlabs/FAN" ["e"=1]
"Sense-X/UniFormer" -> "czczup/ViT-Adapter" ["e"=1]
"Sense-X/UniFormer" -> "MCG-NJU/TDN"
"Sense-X/UniFormer" -> "raoyongming/DenseCLIP" ["e"=1]
"DirtyHarryLYL/HAKE" -> "DirtyHarryLYL/HAKE-Action"
"DirtyHarryLYL/HAKE" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"DirtyHarryLYL/HAKE" -> "YueLiao/PPDM"
"DirtyHarryLYL/HAKE" -> "DirtyHarryLYL/HAKE-Action-Torch"
"DirtyHarryLYL/HAKE" -> "DirtyHarryLYL/HOI-Learning-List"
"DirtyHarryLYL/HAKE" -> "bobwan1995/PMFNet"
"DirtyHarryLYL/HAKE" -> "vt-vl-lab/iCAN"
"DirtyHarryLYL/HAKE" -> "DirtyHarryLYL/DJ-RN"
"DirtyHarryLYL/HAKE" -> "s-gupta/v-coco"
"DirtyHarryLYL/HAKE" -> "chinancheng/awesome-human-object-interaction"
"DirtyHarryLYL/HAKE" -> "vt-vl-lab/DRG"
"DirtyHarryLYL/HAKE" -> "BigRedT/no_frills_hoi_det"
"DirtyHarryLYL/HAKE" -> "Fang-Haoshu/Halpe-FullBody" ["e"=1]
"DirtyHarryLYL/HAKE" -> "ASMIftekhar/VSGNet"
"DirtyHarryLYL/HAKE" -> "DirtyHarryLYL/SymNet"
"imageio/imageio" -> "imageio/imageio-ffmpeg"
"imageio/imageio" -> "scikit-image/scikit-image" ["e"=1]
"imageio/imageio" -> "pydata/numexpr" ["e"=1]
"imageio/imageio" -> "vispy/vispy" ["e"=1]
"imageio/imageio" -> "letmaik/rawpy" ["e"=1]
"imageio/imageio" -> "h5py/h5py" ["e"=1]
"imageio/imageio" -> "scikit-video/scikit-video"
"imageio/imageio" -> "napari/napari" ["e"=1]
"imageio/imageio" -> "maartenbreddels/ipyvolume" ["e"=1]
"imageio/imageio" -> "cgohlke/tifffile" ["e"=1]
"imageio/imageio" -> "hgrecco/pint" ["e"=1]
"imageio/imageio" -> "PyAV-Org/PyAV"
"imageio/imageio" -> "Zulko/moviepy" ["e"=1]
"imageio/imageio" -> "python-pillow/Pillow" ["e"=1]
"imageio/imageio" -> "colour-science/colour" ["e"=1]
"cwlroda/falldetection_openpifpaf" -> "taufeeque9/HumanFallDetection"
"cwlroda/falldetection_openpifpaf" -> "AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow"
"cwlroda/falldetection_openpifpaf" -> "JJN123/Fall-Detection"
"cwlroda/falldetection_openpifpaf" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"cwlroda/falldetection_openpifpaf" -> "ambianic/fall-detection"
"cwlroda/falldetection_openpifpaf" -> "BlackFeatherQQ/openpose_fall_detect"
"cwlroda/falldetection_openpifpaf" -> "qiaoguan/Fall-detection"
"cwlroda/falldetection_openpifpaf" -> "uttej2001/Image-based-Human-Fall-Detection"
"cwlroda/falldetection_openpifpaf" -> "zhuoxiangpang/ism_person_openpose"
"cwlroda/falldetection_openpifpaf" -> "ivineetm007/Fall-detection"
"cwlroda/falldetection_openpifpaf" -> "kasakun/Fall-Detection"
"cwlroda/falldetection_openpifpaf" -> "chizhanyuefeng/Realtime-Fall-Detection-for-RNN"
"yjxiong/anet2016-cuhk" -> "wzmsltw/BSN-boundary-sensitive-network"
"yjxiong/anet2016-cuhk" -> "shyamal-b/sst"
"yjxiong/anet2016-cuhk" -> "yjxiong/action-detection"
"yjxiong/anet2016-cuhk" -> "yjxiong/temporal-segment-networks"
"yjxiong/anet2016-cuhk" -> "wanglimin/UntrimmedNet"
"yjxiong/anet2016-cuhk" -> "shyamal-b/ss-tad"
"yjxiong/anet2016-cuhk" -> "imatge-upc/activitynet-2016-cvprw"
"yjxiong/anet2016-cuhk" -> "zhengshou/scnn"
"yjxiong/anet2016-cuhk" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"yjxiong/anet2016-cuhk" -> "ranjaykrishna/SST"
"yjxiong/anet2016-cuhk" -> "yjxiong/caffe"
"yjxiong/anet2016-cuhk" -> "vkalogeiton/caffe"
"yjxiong/anet2016-cuhk" -> "Finspire13/CMCS-Temporal-Action-Localization"
"yjxiong/anet2016-cuhk" -> "wanglimin/TDD"
"yjxiong/anet2016-cuhk" -> "zbwglory/MV-release"
"yongqyu/st-gcn-pytorch" -> "1zgh/st-gcn"
"yongqyu/st-gcn-pytorch" -> "kdkalvik/ST-GCN"
"yongqyu/st-gcn-pytorch" -> "limaosen0/AS-GCN"
"yongqyu/st-gcn-pytorch" -> "kchengiva/Shift-GCN"
"yongqyu/st-gcn-pytorch" -> "XinzeWu/st-GCN"
"Alvin-Zeng/PGCN" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"Alvin-Zeng/PGCN" -> "JJBOY/BMN-Boundary-Matching-Network"
"Alvin-Zeng/PGCN" -> "Finspire13/CMCS-Temporal-Action-Localization"
"Alvin-Zeng/PGCN" -> "frostinassiky/gtad"
"Alvin-Zeng/PGCN" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"Alvin-Zeng/PGCN" -> "Rheelt/Materials-Temporal-Action-Detection"
"Alvin-Zeng/PGCN" -> "sujoyp/wtalc-pytorch"
"Alvin-Zeng/PGCN" -> "wzmsltw/BSN-boundary-sensitive-network"
"Alvin-Zeng/PGCN" -> "Tencent/ActionDetection-DBG"
"Alvin-Zeng/PGCN" -> "HYPJUDY/Decouple-SSAD"
"Alvin-Zeng/PGCN" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"Alvin-Zeng/PGCN" -> "yjxiong/action-detection"
"Alvin-Zeng/PGCN" -> "Frostinassiky/gtad"
"Alvin-Zeng/PGCN" -> "Pilhyeon/BaSNet-pytorch"
"Alvin-Zeng/PGCN" -> "sunnyxiaohu/R-C3D.pytorch"
"oulutan/ACAM_Demo" -> "oulutan/ActorConditionedAttentionMaps"
"oulutan/ACAM_Demo" -> "NVlabs/STEP"
"oulutan/ACAM_Demo" -> "gurkirt/realtime-action-detection"
"google/youtube-8m" -> "antoine77340/Youtube-8M-WILLOW"
"google/youtube-8m" -> "wangheda/youtube-8m"
"google/youtube-8m" -> "facebookresearch/video-nonlocal-net"
"google/youtube-8m" -> "antoine77340/LOUPE"
"google/youtube-8m" -> "linrongc/youtube-8m"
"google/youtube-8m" -> "activitynet/ActivityNet"
"google/youtube-8m" -> "deepmind/kinetics-i3d"
"google/youtube-8m" -> "miha-skalic/youtube8mchallenge"
"google/youtube-8m" -> "facebook/C3D"
"google/youtube-8m" -> "yjxiong/temporal-segment-networks"
"google/youtube-8m" -> "harvitronix/five-video-classification-methods"
"google/youtube-8m" -> "mit-han-lab/temporal-shift-module"
"google/youtube-8m" -> "yoosan/video-understanding-dataset"
"google/youtube-8m" -> "facebook/fb.resnet.torch" ["e"=1]
"google/youtube-8m" -> "facebookresearch/SlowFast"
"torch2424/live-stream-radio" -> "NoniDOTio/LiveStreamRadio"
"torch2424/live-stream-radio" -> "macedonga/lofi.twitch.auto.stream"
"OpenGVLab/Ask-Anything" -> "OpenGVLab/unmasked_teacher"
"jinwchoi/awesome-action-recognition" -> "kenshohara/3D-ResNets-PyTorch"
"jinwchoi/awesome-action-recognition" -> "open-mmlab/mmaction"
"jinwchoi/awesome-action-recognition" -> "yjxiong/temporal-segment-networks"
"jinwchoi/awesome-action-recognition" -> "facebookresearch/SlowFast"
"jinwchoi/awesome-action-recognition" -> "yysijie/st-gcn"
"jinwchoi/awesome-action-recognition" -> "deepmind/kinetics-i3d"
"jinwchoi/awesome-action-recognition" -> "yjxiong/tsn-pytorch"
"jinwchoi/awesome-action-recognition" -> "mit-han-lab/temporal-shift-module"
"jinwchoi/awesome-action-recognition" -> "activitynet/ActivityNet"
"jinwchoi/awesome-action-recognition" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"jinwchoi/awesome-action-recognition" -> "open-mmlab/mmaction2"
"jinwchoi/awesome-action-recognition" -> "yjxiong/action-detection"
"jinwchoi/awesome-action-recognition" -> "jfzhang95/pytorch-video-recognition"
"jinwchoi/awesome-action-recognition" -> "open-mmlab/mmskeleton"
"jinwchoi/awesome-action-recognition" -> "facebookresearch/video-nonlocal-net"
"ArtLabss/tennis-tracking" -> "MaximeBataille/tennis_tracking"
"ArtLabss/tennis-tracking" -> "avivcaspi/TennisProject"
"ArtLabss/tennis-tracking" -> "vishaltiwari/bmvc-tennis-analytics"
"ArtLabss/tennis-tracking" -> "gchlebus/tennis-court-detection"
"ArtLabss/tennis-tracking" -> "ckjellson/tt_tracker"
"ArtLabss/tennis-tracking" -> "weekenddeeplearning/TrackNet"
"ArtLabss/tennis-tracking" -> "maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch"
"ArtLabss/tennis-tracking" -> "hampen2929/survey_on_tennis_tech"
"ArtLabss/tennis-tracking" -> "Chang-Chia-Chi/TrackNet-Badminton-Tracking-tensorflow2"
"wei-tim/YOWO" -> "MCG-NJU/MOC-Detector"
"wei-tim/YOWO" -> "MVIG-SJTU/AlphAction"
"wei-tim/YOWO" -> "Siyu-C/ACAR-Net"
"wei-tim/YOWO" -> "gurkirt/realtime-action-detection"
"wei-tim/YOWO" -> "open-mmlab/mmaction"
"wei-tim/YOWO" -> "decisionforce/TPN"
"wei-tim/YOWO" -> "NVlabs/STEP"
"wei-tim/YOWO" -> "mit-han-lab/temporal-shift-module"
"wei-tim/YOWO" -> "okankop/Efficient-3DCNNs"
"wei-tim/YOWO" -> "Alvin-Zeng/PGCN"
"wei-tim/YOWO" -> "facebookresearch/SlowFast"
"wei-tim/YOWO" -> "cvdfoundation/ava-dataset"
"wei-tim/YOWO" -> "Rheelt/Materials-Temporal-Action-Detection"
"wei-tim/YOWO" -> "TencentYoutuResearch/ActionDetection-DBG"
"wei-tim/YOWO" -> "open-mmlab/mmaction2"
"NVIDIA/nvvl" -> "dukebw/lintel"
"NVIDIA/nvvl" -> "facebookresearch/R2Plus1D"
"NVIDIA/nvvl" -> "mitmul/pynvvl"
"NVIDIA/nvvl" -> "ignacio-rocco/detectorch" ["e"=1]
"NVIDIA/nvvl" -> "chaoyuaw/pytorch-coviar"
"NVIDIA/nvvl" -> "hangzhaomit/HACS-dataset"
"NVIDIA/nvvl" -> "NVIDIA/DALI" ["e"=1]
"NVIDIA/nvvl" -> "hassony2/kinetics_i3d_pytorch"
"NVIDIA/nvvl" -> "cvondrick/soundnet" ["e"=1]
"NVIDIA/nvvl" -> "jerryli27/TwinGAN" ["e"=1]
"NVIDIA/nvvl" -> "wzmsltw/BSN-boundary-sensitive-network"
"NVIDIA/nvvl" -> "yjxiong/action-detection"
"NVIDIA/nvvl" -> "MohsenFayyaz89/PyTorch_Video_Dataset"
"NVIDIA/nvvl" -> "ankurhanda/gvnn" ["e"=1]
"NVIDIA/nvvl" -> "facebookresearch/video-nonlocal-net"
"colincsl/TemporalConvolutionalNetworks" -> "yabufarha/ms-tcn"
"colincsl/TemporalConvolutionalNetworks" -> "shyamal-b/sst"
"colincsl/TemporalConvolutionalNetworks" -> "MCG-NJU/BCN"
"colincsl/TemporalConvolutionalNetworks" -> "Zephyr-D/TCFPN-ISBA"
"colincsl/TemporalConvolutionalNetworks" -> "Finspire13/pytorch-i3d-feature-extraction"
"colincsl/TemporalConvolutionalNetworks" -> "TaeSoo-Kim/TCNActionRecognition"
"colincsl/TemporalConvolutionalNetworks" -> "ZheLi2020/TimestampActionSeg"
"colincsl/TemporalConvolutionalNetworks" -> "vdavid70619/TCN"
"colincsl/TemporalConvolutionalNetworks" -> "ahsaniqbal/Kinetics-FeatureExtractor"
"colincsl/TemporalConvolutionalNetworks" -> "zhengshou/scnn"
"colincsl/TemporalConvolutionalNetworks" -> "JJBOY/BMN-Boundary-Matching-Network"
"colincsl/TemporalConvolutionalNetworks" -> "yiskw713/asrf"
"colincsl/TemporalConvolutionalNetworks" -> "rohitgirdhar/ActionVLAD"
"yabufarha/ms-tcn" -> "sj-li/MS-TCN2"
"yabufarha/ms-tcn" -> "MCG-NJU/BCN"
"yabufarha/ms-tcn" -> "ahsaniqbal/Kinetics-FeatureExtractor"
"yabufarha/ms-tcn" -> "cmhungsteve/SSTDA"
"yabufarha/ms-tcn" -> "yiskw713/asrf"
"yabufarha/ms-tcn" -> "HYPJUDY/Decouple-SSAD"
"yabufarha/ms-tcn" -> "alexanderrichard/action-sets"
"yabufarha/ms-tcn" -> "ChinaYi/ASFormer"
"yabufarha/ms-tcn" -> "piergiaj/AViD"
"yabufarha/ms-tcn" -> "JunLi-Galios/CDFL"
"yabufarha/ms-tcn" -> "colincsl/TemporalConvolutionalNetworks"
"yabufarha/ms-tcn" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"yabufarha/ms-tcn" -> "piergiaj/super-events-cvpr18"
"JJBOY/BMN-Boundary-Matching-Network" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"JJBOY/BMN-Boundary-Matching-Network" -> "wzmsltw/BSN-boundary-sensitive-network"
"JJBOY/BMN-Boundary-Matching-Network" -> "Rheelt/Materials-Temporal-Action-Detection"
"JJBOY/BMN-Boundary-Matching-Network" -> "Tencent/ActionDetection-DBG"
"JJBOY/BMN-Boundary-Matching-Network" -> "Alvin-Zeng/PGCN"
"JJBOY/BMN-Boundary-Matching-Network" -> "frostinassiky/gtad"
"JJBOY/BMN-Boundary-Matching-Network" -> "Finspire13/CMCS-Temporal-Action-Localization"
"JJBOY/BMN-Boundary-Matching-Network" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"JJBOY/BMN-Boundary-Matching-Network" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"JJBOY/BMN-Boundary-Matching-Network" -> "yjxiong/action-detection"
"JJBOY/BMN-Boundary-Matching-Network" -> "microsoft/2D-TAN" ["e"=1]
"JJBOY/BMN-Boundary-Matching-Network" -> "HYPJUDY/Decouple-SSAD"
"JJBOY/BMN-Boundary-Matching-Network" -> "sujoyp/wtalc-pytorch"
"JJBOY/BMN-Boundary-Matching-Network" -> "Frostinassiky/gtad"
"JJBOY/BMN-Boundary-Matching-Network" -> "TencentYoutuResearch/ActionDetection-DBG"
"dmlc/decord" -> "facebookresearch/pytorchvideo"
"dmlc/decord" -> "facebookresearch/SlowFast"
"dmlc/decord" -> "MCG-NJU/VideoMAE"
"dmlc/decord" -> "open-mmlab/mmaction"
"dmlc/decord" -> "open-mmlab/mmaction2"
"dmlc/decord" -> "NVIDIA/VideoProcessingFramework" ["e"=1]
"dmlc/decord" -> "PyAV-Org/PyAV"
"dmlc/decord" -> "facebookresearch/TimeSformer"
"dmlc/decord" -> "decisionforce/TPN"
"dmlc/decord" -> "activitynet/ActivityNet"
"dmlc/decord" -> "SwinTransformer/Video-Swin-Transformer"
"dmlc/decord" -> "Sense-X/X-Temporal" ["e"=1]
"dmlc/decord" -> "mit-han-lab/temporal-shift-module"
"dmlc/decord" -> "cvdfoundation/kinetics-dataset"
"dmlc/decord" -> "deepmind/kinetics-i3d"
"kevinlin311tw/ava-dataset-tool" -> "alainray/ava_downloader"
"kevinlin311tw/ava-dataset-tool" -> "leaderj1001/Action-Localization"
"wzmsltw/BSN-boundary-sensitive-network" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"wzmsltw/BSN-boundary-sensitive-network" -> "JJBOY/BMN-Boundary-Matching-Network"
"wzmsltw/BSN-boundary-sensitive-network" -> "yjxiong/action-detection"
"wzmsltw/BSN-boundary-sensitive-network" -> "Alvin-Zeng/PGCN"
"wzmsltw/BSN-boundary-sensitive-network" -> "Finspire13/CMCS-Temporal-Action-Localization"
"wzmsltw/BSN-boundary-sensitive-network" -> "sujoyp/wtalc-pytorch"
"wzmsltw/BSN-boundary-sensitive-network" -> "jiyanggao/CTAP"
"wzmsltw/BSN-boundary-sensitive-network" -> "yjxiong/anet2016-cuhk"
"wzmsltw/BSN-boundary-sensitive-network" -> "Rheelt/Materials-Temporal-Action-Detection"
"wzmsltw/BSN-boundary-sensitive-network" -> "VisionLearningGroup/R-C3D"
"wzmsltw/BSN-boundary-sensitive-network" -> "activitynet/ActivityNet"
"wzmsltw/BSN-boundary-sensitive-network" -> "yjxiong/temporal-segment-networks"
"wzmsltw/BSN-boundary-sensitive-network" -> "mzolfaghari/ECO-efficient-video-understanding"
"wzmsltw/BSN-boundary-sensitive-network" -> "yjxiong/tsn-pytorch"
"wzmsltw/BSN-boundary-sensitive-network" -> "Tencent/ActionDetection-DBG"
"BlackFeatherQQ/openpose_fall_detect" -> "zhuoxiangpang/ism_person_openpose"
"antoine77340/Youtube-8M-WILLOW" -> "antoine77340/LOUPE"
"antoine77340/Youtube-8M-WILLOW" -> "wangheda/youtube-8m"
"antoine77340/Youtube-8M-WILLOW" -> "baidu/Youtube-8M"
"antoine77340/Youtube-8M-WILLOW" -> "miha-skalic/youtube8mchallenge"
"antoine77340/Youtube-8M-WILLOW" -> "linrongc/youtube-8m"
"antoine77340/Youtube-8M-WILLOW" -> "google/youtube-8m"
"antoine77340/Youtube-8M-WILLOW" -> "miha-skalic/youtube8mchallange"
"antoine77340/Youtube-8M-WILLOW" -> "yoosan/video-understanding-dataset"
"antoine77340/Youtube-8M-WILLOW" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"antoine77340/Youtube-8M-WILLOW" -> "rohitgirdhar/ActionVLAD"
"antoine77340/Youtube-8M-WILLOW" -> "facebookresearch/video-nonlocal-net"
"antoine77340/Youtube-8M-WILLOW" -> "metalbubble/moments_models"
"antoine77340/Youtube-8M-WILLOW" -> "yjxiong/anet2016-cuhk"
"antoine77340/Youtube-8M-WILLOW" -> "wanglimin/ARTNet"
"antoine77340/Youtube-8M-WILLOW" -> "mzolfaghari/ECO-efficient-video-understanding"
"harvitronix/five-video-classification-methods" -> "sujiongming/UCF-101_video_classification"
"harvitronix/five-video-classification-methods" -> "sagarvegad/Video-Classification-CNN-and-LSTM-"
"harvitronix/five-video-classification-methods" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"harvitronix/five-video-classification-methods" -> "kenshohara/video-classification-3d-cnn-pytorch"
"harvitronix/five-video-classification-methods" -> "harvitronix/continuous-online-video-classification-blog"
"harvitronix/five-video-classification-methods" -> "HHTseng/video-classification"
"harvitronix/five-video-classification-methods" -> "facebookresearch/video-nonlocal-net"
"harvitronix/five-video-classification-methods" -> "deepmind/kinetics-i3d"
"harvitronix/five-video-classification-methods" -> "jeffreyhuang1/two-stream-action-recognition"
"harvitronix/five-video-classification-methods" -> "hx173149/C3D-tensorflow"
"harvitronix/five-video-classification-methods" -> "jinwchoi/awesome-action-recognition"
"harvitronix/five-video-classification-methods" -> "feichtenhofer/twostreamfusion"
"harvitronix/five-video-classification-methods" -> "yjxiong/temporal-segment-networks"
"harvitronix/five-video-classification-methods" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"harvitronix/five-video-classification-methods" -> "imatge-upc/activitynet-2016-cvprw"
"sunnyxiaohu/R-C3D.pytorch" -> "VisionLearningGroup/R-C3D"
"sunnyxiaohu/R-C3D.pytorch" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"sunnyxiaohu/R-C3D.pytorch" -> "Alvin-Zeng/PGCN"
"sunnyxiaohu/R-C3D.pytorch" -> "Rheelt/Materials-Temporal-Action-Detection"
"sunnyxiaohu/R-C3D.pytorch" -> "yjxiong/action-detection"
"sunnyxiaohu/R-C3D.pytorch" -> "HYPJUDY/Decouple-SSAD"
"sunnyxiaohu/R-C3D.pytorch" -> "sujoyp/wtalc-pytorch"
"sunnyxiaohu/R-C3D.pytorch" -> "DavideA/c3d-pytorch"
"sunnyxiaohu/R-C3D.pytorch" -> "piergiaj/tgm-icml19"
"sunnyxiaohu/R-C3D.pytorch" -> "shyamal-b/ss-tad"
"sunnyxiaohu/R-C3D.pytorch" -> "jfzhang95/pytorch-video-recognition"
"sunnyxiaohu/R-C3D.pytorch" -> "JJBOY/BMN-Boundary-Matching-Network"
"sunnyxiaohu/R-C3D.pytorch" -> "jiyanggao/CBR"
"sunnyxiaohu/R-C3D.pytorch" -> "piergiaj/super-events-cvpr18"
"sunnyxiaohu/R-C3D.pytorch" -> "bellos1203/STPN"
"Chiaraplizz/ST-TR" -> "kenziyuliu/MS-G3D"
"Chiaraplizz/ST-TR" -> "kchengiva/Shift-GCN"
"Chiaraplizz/ST-TR" -> "Uason-Chen/CTR-GCN"
"Chiaraplizz/ST-TR" -> "microsoft/SGN"
"Chiaraplizz/ST-TR" -> "kchengiva/DecoupleGCN-DropGraph"
"Chiaraplizz/ST-TR" -> "lshiwjx/DSTA-Net"
"Chiaraplizz/ST-TR" -> "lshiwjx/2s-AGCN"
"Chiaraplizz/ST-TR" -> "shahroudy/NTURGB-D"
"Chiaraplizz/ST-TR" -> "limaosen0/AS-GCN"
"Chiaraplizz/ST-TR" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"Chiaraplizz/ST-TR" -> "yfsong0709/ResGCNv1"
"Chiaraplizz/ST-TR" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"Chiaraplizz/ST-TR" -> "stnoah1/infogcn"
"Chiaraplizz/ST-TR" -> "kennymckormick/pyskl"
"Chiaraplizz/ST-TR" -> "xiaoiker/GCN-NAS"
"yjxiong/caffe" -> "yjxiong/temporal-segment-networks"
"yjxiong/caffe" -> "yjxiong/anet2016-cuhk"
"yjxiong/caffe" -> "feichtenhofer/twostreamfusion"
"yjxiong/caffe" -> "wanglimin/dense_flow"
"yjxiong/caffe" -> "wanglimin/MRCNN-Scene-Recognition"
"yjxiong/caffe" -> "soeaver/caffe-model" ["e"=1]
"yjxiong/caffe" -> "facebook/C3D"
"yjxiong/caffe" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"yjxiong/caffe" -> "sanghoon/pva-faster-rcnn" ["e"=1]
"yjxiong/caffe" -> "shicai/DenseNet-Caffe" ["e"=1]
"yjxiong/caffe" -> "wanglimin/ARTNet"
"yjxiong/caffe" -> "yjxiong/action-detection"
"yjxiong/caffe" -> "kracwarlock/action-recognition-visual-attention"
"yjxiong/caffe" -> "craftGBD/craftGBD" ["e"=1]
"yjxiong/caffe" -> "LisaAnne/lisa-caffe-public"
"quanhua92/human-pose-estimation-opencv" -> "sanfooh/camera-openpose-keras"
"quanhua92/human-pose-estimation-opencv" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"quanhua92/human-pose-estimation-opencv" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"quanhua92/human-pose-estimation-opencv" -> "YangZeyu95/unofficial-implement-of-openpose" ["e"=1]
"quanhua92/human-pose-estimation-opencv" -> "ilovepose/DarkPose" ["e"=1]
"quanhua92/human-pose-estimation-opencv" -> "augmentedstartups/Pose-Estimation"
"wondonghyeon/protest-detection-violence-estimation" -> "JoshuaPiinRueyPan/ViolenceDetection"
"wondonghyeon/protest-detection-violence-estimation" -> "swathikirans/violence-recognition-pytorch"
"wondonghyeon/protest-detection-violence-estimation" -> "wondonghyeon/face-classification" ["e"=1]
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "ckjellson/tt_tracker"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "ArtLabss/tennis-tracking"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "vmarquet/table-tennis-computer-vision"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "Chang-Chia-Chi/TrackNet-Badminton-Tracking-tensorflow2"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "stephanj/basketballVideoAnalysis"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "simonefrancia/SpaceJam"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "gchlebus/tennis-court-detection"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "vcg-uvic/sportsfield_release"
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" -> "weekenddeeplearning/TrackNet"
"wanglimin/MRCNN-Scene-Recognition" -> "wangzheallen/vsad"
"wanglimin/MRCNN-Scene-Recognition" -> "wanglimin/Places205-VGGNet"
"wanglimin/MRCNN-Scene-Recognition" -> "yifita/action.sr_cnn"
"wanglimin/MRCNN-Scene-Recognition" -> "yjxiong/caffe"
"OpenGVLab/efficient-video-recognition" -> "ju-chen/Efficient-Prompt"
"OpenGVLab/efficient-video-recognition" -> "sauradip/STALE"
"OpenGVLab/efficient-video-recognition" -> "microsoft/VideoX"
"kenziyuliu/DGNN-PyTorch" -> "lshiwjx/2s-AGCN"
"kenziyuliu/DGNN-PyTorch" -> "kenziyuliu/MS-G3D"
"kenziyuliu/DGNN-PyTorch" -> "limaosen0/AS-GCN"
"kenziyuliu/DGNN-PyTorch" -> "kchengiva/Shift-GCN"
"kenziyuliu/DGNN-PyTorch" -> "xiaoiker/GCN-NAS"
"kenziyuliu/DGNN-PyTorch" -> "cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes"
"kenziyuliu/DGNN-PyTorch" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"kenziyuliu/DGNN-PyTorch" -> "kalpitthakkar/pb-gcn"
"kenziyuliu/DGNN-PyTorch" -> "shahroudy/NTURGB-D"
"kenziyuliu/DGNN-PyTorch" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"kenziyuliu/DGNN-PyTorch" -> "yfsong0709/RA-GCNv1"
"kenziyuliu/DGNN-PyTorch" -> "carloscaetano/skeleton-images"
"kenziyuliu/DGNN-PyTorch" -> "Uason-Chen/CTR-GCN"
"kenziyuliu/DGNN-PyTorch" -> "microsoft/SGN"
"DavideA/c3d-pytorch" -> "jfzhang95/pytorch-video-recognition"
"DavideA/c3d-pytorch" -> "yyuanad/Pytorch_C3D_Feature_Extractor" ["e"=1]
"DavideA/c3d-pytorch" -> "hassony2/kinetics_i3d_pytorch"
"DavideA/c3d-pytorch" -> "sunnyxiaohu/R-C3D.pytorch"
"DavideA/c3d-pytorch" -> "piergiaj/pytorch-i3d"
"DavideA/c3d-pytorch" -> "hx173149/C3D-tensorflow"
"DavideA/c3d-pytorch" -> "kenshohara/video-classification-3d-cnn-pytorch"
"DavideA/c3d-pytorch" -> "bryanyzhu/two-stream-pytorch"
"DavideA/c3d-pytorch" -> "yjxiong/tsn-pytorch"
"DavideA/c3d-pytorch" -> "qijiezhao/pseudo-3d-pytorch"
"DavideA/c3d-pytorch" -> "jeffreyhuang1/two-stream-action-recognition"
"DavideA/c3d-pytorch" -> "VisionLearningGroup/R-C3D"
"DavideA/c3d-pytorch" -> "deepmind/kinetics-i3d"
"DavideA/c3d-pytorch" -> "yjxiong/action-detection"
"DavideA/c3d-pytorch" -> "facebookarchive/C3D"
"hassony2/kinetics_i3d_pytorch" -> "piergiaj/pytorch-i3d"
"hassony2/kinetics_i3d_pytorch" -> "deepmind/kinetics-i3d"
"hassony2/kinetics_i3d_pytorch" -> "qijiezhao/pseudo-3d-pytorch"
"hassony2/kinetics_i3d_pytorch" -> "tomrunia/PyTorchConv3D"
"hassony2/kinetics_i3d_pytorch" -> "yjxiong/tsn-pytorch"
"hassony2/kinetics_i3d_pytorch" -> "yjxiong/action-detection"
"hassony2/kinetics_i3d_pytorch" -> "DavideA/c3d-pytorch"
"hassony2/kinetics_i3d_pytorch" -> "yjxiong/temporal-segment-networks"
"hassony2/kinetics_i3d_pytorch" -> "rimchang/kinetics-i3d-Pytorch"
"hassony2/kinetics_i3d_pytorch" -> "wzmsltw/BSN-boundary-sensitive-network"
"hassony2/kinetics_i3d_pytorch" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"hassony2/kinetics_i3d_pytorch" -> "open-mmlab/mmaction"
"hassony2/kinetics_i3d_pytorch" -> "gsig/PyVideoResearch"
"hassony2/kinetics_i3d_pytorch" -> "bryanyzhu/two-stream-pytorch"
"hassony2/kinetics_i3d_pytorch" -> "qijiezhao/py-denseflow"
"imatge-upc/activitynet-2016-cvprw" -> "yjxiong/anet2016-cuhk"
"imatge-upc/activitynet-2016-cvprw" -> "shyamal-b/sst"
"imatge-upc/activitynet-2016-cvprw" -> "escorciav/daps"
"imatge-upc/activitynet-2016-cvprw" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"imatge-upc/activitynet-2016-cvprw" -> "kracwarlock/action-recognition-visual-attention"
"imatge-upc/activitynet-2016-cvprw" -> "syyeung/frameglimpses"
"imatge-upc/activitynet-2016-cvprw" -> "shyamal-b/ss-tad"
"imatge-upc/activitynet-2016-cvprw" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"imatge-upc/activitynet-2016-cvprw" -> "zhengshou/scnn"
"imatge-upc/activitynet-2016-cvprw" -> "facebook/C3D"
"imatge-upc/activitynet-2016-cvprw" -> "rohitgirdhar/ActionVLAD"
"imatge-upc/activitynet-2016-cvprw" -> "wanglimin/UntrimmedNet"
"imatge-upc/activitynet-2016-cvprw" -> "axon-research/c3d-keras"
"imatge-upc/activitynet-2016-cvprw" -> "jrbtaylor/ActivityNet"
"imatge-upc/activitynet-2016-cvprw" -> "cabaf/sparseprop"
"kcct-fujimotolab/3DCNN" -> "OValery16/Tutorial-about-3D-convolutional-network"
"kcct-fujimotolab/3DCNN" -> "JihongJu/keras-resnet3d"
"kcct-fujimotolab/3DCNN" -> "sujiongming/UCF-101_video_classification"
"kcct-fujimotolab/3DCNN" -> "jibikbam/CNN-3D-images-Tensorflow" ["e"=1]
"kcct-fujimotolab/3DCNN" -> "okankop/Efficient-3DCNNs"
"kcct-fujimotolab/3DCNN" -> "dipakkr/3d-cnn-action-recognition"
"kcct-fujimotolab/3DCNN" -> "kenshohara/video-classification-3d-cnn-pytorch"
"kcct-fujimotolab/3DCNN" -> "feichtenhofer/twostreamfusion"
"kcct-fujimotolab/3DCNN" -> "axon-research/c3d-keras"
"kcct-fujimotolab/3DCNN" -> "dlpbc/keras-kinetics-i3d"
"kcct-fujimotolab/3DCNN" -> "bityangke/3DCNN"
"kcct-fujimotolab/3DCNN" -> "qijiezhao/pseudo-3d-pytorch"
"kcct-fujimotolab/3DCNN" -> "Ectsang/3D-CNN-Keras"
"imankgoyal/NonDeepNetworks" -> "Sense-X/UniFormer"
"imankgoyal/NonDeepNetworks" -> "zimoqingfeng/UMOP"
"imankgoyal/NonDeepNetworks" -> "DingXiaoH/RepLKNet-pytorch" ["e"=1]
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "felixchenfy/Realtime-Action-Recognition"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "TianzhongSong/Real-Time-Action-Recognition"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "open-mmlab/mmskeleton"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "noboevbo/ehpi_action_recognition"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "dluvizon/deephar"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "smellslikeml/ActionAI"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "lshiwjx/2s-AGCN"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "YangZeyu95/unofficial-implement-of-openpose" ["e"=1]
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "yysijie/st-gcn"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" -> "ildoonet/tf-pose-estimation" ["e"=1]
"felixchenfy/Realtime-Action-Recognition" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"felixchenfy/Realtime-Action-Recognition" -> "TianzhongSong/Real-Time-Action-Recognition"
"felixchenfy/Realtime-Action-Recognition" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"felixchenfy/Realtime-Action-Recognition" -> "open-mmlab/mmskeleton"
"felixchenfy/Realtime-Action-Recognition" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"felixchenfy/Realtime-Action-Recognition" -> "smellslikeml/ActionAI"
"felixchenfy/Realtime-Action-Recognition" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"felixchenfy/Realtime-Action-Recognition" -> "noboevbo/ehpi_action_recognition"
"felixchenfy/Realtime-Action-Recognition" -> "jeffreyyihuang/two-stream-action-recognition"
"felixchenfy/Realtime-Action-Recognition" -> "Daniil-Osokin/lightweight-human-pose-estimation.pytorch" ["e"=1]
"felixchenfy/Realtime-Action-Recognition" -> "jinwchoi/awesome-action-recognition"
"felixchenfy/Realtime-Action-Recognition" -> "shahroudy/NTURGB-D"
"felixchenfy/Realtime-Action-Recognition" -> "dluvizon/deephar"
"felixchenfy/Realtime-Action-Recognition" -> "ildoonet/tf-pose-estimation" ["e"=1]
"felixchenfy/Realtime-Action-Recognition" -> "yysijie/st-gcn"
"mostafa-saad/deep-activity-rec" -> "cvlab-epfl/social-scene-understanding"
"mostafa-saad/deep-activity-rec" -> "wjchaoGit/Group-Activity-Recognition"
"mostafa-saad/deep-activity-rec" -> "mostafa-saad/hierarchical-relational-network"
"mostafa-saad/deep-activity-rec" -> "huguyuehuhu/Awesome-Group-Activity-Recognition"
"mostafa-saad/deep-activity-rec" -> "ruiyan1995/Group-Activity-Recognition"
"mostafa-saad/deep-activity-rec" -> "ruiyan1995/HiGCIN"
"mostafa-saad/deep-activity-rec" -> "gurkirt/corrected-UCF101-Annots"
"dluvizon/deephar" -> "TianzhongSong/Real-Time-Action-Recognition"
"dluvizon/deephar" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"dluvizon/deephar" -> "stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
"dluvizon/deephar" -> "xingyizhou/pytorch-pose-hg-3d" ["e"=1]
"dluvizon/deephar" -> "garyzhao/SemGCN" ["e"=1]
"dluvizon/deephar" -> "huguyuehuhu/HCN-pytorch"
"dluvizon/deephar" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"dluvizon/deephar" -> "JimmySuen/integral-human-pose" ["e"=1]
"dluvizon/deephar" -> "felixchenfy/Realtime-Action-Recognition"
"dluvizon/deephar" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"dluvizon/deephar" -> "dronefreak/human-action-classification"
"dluvizon/deephar" -> "weigq/3d_pose_baseline_pytorch" ["e"=1]
"dluvizon/deephar" -> "DenisTome/Lifting-from-the-Deep-release" ["e"=1]
"dluvizon/deephar" -> "una-dinosauria/3d-pose-baseline" ["e"=1]
"dluvizon/deephar" -> "smellslikeml/ActionAI"
"Amanbhandula/AlphaPose" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"Amanbhandula/AlphaPose" -> "xqZhang-Strong/Human-Falling-Detect-Tracks-master"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "huguyuehuhu/HCN-pytorch"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "limaosen0/AS-GCN"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "lshiwjx/2s-AGCN"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "shahroudy/NTURGB-D"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "shuangshuangguo/skeleton-based-action-recognition-review"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "XiaoCode-er/Two-Stream-CNN"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "kenziyuliu/MS-G3D"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "InwoongLee/TS-LSTM"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "kchengiva/Shift-GCN"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "yysijie/st-gcn"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "FesianXu/PLSTM"
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" -> "kenziyuliu/DGNN-PyTorch"
"lmb-freiburg/flownet2-docker" -> "feichtenhofer/gpu_flow"
"lmb-freiburg/flownet2-docker" -> "jeffreyhuang1/two-stream-action-recognition"
"lmb-freiburg/flownet2-docker" -> "feichtenhofer/twostreamfusion"
"lmb-freiburg/flownet2-docker" -> "lmb-freiburg/flownet2" ["e"=1]
"xlliu7/E2E-TAD" -> "xlliu7/TadTR"
"xlliu7/E2E-TAD" -> "MCG-NJU/BasicTAD"
"xlliu7/E2E-TAD" -> "TencentYoutuResearch/ActionDetection-AFSD"
"xlliu7/E2E-TAD" -> "xlliu7/MUSES"
"xlliu7/MUSES" -> "xlliu7/TadTR"
"xlliu7/TadTR" -> "xlliu7/E2E-TAD"
"xlliu7/TadTR" -> "xlliu7/MUSES"
"xlliu7/TadTR" -> "klauscc/TALLFormer"
"xlliu7/TadTR" -> "happyharrycn/actionformer_release"
"xlliu7/TadTR" -> "zhang-can/UP-TAL"
"xlliu7/TadTR" -> "HumamAlwassel/TSP"
"JihongJu/keras-resnet3d" -> "TianzhongSong/3D-ConvNets-for-Action-Recognition"
"JihongJu/keras-resnet3d" -> "pantheon5100/3D-CNN-resnet-keras"
"JihongJu/keras-resnet3d" -> "JihongJu/lung-cancer-detector"
"JihongJu/keras-resnet3d" -> "dlpbc/keras-kinetics-i3d"
"okankop/Efficient-3DCNNs" -> "jfzhang95/pytorch-video-recognition"
"okankop/Efficient-3DCNNs" -> "kenshohara/3D-ResNets-PyTorch"
"okankop/Efficient-3DCNNs" -> "shijianjian/EfficientNet-PyTorch-3D"
"okankop/Efficient-3DCNNs" -> "kenshohara/video-classification-3d-cnn-pytorch"
"okankop/Efficient-3DCNNs" -> "wei-tim/YOWO"
"okankop/Efficient-3DCNNs" -> "mit-han-lab/temporal-shift-module"
"okankop/Efficient-3DCNNs" -> "okankop/vidaug"
"okankop/Efficient-3DCNNs" -> "facebookresearch/VMZ"
"okankop/Efficient-3DCNNs" -> "decisionforce/TPN"
"okankop/Efficient-3DCNNs" -> "piergiaj/pytorch-i3d"
"okankop/Efficient-3DCNNs" -> "kcct-fujimotolab/3DCNN"
"okankop/Efficient-3DCNNs" -> "qijiezhao/pseudo-3d-pytorch"
"okankop/Efficient-3DCNNs" -> "tomrunia/PyTorchConv3D"
"okankop/Efficient-3DCNNs" -> "HHTseng/video-classification"
"okankop/Efficient-3DCNNs" -> "moabitcoin/ig65m-pytorch"
"shijianjian/EfficientNet-PyTorch-3D" -> "ZFTurbo/classification_models_3D"
"shijianjian/EfficientNet-PyTorch-3D" -> "okankop/Efficient-3DCNNs"
"shijianjian/EfficientNet-PyTorch-3D" -> "ZFTurbo/efficientnet_3D"
"JoshuaPiinRueyPan/ViolenceDetection" -> "hasnainnaeem/Violence-Detection-in-Videos"
"JoshuaPiinRueyPan/ViolenceDetection" -> "liorsidi/ViolenceDetection_CNNLSTM"
"JoshuaPiinRueyPan/ViolenceDetection" -> "wondonghyeon/protest-detection-violence-estimation"
"JoshuaPiinRueyPan/ViolenceDetection" -> "swathikirans/violence-recognition-pytorch"
"JoshuaPiinRueyPan/ViolenceDetection" -> "mchengny/RWF2000-Video-Database-for-Violence-Detection"
"JoshuaPiinRueyPan/ViolenceDetection" -> "sayibet/fight-detection-surv-dataset"
"JoshuaPiinRueyPan/ViolenceDetection" -> "eazydammy/violence-detection-with-C3D"
"JoshuaPiinRueyPan/ViolenceDetection" -> "mamonraab/Real-Time-Violence-Detection-in-Video-"
"hasnainnaeem/Violence-Detection-in-Videos" -> "JoshuaPiinRueyPan/ViolenceDetection"
"hasnainnaeem/Violence-Detection-in-Videos" -> "eazydammy/violence-detection-with-C3D"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "hasnainnaeem/Violence-Detection-in-Videos"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "swathikirans/violence-recognition-pytorch"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "JoshuaPiinRueyPan/ViolenceDetection"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "eazydammy/violence-detection-with-C3D"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "sayibet/fight-detection-surv-dataset"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "mamonraab/Real-Time-Violence-Detection-in-Video-"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "liorsidi/ViolenceDetection_CNNLSTM"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "imsoo/fight_detection"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "Roc-Ng/XDVioDet" ["e"=1]
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "liorsidi/violence-detection-deep-learning-cnnlstm"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "TheAnkurGoswami/Human-Violence-Detection"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "airtlab/A-Dataset-for-Automatic-Violence-Detection-in-Videos"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "zahid58/TwoStreamSepConvLSTM_ViolenceDetection"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "pedrofrodenas/Violence-Detection-CNN-LSTM"
"mchengny/RWF2000-Video-Database-for-Violence-Detection" -> "aitikgupta/violence_detection"
"Pilhyeon/WTAL-Uncertainty-Modeling" -> "zhang-can/CoLA"
"Pilhyeon/WTAL-Uncertainty-Modeling" -> "Pilhyeon/BaSNet-pytorch"
"Pilhyeon/WTAL-Uncertainty-Modeling" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"Pilhyeon/WTAL-Uncertainty-Modeling" -> "Pilhyeon/Learning-Action-Completeness-from-Points"
"s-gupta/v-coco" -> "ywchao/ho-rcnn"
"s-gupta/v-coco" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"s-gupta/v-coco" -> "vt-vl-lab/iCAN"
"s-gupta/v-coco" -> "BigRedT/no_frills_hoi_det"
"s-gupta/v-coco" -> "bobwan1995/PMFNet"
"s-gupta/v-coco" -> "fredzzhang/hicodet"
"s-gupta/v-coco" -> "DirtyHarryLYL/HOI-Learning-List"
"s-gupta/v-coco" -> "YueLiao/PPDM"
"s-gupta/v-coco" -> "SiyuanQi/gpnn"
"s-gupta/v-coco" -> "chinancheng/awesome-human-object-interaction"
"s-gupta/v-coco" -> "vt-vl-lab/DRG"
"s-gupta/v-coco" -> "cjw2021/QAHOI"
"s-gupta/v-coco" -> "SHI-Labs/Human-Object-Interaction-Detection"
"s-gupta/v-coco" -> "DirtyHarryLYL/HAKE"
"s-gupta/v-coco" -> "MVIG-SJTU/DIRV"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "wzmsltw/BSN-boundary-sensitive-network"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "JJBOY/BMN-Boundary-Matching-Network"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "Alvin-Zeng/PGCN"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "Finspire13/CMCS-Temporal-Action-Localization"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "sujoyp/wtalc-pytorch"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "Rheelt/Materials-Temporal-Action-Detection"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "HYPJUDY/Decouple-SSAD"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "bellos1203/STPN"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "jiyanggao/CBR"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "jiyanggao/CTAP"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "sunnyxiaohu/R-C3D.pytorch"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "zhengshou/AutoLoc"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "JiaHeeeee/Deep_Learning_Temporal_Action_Detection"
"wzmsltw/BSN-boundary-sensitive-network.pytorch" -> "yjxiong/action-detection"
"yfsong0709/EfficientGCNv1" -> "yfsong0709/ResGCNv1"
"facebookresearch/omnivore" -> "EPFL-VILAB/MultiMAE" ["e"=1]
"facebookresearch/omnivore" -> "MCG-NJU/VideoMAE"
"facebookresearch/omnivore" -> "Sense-X/UniFormer"
"facebookresearch/omnivore" -> "facebookresearch/long_seq_mae"
"facebookresearch/omnivore" -> "m-bain/frozen-in-time" ["e"=1]
"facebookresearch/omnivore" -> "showlab/EgoVLP" ["e"=1]
"facebookresearch/omnivore" -> "google-research/pix2seq" ["e"=1]
"facebookresearch/omnivore" -> "facebookresearch/LaViLa" ["e"=1]
"facebookresearch/omnivore" -> "sallymmx/ActionCLIP"
"facebookresearch/omnivore" -> "jayleicn/moment_detr" ["e"=1]
"facebookresearch/omnivore" -> "facebookresearch/AVT" ["e"=1]
"facebookresearch/omnivore" -> "facebookresearch/Motionformer"
"shahroudy/NTURGB-D" -> "lshiwjx/2s-AGCN"
"shahroudy/NTURGB-D" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"shahroudy/NTURGB-D" -> "kenziyuliu/MS-G3D"
"shahroudy/NTURGB-D" -> "yysijie/st-gcn"
"shahroudy/NTURGB-D" -> "kchengiva/Shift-GCN"
"shahroudy/NTURGB-D" -> "limaosen0/AS-GCN"
"shahroudy/NTURGB-D" -> "microsoft/SGN"
"shahroudy/NTURGB-D" -> "Chiaraplizz/ST-TR"
"shahroudy/NTURGB-D" -> "open-mmlab/mmskeleton"
"shahroudy/NTURGB-D" -> "Uason-Chen/CTR-GCN"
"shahroudy/NTURGB-D" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"shahroudy/NTURGB-D" -> "huguyuehuhu/HCN-pytorch"
"shahroudy/NTURGB-D" -> "cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes"
"shahroudy/NTURGB-D" -> "Hrener/3D-Action-recognition"
"shahroudy/NTURGB-D" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"bobwan1995/PMFNet" -> "BigRedT/no_frills_hoi_det"
"bobwan1995/PMFNet" -> "vaesl/IP-Net"
"bobwan1995/PMFNet" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"bobwan1995/PMFNet" -> "ywchao/ho-rcnn"
"bobwan1995/PMFNet" -> "YueLiao/PPDM"
"bobwan1995/PMFNet" -> "jpeyre/analogy"
"bobwan1995/PMFNet" -> "tfzhou/C-HOI"
"bobwan1995/PMFNet" -> "vt-vl-lab/iCAN"
"bobwan1995/PMFNet" -> "yoyomimi/AS-Net"
"DirtyHarryLYL/SymNet" -> "DirtyHarryLYL/DJ-RN"
"DirtyHarryLYL/SymNet" -> "DirtyHarryLYL/HAKE-Action"
"gtoderici/sports-1m-dataset" -> "facebook/C3D"
"MRzzm/action-recognition-models-pytorch" -> "jfzhang95/pytorch-video-recognition"
"MRzzm/action-recognition-models-pytorch" -> "jeffreyyihuang/two-stream-action-recognition"
"MRzzm/action-recognition-models-pytorch" -> "woodfrog/ActionRecognition"
"MRzzm/action-recognition-models-pytorch" -> "MCG-NJU/TDN"
"MRzzm/action-recognition-models-pytorch" -> "bryanyzhu/two-stream-pytorch"
"MRzzm/action-recognition-models-pytorch" -> "qijiezhao/pseudo-3d-pytorch"
"MRzzm/action-recognition-models-pytorch" -> "piergiaj/representation-flow-cvpr19"
"MRzzm/action-recognition-models-pytorch" -> "coderSkyChen/Action_Recognition_Zoo"
"MRzzm/action-recognition-models-pytorch" -> "qijiezhao/s3d.pytorch"
"MRzzm/action-recognition-models-pytorch" -> "irhum/R2Plus1D-PyTorch"
"MRzzm/action-recognition-models-pytorch" -> "V-Sense/ACTION-Net"
"MRzzm/action-recognition-models-pytorch" -> "tomrunia/PyTorchConv3D"
"MRzzm/action-recognition-models-pytorch" -> "decisionforce/TPN"
"MRzzm/action-recognition-models-pytorch" -> "yjxiong/tsn-pytorch"
"MRzzm/action-recognition-models-pytorch" -> "facebookresearch/VMZ"
"cvdfoundation/kinetics-dataset" -> "facebookresearch/TimeSformer"
"cvdfoundation/kinetics-dataset" -> "SwinTransformer/Video-Swin-Transformer"
"cvdfoundation/kinetics-dataset" -> "MCG-NJU/VideoMAE"
"cvdfoundation/kinetics-dataset" -> "open-mmlab/mmaction2"
"cvdfoundation/kinetics-dataset" -> "activitynet/ActivityNet"
"cvdfoundation/kinetics-dataset" -> "Showmax/kinetics-downloader"
"cvdfoundation/kinetics-dataset" -> "facebookresearch/pytorchvideo"
"cvdfoundation/kinetics-dataset" -> "MCG-NJU/TDN"
"cvdfoundation/kinetics-dataset" -> "open-mmlab/denseflow" ["e"=1]
"cvdfoundation/kinetics-dataset" -> "mit-han-lab/temporal-shift-module"
"cvdfoundation/kinetics-dataset" -> "sallymmx/ActionCLIP"
"cvdfoundation/kinetics-dataset" -> "decisionforce/TPN"
"cvdfoundation/kinetics-dataset" -> "TengdaHan/CoCLR" ["e"=1]
"cvdfoundation/kinetics-dataset" -> "s9xie/Mini-Kinetics-200"
"cvdfoundation/kinetics-dataset" -> "facebookresearch/SlowFast"
"gsig/PyVideoResearch" -> "open-mmlab/mmaction"
"gsig/PyVideoResearch" -> "facebookresearch/video-long-term-feature-banks"
"gsig/PyVideoResearch" -> "facebookresearch/VMZ"
"gsig/PyVideoResearch" -> "hassony2/kinetics_i3d_pytorch"
"gsig/PyVideoResearch" -> "decisionforce/TPN"
"gsig/PyVideoResearch" -> "activitynet/ActivityNet"
"gsig/PyVideoResearch" -> "alexandonian/pretorched-x"
"gsig/PyVideoResearch" -> "metalbubble/TRN-pytorch"
"gsig/PyVideoResearch" -> "piergiaj/pytorch-i3d"
"gsig/PyVideoResearch" -> "swathikirans/GSM"
"gsig/PyVideoResearch" -> "coderSkyChen/Action_Recognition_Zoo"
"gsig/PyVideoResearch" -> "Rheelt/Materials-Temporal-Action-Detection"
"gsig/PyVideoResearch" -> "jinwchoi/awesome-action-recognition"
"gsig/PyVideoResearch" -> "noureldien/timeception"
"gsig/PyVideoResearch" -> "wzmsltw/BSN-boundary-sensitive-network"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "Alvin-Zeng/PGCN"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "JJBOY/BMN-Boundary-Matching-Network"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "Rheelt/Materials-Temporal-Action-Detection"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "piergiaj/pytorch-i3d"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "TencentYoutuResearch/ActionDetection-AFSD"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "wzmsltw/BSN-boundary-sensitive-network"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "frostinassiky/gtad"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "Pilhyeon/BaSNet-pytorch"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "Finspire13/CMCS-Temporal-Action-Localization"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "Tencent/ActionDetection-DBG"
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "microsoft/2D-TAN" ["e"=1]
"Alvin-Zeng/Awesome-Temporal-Action-Localization" -> "sujoyp/wtalc-pytorch"
"MCG-NJU/BasicTAD" -> "cg1177/DCAN"
"happyharrycn/actionformer_release" -> "HumamAlwassel/TSP"
"happyharrycn/actionformer_release" -> "xlliu7/E2E-TAD"
"happyharrycn/actionformer_release" -> "xlliu7/TadTR"
"happyharrycn/actionformer_release" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"happyharrycn/actionformer_release" -> "MCG-NJU/BasicTAD"
"happyharrycn/actionformer_release" -> "TencentYoutuResearch/ActionDetection-AFSD"
"happyharrycn/actionformer_release" -> "Finspire13/pytorch-i3d-feature-extraction"
"happyharrycn/actionformer_release" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"happyharrycn/actionformer_release" -> "qinzhi-0110/Temporal-Context-Aggregation-Network-Pytorch"
"happyharrycn/actionformer_release" -> "MCG-NJU/RTD-Action"
"happyharrycn/actionformer_release" -> "klauscc/TALLFormer"
"happyharrycn/actionformer_release" -> "OpenGVLab/InternVideo"
"happyharrycn/actionformer_release" -> "frostinassiky/gtad"
"happyharrycn/actionformer_release" -> "dingfengshi/TriDet"
"happyharrycn/actionformer_release" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "kenziyuliu/MS-G3D"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "lshiwjx/2s-AGCN"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "shahroudy/NTURGB-D"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "kchengiva/Shift-GCN"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "limaosen0/AS-GCN"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "open-mmlab/mmskeleton"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "microsoft/SGN"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "huguyuehuhu/HCN-pytorch"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "yysijie/st-gcn"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "Chiaraplizz/ST-TR"
"niais/Awesome-Skeleton-based-Action-Recognition" -> "kennymckormick/pyskl"
"Uason-Chen/CTR-GCN" -> "microsoft/SGN"
"Uason-Chen/CTR-GCN" -> "kchengiva/Shift-GCN"
"Uason-Chen/CTR-GCN" -> "stnoah1/infogcn"
"Uason-Chen/CTR-GCN" -> "MartinXM/LST"
"Uason-Chen/CTR-GCN" -> "kenziyuliu/MS-G3D"
"Uason-Chen/CTR-GCN" -> "Chiaraplizz/ST-TR"
"Uason-Chen/CTR-GCN" -> "Jho-Yonsei/HD-GCN" ["e"=1]
"Uason-Chen/CTR-GCN" -> "tailin1009/DualHead-Network"
"Uason-Chen/CTR-GCN" -> "lshiwjx/2s-AGCN"
"Uason-Chen/CTR-GCN" -> "yfsong0709/EfficientGCNv1"
"Uason-Chen/CTR-GCN" -> "kchengiva/DecoupleGCN-DropGraph"
"Uason-Chen/CTR-GCN" -> "shahroudy/NTURGB-D"
"Uason-Chen/CTR-GCN" -> "heleiqiu/STTFormer"
"Uason-Chen/CTR-GCN" -> "Levigty/AimCLR"
"Uason-Chen/CTR-GCN" -> "kennymckormick/pyskl"
"kenziyuliu/MS-G3D" -> "kchengiva/Shift-GCN"
"kenziyuliu/MS-G3D" -> "lshiwjx/2s-AGCN"
"kenziyuliu/MS-G3D" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"kenziyuliu/MS-G3D" -> "microsoft/SGN"
"kenziyuliu/MS-G3D" -> "xiaoiker/GCN-NAS"
"kenziyuliu/MS-G3D" -> "shahroudy/NTURGB-D"
"kenziyuliu/MS-G3D" -> "limaosen0/AS-GCN"
"kenziyuliu/MS-G3D" -> "Chiaraplizz/ST-TR"
"kenziyuliu/MS-G3D" -> "Uason-Chen/CTR-GCN"
"kenziyuliu/MS-G3D" -> "kenziyuliu/DGNN-PyTorch"
"kenziyuliu/MS-G3D" -> "yfsong0709/ResGCNv1"
"kenziyuliu/MS-G3D" -> "open-mmlab/mmskeleton"
"kenziyuliu/MS-G3D" -> "huguyuehuhu/HCN-pytorch"
"kenziyuliu/MS-G3D" -> "limaosen0/DMGNN" ["e"=1]
"kenziyuliu/MS-G3D" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"zhuoxiangpang/ism_person_openpose" -> "BlackFeatherQQ/openpose_fall_detect"
"zhuoxiangpang/ism_person_openpose" -> "xintao222/PoseDetect"
"TencentYoutuResearch/ActionDetection-DBG" -> "JJBOY/BMN-Boundary-Matching-Network"
"TencentYoutuResearch/ActionDetection-DBG" -> "wzmsltw/BSN-boundary-sensitive-network"
"TencentYoutuResearch/ActionDetection-DBG" -> "HYPJUDY/Decouple-SSAD"
"TencentYoutuResearch/ActionDetection-DBG" -> "JiaHeeeee/Deep_Learning_Temporal_Action_Detection"
"TencentYoutuResearch/ActionDetection-DBG" -> "Frostinassiky/gtad"
"TencentYoutuResearch/ActionDetection-DBG" -> "Finspire13/CMCS-Temporal-Action-Localization"
"TencentYoutuResearch/ActionDetection-DBG" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"TencentYoutuResearch/ActionDetection-DBG" -> "jiyanggao/CTAP"
"TencentYoutuResearch/ActionDetection-DBG" -> "Alvin-Zeng/PGCN"
"TencentYoutuResearch/ActionDetection-DBG" -> "Rheelt/Materials-Temporal-Action-Detection"
"TencentYoutuResearch/ActionDetection-DBG" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"TencentYoutuResearch/ActionDetection-DBG" -> "zhengshou/AutoLoc"
"TencentYoutuResearch/ActionDetection-DBG" -> "piergiaj/tgm-icml19"
"TencentYoutuResearch/ActionDetection-DBG" -> "sujoyp/wtalc-pytorch"
"TencentYoutuResearch/ActionDetection-DBG" -> "jiyanggao/CBR"
"TianzhongSong/Real-Time-Action-Recognition" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"TianzhongSong/Real-Time-Action-Recognition" -> "felixchenfy/Realtime-Action-Recognition"
"TianzhongSong/Real-Time-Action-Recognition" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"TianzhongSong/Real-Time-Action-Recognition" -> "FingerRec/real_time_video_action_recognition"
"TianzhongSong/Real-Time-Action-Recognition" -> "noboevbo/ehpi_action_recognition"
"TianzhongSong/Real-Time-Action-Recognition" -> "dluvizon/deephar"
"TianzhongSong/Real-Time-Action-Recognition" -> "lshiwjx/2s-AGCN"
"TianzhongSong/Real-Time-Action-Recognition" -> "jeffreyyihuang/two-stream-action-recognition"
"TianzhongSong/Real-Time-Action-Recognition" -> "stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
"TianzhongSong/Real-Time-Action-Recognition" -> "bryanyzhu/two-stream-pytorch"
"TianzhongSong/Real-Time-Action-Recognition" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"TianzhongSong/Real-Time-Action-Recognition" -> "TianzhongSong/C3D-keras"
"TianzhongSong/Real-Time-Action-Recognition" -> "open-mmlab/mmskeleton"
"TianzhongSong/Real-Time-Action-Recognition" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"TianzhongSong/Real-Time-Action-Recognition" -> "woodfrog/ActionRecognition"
"xiaoiker/GCN-NAS" -> "kchengiva/Shift-GCN"
"xiaoiker/GCN-NAS" -> "kenziyuliu/MS-G3D"
"xiaoiker/GCN-NAS" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"xiaoiker/GCN-NAS" -> "microsoft/SGN"
"xiaoiker/GCN-NAS" -> "limaosen0/AS-GCN"
"xiaoiker/GCN-NAS" -> "lshiwjx/2s-AGCN"
"xiaoiker/GCN-NAS" -> "yfsong0709/ResGCNv1"
"xiaoiker/GCN-NAS" -> "yfsong0709/RA-GCNv1"
"xiaoiker/GCN-NAS" -> "kenziyuliu/DGNN-PyTorch"
"xiaoiker/GCN-NAS" -> "kchengiva/DecoupleGCN-DropGraph"
"xiaoiker/GCN-NAS" -> "kenziyuliu/Unofficial-DGNN-PyTorch"
"qijiezhao/py-denseflow" -> "feichtenhofer/gpu_flow"
"qijiezhao/py-denseflow" -> "yjxiong/dense_flow"
"qijiezhao/py-denseflow" -> "wizyoung/Optical-Flow-GPU-Docker"
"qijiezhao/py-denseflow" -> "qijiezhao/s3d.pytorch"
"qijiezhao/py-denseflow" -> "yangwangx/denseFlow_gpu"
"qijiezhao/py-denseflow" -> "USTC-Video-Understanding/I3D_Finetune"
"qijiezhao/py-denseflow" -> "hassony2/kinetics_i3d_pytorch"
"qijiezhao/py-denseflow" -> "qijiezhao/Video-Classification-Action-Recognition"
"qijiezhao/py-denseflow" -> "wanglimin/dense_flow"
"qijiezhao/py-denseflow" -> "dlpbc/keras-kinetics-i3d"
"qijiezhao/py-denseflow" -> "wanglimin/ARTNet"
"qijiezhao/py-denseflow" -> "jeffreyhuang1/two-stream-action-recognition"
"qijiezhao/py-denseflow" -> "rohitgirdhar/ActionVLAD"
"qijiezhao/py-denseflow" -> "qijiezhao/pseudo-3d-pytorch"
"qijiezhao/py-denseflow" -> "Finspire13/CMCS-Temporal-Action-Localization"
"pranoyr/cnn-lstm" -> "HHTseng/video-classification"
"pranoyr/cnn-lstm" -> "IDKiro/action-recognition"
"pranoyr/cnn-lstm" -> "junyongyou/Attention-boosted-deep-networks-for-video-classification"
"oswaldoludwig/Human-Action-Recognition-with-Keras" -> "kracwarlock/action-recognition-visual-attention"
"oswaldoludwig/Human-Action-Recognition-with-Keras" -> "fomorians/distracted-drivers-keras"
"oswaldoludwig/Human-Action-Recognition-with-Keras" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"oswaldoludwig/Human-Action-Recognition-with-Keras" -> "qijiezhao/Video-Classification-Action-Recognition"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "felixchenfy/Realtime-Action-Recognition"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "TianzhongSong/Real-Time-Action-Recognition"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "noboevbo/ehpi_action_recognition"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "dronefreak/human-action-classification"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "dakenan1/Realtime-Action-Recognition-Openpose"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "smellslikeml/ActionAI"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "dluvizon/deephar"
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"ColumbiaDVMM/CDC" -> "jiyanggao/CBR"
"ColumbiaDVMM/CDC" -> "naraysa/3c-net"
"FingerRec/real_time_video_action_recognition" -> "danbochman/Real-Time-Action-Recognition"
"RI-CH/SlowFastNetworks" -> "Guocode/SlowFast-Networks"
"TaeSoo-Kim/TCNActionRecognition" -> "fandulu/Keras-for-Co-occurrence-Feature-Learning-from-Skeleton-Data-for-Action-Recognition"
"TaeSoo-Kim/TCNActionRecognition" -> "hongsong-wang/RNN-for-skeletons"
"TaeSoo-Kim/TCNActionRecognition" -> "InwoongLee/TS-LSTM"
"TaeSoo-Kim/TCNActionRecognition" -> "huguyuehuhu/HCN-pytorch"
"cypw/PyTorch-MFNet" -> "metalbubble/TRN-pytorch"
"cypw/PyTorch-MFNet" -> "facebookresearch/video-long-term-feature-banks"
"cypw/PyTorch-MFNet" -> "piergiaj/representation-flow-cvpr19"
"cypw/PyTorch-MFNet" -> "hassony2/kinetics_i3d_pytorch"
"cypw/PyTorch-MFNet" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"cypw/PyTorch-MFNet" -> "wzmsltw/BSN-boundary-sensitive-network"
"cypw/PyTorch-MFNet" -> "noureldien/timeception"
"cypw/PyTorch-MFNet" -> "wanglimin/ARTNet"
"cypw/PyTorch-MFNet" -> "MIT-HAN-LAB/temporal-shift-module"
"cypw/PyTorch-MFNet" -> "chaoyuaw/pytorch-coviar"
"cypw/PyTorch-MFNet" -> "yjxiong/tsn-pytorch"
"cypw/PyTorch-MFNet" -> "mzolfaghari/ECO-efficient-video-understanding"
"cypw/PyTorch-MFNet" -> "ZhaofanQiu/local-and-global-diffusion-networks"
"cypw/PyTorch-MFNet" -> "qijiezhao/pseudo-3d-pytorch"
"cypw/PyTorch-MFNet" -> "qijiezhao/s3d.pytorch"
"fandulu/Keras-for-Co-occurrence-Feature-Learning-from-Skeleton-Data-for-Action-Recognition" -> "FesianXu/PLSTM"
"gurkirt/realtime-action-detection" -> "vkalogeiton/caffe"
"gurkirt/realtime-action-detection" -> "gurkirt/corrected-UCF101-Annots"
"gurkirt/realtime-action-detection" -> "yjxiong/action-detection"
"gurkirt/realtime-action-detection" -> "pengxj/action-faster-rcnn"
"gurkirt/realtime-action-detection" -> "Feynman27/realtime-action-detection"
"gurkirt/realtime-action-detection" -> "NVlabs/STEP"
"gurkirt/realtime-action-detection" -> "metalbubble/TRN-pytorch"
"gurkirt/realtime-action-detection" -> "VisionLearningGroup/R-C3D"
"gurkirt/realtime-action-detection" -> "wzmsltw/BSN-boundary-sensitive-network"
"gurkirt/realtime-action-detection" -> "mzolfaghari/ECO-efficient-video-understanding"
"gurkirt/realtime-action-detection" -> "jiaozizhao/Two-in-One-ActionDetection"
"gurkirt/realtime-action-detection" -> "shyamal-b/ss-tad"
"gurkirt/realtime-action-detection" -> "MCG-NJU/MOC-Detector"
"gurkirt/realtime-action-detection" -> "oulutan/ACAM_Demo"
"gurkirt/realtime-action-detection" -> "activitynet/ActivityNet"
"hjjpku/Action_Detection_DQN" -> "demianzhang/weakly-action-localization"
"hjjpku/Action_Detection_DQN" -> "jiyanggao/CBR"
"mzolfaghari/ECO-efficient-video-understanding" -> "mzolfaghari/ECO-pytorch"
"mzolfaghari/ECO-efficient-video-understanding" -> "zhang-can/ECO-pytorch"
"mzolfaghari/ECO-efficient-video-understanding" -> "metalbubble/TRN-pytorch"
"mzolfaghari/ECO-efficient-video-understanding" -> "wzmsltw/BSN-boundary-sensitive-network"
"mzolfaghari/ECO-efficient-video-understanding" -> "yjxiong/tsn-pytorch"
"mzolfaghari/ECO-efficient-video-understanding" -> "yjxiong/action-detection"
"mzolfaghari/ECO-efficient-video-understanding" -> "wanglimin/ARTNet"
"mzolfaghari/ECO-efficient-video-understanding" -> "gurkirt/realtime-action-detection"
"mzolfaghari/ECO-efficient-video-understanding" -> "yjxiong/temporal-segment-networks"
"mzolfaghari/ECO-efficient-video-understanding" -> "qijiezhao/pseudo-3d-pytorch"
"mzolfaghari/ECO-efficient-video-understanding" -> "chaoyuaw/pytorch-coviar"
"mzolfaghari/ECO-efficient-video-understanding" -> "cypw/PyTorch-MFNet"
"mzolfaghari/ECO-efficient-video-understanding" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"mzolfaghari/ECO-efficient-video-understanding" -> "yoosan/video-understanding-dataset"
"mzolfaghari/ECO-efficient-video-understanding" -> "VisionLearningGroup/R-C3D"
"qijiezhao/Video-Classification-Action-Recognition" -> "jeffreyhuang1/two-stream-action-recognition"
"qijiezhao/Video-Classification-Action-Recognition" -> "rohitgirdhar/ActionVLAD"
"qijiezhao/Video-Classification-Action-Recognition" -> "woodfrog/ActionRecognition"
"qijiezhao/Video-Classification-Action-Recognition" -> "qijiezhao/py-denseflow"
"qijiezhao/Video-Classification-Action-Recognition" -> "bryanyzhu/two-stream-pytorch"
"qijiezhao/Video-Classification-Action-Recognition" -> "sujiongming/UCF-101_video_classification"
"qijiezhao/Video-Classification-Action-Recognition" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"qijiezhao/Video-Classification-Action-Recognition" -> "frankgu/3d-DenseNet"
"qijiezhao/Video-Classification-Action-Recognition" -> "Adopteruf/Action_Recognition_using_Visual_Attention"
"qijiezhao/Video-Classification-Action-Recognition" -> "coderSkyChen/Action_Recognition_Zoo"
"qijiezhao/Video-Classification-Action-Recognition" -> "kracwarlock/action-recognition-visual-attention"
"qijiezhao/Video-Classification-Action-Recognition" -> "TaeSoo-Kim/TCNActionRecognition"
"qijiezhao/Video-Classification-Action-Recognition" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"vkalogeiton/caffe" -> "gurkirt/corrected-UCF101-Annots"
"vkalogeiton/caffe" -> "imatge-upc/Action-Tubelet-Detection-in-AVA"
"vkalogeiton/caffe" -> "gurkirt/realtime-action-detection"
"vkalogeiton/caffe" -> "kevinlin311tw/ava-dataset-tool"
"xiaolonw/TimeCycle" -> "zlai0/CorrFlow" ["e"=1]
"xiaolonw/TimeCycle" -> "Liusifei/UVC" ["e"=1]
"xiaolonw/TimeCycle" -> "facebookresearch/video-long-term-feature-banks"
"xiaolonw/TimeCycle" -> "metalbubble/TRN-pytorch"
"xiaolonw/TimeCycle" -> "zlai0/MAST" ["e"=1]
"xiaolonw/TimeCycle" -> "facebookresearch/fair_self_supervision_benchmark" ["e"=1]
"xiaolonw/TimeCycle" -> "facebookresearch/video-nonlocal-net"
"xiaolonw/TimeCycle" -> "ajabri/videowalk" ["e"=1]
"xiaolonw/TimeCycle" -> "hassony2/kinetics_i3d_pytorch"
"xiaolonw/TimeCycle" -> "open-mmlab/mmaction"
"xiaolonw/TimeCycle" -> "yjxiong/action-detection"
"xiaolonw/TimeCycle" -> "mit-han-lab/temporal-shift-module"
"xiaolonw/TimeCycle" -> "chaoyuaw/pytorch-coviar"
"xiaolonw/TimeCycle" -> "google/revisiting-self-supervised" ["e"=1]
"xiaolonw/TimeCycle" -> "TengdaHan/DPC" ["e"=1]
"zhang-can/ECO-pytorch" -> "mzolfaghari/ECO-pytorch"
"zhang-can/ECO-pytorch" -> "mzolfaghari/ECO-efficient-video-understanding"
"zhang-can/ECO-pytorch" -> "metalbubble/TRN-pytorch"
"zhang-can/ECO-pytorch" -> "StrangerZhang/pyECO" ["e"=1]
"jishnujayakumar/MV-Tractus" -> "vadimkantorov/mpegflow"
"jishnujayakumar/MV-Tractus" -> "LukasBommes/mv-extractor"
"Alibaba-MIIL/STAM" -> "lucidrains/STAM-pytorch"
"Alibaba-MIIL/STAM" -> "lucidrains/TimeSformer-pytorch"
"Alibaba-MIIL/STAM" -> "zhang-can/PAN-PyTorch"
"Alibaba-MIIL/STAM" -> "Phoenix1327/tea-action-recognition"
"Alibaba-MIIL/STAM" -> "sallymmx/ActionCLIP"
"ZFTurbo/segmentation_models_3D" -> "ZFTurbo/classification_models_3D"
"ZFTurbo/segmentation_models_3D" -> "ZFTurbo/efficientnet_3D"
"ZFTurbo/segmentation_models_3D" -> "ZFTurbo/volumentations"
"Hrener/3D-Action-recognition" -> "shahroudy/NTURGB-D"
"Hrener/3D-Action-recognition" -> "microsoft/SGN"
"Hrener/3D-Action-recognition" -> "kenziyuliu/MS-G3D"
"Hrener/3D-Action-recognition" -> "lshiwjx/2s-AGCN"
"Hrener/3D-Action-recognition" -> "limaosen0/AS-GCN"
"Hrener/3D-Action-recognition" -> "kchengiva/Shift-GCN"
"Hrener/3D-Action-recognition" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"Hrener/3D-Action-recognition" -> "xiaoiker/GCN-NAS"
"Flowerfan/SF-Net" -> "naraysa/3c-net"
"Flowerfan/SF-Net" -> "sujoyp/wtalc-pytorch"
"Flowerfan/SF-Net" -> "zhang-can/UP-TAL"
"Flowerfan/SF-Net" -> "asrafulashiq/hamnet"
"linrongc/youtube-8m" -> "miha-skalic/youtube8mchallenge"
"linrongc/youtube-8m" -> "antoine77340/Youtube-8M-WILLOW"
"linrongc/youtube-8m" -> "zhangyaoyuan/NextVLAD-Attention-Model"
"linrongc/youtube-8m" -> "antoine77340/LOUPE"
"linrongc/youtube-8m" -> "linrongc/solution_youtube8m_v3"
"linrongc/youtube-8m" -> "miha-skalic/youtube8mchallange"
"linrongc/youtube-8m" -> "rohitgirdhar/ActionVLAD"
"linrongc/youtube-8m" -> "wangheda/youtube-8m"
"linrongc/youtube-8m" -> "lyakaap/NetVLAD-pytorch" ["e"=1]
"sayibet/fight-detection-surv-dataset" -> "imsoo/fight_detection"
"sayibet/fight-detection-surv-dataset" -> "mchengny/RWF2000-Video-Database-for-Violence-Detection"
"sayibet/fight-detection-surv-dataset" -> "meet-soni5720/Fight-Detection"
"sayibet/fight-detection-surv-dataset" -> "JoshuaPiinRueyPan/ViolenceDetection"
"Breakthrough/PySceneDetect" -> "AnyiRao/SceneSeg" ["e"=1]
"Breakthrough/PySceneDetect" -> "dmlc/decord"
"Breakthrough/PySceneDetect" -> "soCzech/TransNetV2" ["e"=1]
"Breakthrough/PySceneDetect" -> "CSAILVision/places365" ["e"=1]
"Breakthrough/PySceneDetect" -> "facebookresearch/pytorchvideo"
"Breakthrough/PySceneDetect" -> "jinwchoi/awesome-action-recognition"
"Breakthrough/PySceneDetect" -> "open-mmlab/mmaction"
"Breakthrough/PySceneDetect" -> "Zulko/moviepy" ["e"=1]
"Breakthrough/PySceneDetect" -> "yahoo/hecate" ["e"=1]
"Breakthrough/PySceneDetect" -> "facebookresearch/SlowFast"
"Breakthrough/PySceneDetect" -> "johmathe/shotdetect"
"Breakthrough/PySceneDetect" -> "movienet/movienet-tools" ["e"=1]
"Breakthrough/PySceneDetect" -> "open-mmlab/mmediting" ["e"=1]
"Breakthrough/PySceneDetect" -> "scikit-video/scikit-video"
"Breakthrough/PySceneDetect" -> "open-mmlab/mmaction2"
"OpenGVLab/InternVideo" -> "OpenGVLab/UniFormerV2"
"OpenGVLab/InternVideo" -> "MCG-NJU/VideoMAE"
"OpenGVLab/InternVideo" -> "happyharrycn/actionformer_release"
"OpenGVLab/InternVideo" -> "OpenGVLab/unmasked_teacher"
"OpenGVLab/InternVideo" -> "OpenGVLab/ego4d-eccv2022-solutions"
"OpenGVLab/InternVideo" -> "OpenGVLab/VideoMAEv2"
"OpenGVLab/InternVideo" -> "klauscc/VindLU"
"OpenGVLab/InternVideo" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"OpenGVLab/InternVideo" -> "showlab/EgoVLP" ["e"=1]
"OpenGVLab/InternVideo" -> "ttlmh/Bridge-Prompt"
"TianzhongSong/C3D-keras" -> "axon-research/c3d-keras"
"TianzhongSong/C3D-keras" -> "adamcasson/c3d"
"TianzhongSong/C3D-keras" -> "FingerRec/real_time_video_action_recognition"
"TianzhongSong/C3D-keras" -> "rekon/T3D-keras"
"TianzhongSong/C3D-keras" -> "wushidonguc/two-stream-action-recognition-keras"
"TianzhongSong/C3D-keras" -> "hx173149/C3D-tensorflow"
"TianzhongSong/C3D-keras" -> "2012013382/C3D-Tensorflow-slim"
"mohammed-elkomy/two-stream-action-recognition" -> "wushidonguc/two-stream-action-recognition-keras"
"woodfrog/ActionRecognition" -> "qijiezhao/Video-Classification-Action-Recognition"
"woodfrog/ActionRecognition" -> "feichtenhofer/twostreamfusion"
"woodfrog/ActionRecognition" -> "jeffreyyihuang/two-stream-action-recognition"
"woodfrog/ActionRecognition" -> "bryanyzhu/two-stream-pytorch"
"woodfrog/ActionRecognition" -> "eriklindernoren/Action-Recognition"
"woodfrog/ActionRecognition" -> "sagarvegad/Video-Classification-CNN-and-LSTM-"
"woodfrog/ActionRecognition" -> "coderSkyChen/Action_Recognition_Zoo"
"woodfrog/ActionRecognition" -> "TianzhongSong/Real-Time-Action-Recognition"
"woodfrog/ActionRecognition" -> "IDKiro/action-recognition"
"woodfrog/ActionRecognition" -> "kracwarlock/action-recognition-visual-attention"
"woodfrog/ActionRecognition" -> "HHTseng/video-classification"
"woodfrog/ActionRecognition" -> "MRzzm/action-recognition-models-pytorch"
"woodfrog/ActionRecognition" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"woodfrog/ActionRecognition" -> "XiaoCode-er/Two-Stream-CNN"
"Siyu-C/ACAR-Net" -> "MVIG-SJTU/AlphAction"
"Siyu-C/ACAR-Net" -> "MCG-NJU/MOC-Detector"
"Siyu-C/ACAR-Net" -> "wei-tim/YOWO"
"Siyu-C/ACAR-Net" -> "joaanna/something_else"
"Siyu-C/ACAR-Net" -> "aimagelab/STAGE_action_detection"
"Siyu-C/ACAR-Net" -> "facebookresearch/video-long-term-feature-banks"
"Siyu-C/ACAR-Net" -> "NVlabs/STEP"
"Siyu-C/ACAR-Net" -> "MCG-NJU/TDN"
"Siyu-C/ACAR-Net" -> "MCG-NJU/RTD-Action"
"Siyu-C/ACAR-Net" -> "MCG-NJU/CRCNN-Action"
"Siyu-C/ACAR-Net" -> "Rheelt/Materials-Temporal-Action-Detection"
"haofanwang/video-swin-transformer-pytorch" -> "SwinTransformer/Video-Swin-Transformer"
"piergiaj/super-events-cvpr18" -> "jiyanggao/CBR"
"piergiaj/super-events-cvpr18" -> "VisionLearningGroup/R-C3D"
"piergiaj/super-events-cvpr18" -> "demianzhang/weakly-action-localization"
"piergiaj/super-events-cvpr18" -> "shyamal-b/ss-tad"
"piergiaj/super-events-cvpr18" -> "hjjpku/Action_Detection_DQN"
"piergiaj/super-events-cvpr18" -> "bellos1203/STPN"
"zhang-can/CoLA" -> "LeonHLJ/RSKP"
"zhang-can/CoLA" -> "zhang-can/UP-TAL"
"zhang-can/CoLA" -> "Pilhyeon/WTAL-Uncertainty-Modeling"
"zhang-can/CoLA" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"zhang-can/CoLA" -> "LeonHLJ/FAC-Net"
"cmhungsteve/TA3N" -> "cmhungsteve/SSTDA"
"cmhungsteve/TA3N" -> "junyuGao/Zero-Shot-Action-Recognition-with-Two-Stream-GCN" ["e"=1]
"cmhungsteve/TA3N" -> "jonmun/MM-SADA-code"
"cmhungsteve/TA3N" -> "fpv-iplab/rulstm" ["e"=1]
"aminyazdanpanah/PHP-FFmpeg-video-streaming" -> "aminyazdanpanah/shaka-php"
"aminyazdanpanah/PHP-FFmpeg-video-streaming" -> "pascalbaljetmedia/laravel-ffmpeg" ["e"=1]
"aminyazdanpanah/PHP-FFmpeg-video-streaming" -> "aminyazdanpanah/python-ffmpeg-video-streaming"
"aminyazdanpanah/PHP-FFmpeg-video-streaming" -> "protonemedia/laravel-ffmpeg" ["e"=1]
"aminyazdanpanah/PHP-FFmpeg-video-streaming" -> "PHP-FFMpeg/PHP-FFMpeg" ["e"=1]
"aminyazdanpanah/PHP-FFmpeg-video-streaming" -> "warren-bank/HLS-Proxy"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "kracwarlock/action-recognition-visual-attention"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "imatge-upc/activitynet-2016-cvprw"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "jeffreyhuang1/two-stream-action-recognition"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "qijiezhao/Video-Classification-Action-Recognition"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "rohitgirdhar/ActionVLAD"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "LisaAnne/lisa-caffe-public"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "feichtenhofer/twostreamfusion"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "oswaldoludwig/Human-Action-Recognition-with-Keras"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "feichtenhofer/st-resnet"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "yjxiong/temporal-segment-networks"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "zhengshou/scnn"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "hx173149/C3D-tensorflow"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "bryanyzhu/two-stream-pytorch"
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" -> "gurkirt/realtime-action-detection"
"MCG-NJU/MOC-Detector" -> "wei-tim/YOWO"
"MCG-NJU/MOC-Detector" -> "NVlabs/STEP"
"MCG-NJU/MOC-Detector" -> "MCG-NJU/CRCNN-Action"
"MCG-NJU/MOC-Detector" -> "MCG-NJU/MultiSports"
"MCG-NJU/MOC-Detector" -> "MVIG-SJTU/AlphAction"
"MCG-NJU/MOC-Detector" -> "Siyu-C/ACAR-Net"
"MCG-NJU/MOC-Detector" -> "MCG-NJU/TDN"
"MCG-NJU/MOC-Detector" -> "Rheelt/Materials-Temporal-Action-Detection"
"MCG-NJU/MOC-Detector" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"MCG-NJU/MOC-Detector" -> "gurkirt/realtime-action-detection"
"MCG-NJU/MOC-Detector" -> "MCG-NJU/MMN" ["e"=1]
"MCG-NJU/MOC-Detector" -> "Phoenix1327/tea-action-recognition"
"MCG-NJU/MOC-Detector" -> "facebookresearch/video-long-term-feature-banks"
"MCG-NJU/MOC-Detector" -> "MCG-NJU/FCOT" ["e"=1]
"MCG-NJU/MOC-Detector" -> "JJBOY/BMN-Boundary-Matching-Network"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "TencentYoutuResearch/ActionDetection-AFSD"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "Rheelt/Materials-Temporal-Action-Detection"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "HumamAlwassel/TSP"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "Alvin-Zeng/PGCN"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "JJBOY/BMN-Boundary-Matching-Network"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "frostinassiky/gtad"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "Nmegha2601/activitygraph_transformer"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "happyharrycn/actionformer_release"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "xlliu7/TadTR"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "sujoyp/wtalc-pytorch"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "MCG-NJU/RTD-Action"
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"1zgh/st-gcn" -> "yongqyu/st-gcn-pytorch"
"ASMIftekhar/VSGNet" -> "zhihou7/VCL"
"ASMIftekhar/VSGNet" -> "bobwan1995/PMFNet"
"ASMIftekhar/VSGNet" -> "vt-vl-lab/DRG"
"ASMIftekhar/VSGNet" -> "BigRedT/no_frills_hoi_det"
"ASMIftekhar/VSGNet" -> "vaesl/IP-Net"
"ASMIftekhar/VSGNet" -> "vt-vl-lab/iCAN"
"ASMIftekhar/VSGNet" -> "YueLiao/PPDM"
"ASMIftekhar/VSGNet" -> "s-gupta/v-coco"
"ASMIftekhar/VSGNet" -> "tfzhou/C-HOI"
"ASMIftekhar/VSGNet" -> "DirtyHarryLYL/HOI-Learning-List"
"ASMIftekhar/VSGNet" -> "DirtyHarryLYL/DJ-RN"
"ASMIftekhar/VSGNet" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"XiaoCode-er/Two-Stream-CNN" -> "wushidonguc/two-stream-action-recognition-keras"
"craston/MARS" -> "piergiaj/representation-flow-cvpr19"
"craston/MARS" -> "decisionforce/TPN"
"craston/MARS" -> "swathikirans/GSM"
"craston/MARS" -> "zhang-can/PAN-PyTorch"
"craston/MARS" -> "mzolfaghari/ECO-pytorch"
"craston/MARS" -> "Phoenix1327/tea-action-recognition"
"craston/MARS" -> "limaosen0/AS-GCN"
"craston/MARS" -> "V-Sense/ACTION-Net"
"craston/MARS" -> "irhum/R2Plus1D-PyTorch"
"cvdfoundation/ava-dataset" -> "NVlabs/STEP"
"cvdfoundation/ava-dataset" -> "activitynet/ActivityNet"
"cvdfoundation/ava-dataset" -> "SmartPorridge/google-AVA-Dataset-downloader"
"cvdfoundation/ava-dataset" -> "vkalogeiton/caffe"
"cvdfoundation/ava-dataset" -> "kevinlin311tw/ava-dataset-tool"
"cvdfoundation/ava-dataset" -> "gurkirt/realtime-action-detection"
"cvdfoundation/ava-dataset" -> "gurkirt/corrected-UCF101-Annots"
"cvdfoundation/ava-dataset" -> "MVIG-SJTU/AlphAction"
"cvdfoundation/ava-dataset" -> "hangzhaomit/HACS-dataset"
"cvdfoundation/ava-dataset" -> "s9xie/Mini-Kinetics-200"
"cvdfoundation/ava-dataset" -> "hassony2/kinetics_i3d_pytorch"
"cvdfoundation/ava-dataset" -> "wei-tim/YOWO"
"cvdfoundation/ava-dataset" -> "oulutan/ACAM_Demo"
"cvdfoundation/ava-dataset" -> "cvlab-columbia/oops"
"cvdfoundation/ava-dataset" -> "Siyu-C/ACAR-Net"
"facebookresearch/video-long-term-feature-banks" -> "noureldien/timeception"
"facebookresearch/video-long-term-feature-banks" -> "gsig/PyVideoResearch"
"facebookresearch/video-long-term-feature-banks" -> "cypw/PyTorch-MFNet"
"facebookresearch/video-long-term-feature-banks" -> "xiaolonw/TimeCycle"
"facebookresearch/video-long-term-feature-banks" -> "decisionforce/TPN"
"facebookresearch/video-long-term-feature-banks" -> "hangzhaomit/HACS-dataset"
"facebookresearch/video-long-term-feature-banks" -> "activitynet/ActivityNet"
"facebookresearch/video-long-term-feature-banks" -> "Alvin-Zeng/PGCN"
"facebookresearch/video-long-term-feature-banks" -> "MCG-NJU/MOC-Detector"
"facebookresearch/video-long-term-feature-banks" -> "facebookresearch/VMZ"
"facebookresearch/video-long-term-feature-banks" -> "NVlabs/STEP"
"facebookresearch/video-long-term-feature-banks" -> "zhoubolei/TRN-pytorch"
"facebookresearch/video-long-term-feature-banks" -> "Rheelt/Materials-Temporal-Action-Detection"
"facebookresearch/video-long-term-feature-banks" -> "JingweiJ/ActionGenome" ["e"=1]
"facebookresearch/video-long-term-feature-banks" -> "metalbubble/TRN-pytorch"
"hangzhaomit/HACS-dataset" -> "Finspire13/CMCS-Temporal-Action-Localization"
"hangzhaomit/HACS-dataset" -> "naraysa/3c-net"
"hangzhaomit/HACS-dataset" -> "sujoyp/wtalc-pytorch"
"hangzhaomit/HACS-dataset" -> "wzmsltw/BSN-boundary-sensitive-network"
"hangzhaomit/HACS-dataset" -> "Rheelt/Materials-Temporal-Action-Detection"
"hangzhaomit/HACS-dataset" -> "wanglimin/UntrimmedNet"
"mzolfaghari/ECO-pytorch" -> "mzolfaghari/ECO-efficient-video-understanding"
"mzolfaghari/ECO-pytorch" -> "zhang-can/ECO-pytorch"
"mzolfaghari/ECO-pytorch" -> "metalbubble/TRN-pytorch"
"mzolfaghari/ECO-pytorch" -> "decisionforce/TPN"
"mzolfaghari/ECO-pytorch" -> "piergiaj/representation-flow-cvpr19"
"mzolfaghari/ECO-pytorch" -> "yjxiong/tsn-pytorch"
"mzolfaghari/ECO-pytorch" -> "zhoubolei/TRN-pytorch"
"mzolfaghari/ECO-pytorch" -> "coderSkyChen/Action_Recognition_Zoo"
"mzolfaghari/ECO-pytorch" -> "craston/MARS"
"mzolfaghari/ECO-pytorch" -> "wzmsltw/BSN-boundary-sensitive-network"
"mzolfaghari/ECO-pytorch" -> "r1ch88/SlowFastNetworks"
"mzolfaghari/ECO-pytorch" -> "yjxiong/temporal-segment-networks"
"mzolfaghari/ECO-pytorch" -> "mit-han-lab/temporal-shift-module"
"mzolfaghari/ECO-pytorch" -> "gurkirt/realtime-action-detection"
"mzolfaghari/ECO-pytorch" -> "open-mmlab/mmaction"
"naraysa/3c-net" -> "sujoyp/wtalc-pytorch"
"naraysa/3c-net" -> "asrafulashiq/wsad"
"naraysa/3c-net" -> "MichiganCOG/A2CL-PT"
"naraysa/3c-net" -> "Finspire13/CMCS-Temporal-Action-Localization"
"naraysa/3c-net" -> "zhengshou/AutoLoc"
"naraysa/3c-net" -> "bellos1203/STPN"
"naraysa/3c-net" -> "demianzhang/weakly-action-localization"
"sujoyp/wtalc-pytorch" -> "bellos1203/STPN"
"sujoyp/wtalc-pytorch" -> "Finspire13/CMCS-Temporal-Action-Localization"
"sujoyp/wtalc-pytorch" -> "zhengshou/AutoLoc"
"sujoyp/wtalc-pytorch" -> "naraysa/3c-net"
"sujoyp/wtalc-pytorch" -> "Pilhyeon/BaSNet-pytorch"
"sujoyp/wtalc-pytorch" -> "Rheelt/Materials-Temporal-Action-Detection"
"sujoyp/wtalc-pytorch" -> "asrafulashiq/wsad"
"sujoyp/wtalc-pytorch" -> "MichiganCOG/A2CL-PT"
"sujoyp/wtalc-pytorch" -> "wanglimin/UntrimmedNet"
"sujoyp/wtalc-pytorch" -> "bfshi/DGAM-Weakly-Supervised-Action-Localization"
"sujoyp/wtalc-pytorch" -> "Flowerfan/SF-Net"
"sujoyp/wtalc-pytorch" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"sujoyp/wtalc-pytorch" -> "demianzhang/weakly-action-localization"
"sujoyp/wtalc-pytorch" -> "Alvin-Zeng/PGCN"
"sujoyp/wtalc-pytorch" -> "wzmsltw/BSN-boundary-sensitive-network"
"qiaoguan/Fall-detection" -> "AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow"
"qiaoguan/Fall-detection" -> "kasakun/Fall-Detection"
"qiaoguan/Fall-detection" -> "chizhanyuefeng/FD-CNN"
"qiaoguan/Fall-detection" -> "JJN123/Fall-Detection"
"qiaoguan/Fall-detection" -> "harishrithish7/Fall-Detection"
"qiaoguan/Fall-detection" -> "KimChwee/Fall-Detection-Py-Raspberry"
"qiaoguan/Fall-detection" -> "cwlroda/falldetection_openpifpaf"
"qiaoguan/Fall-detection" -> "mgei/fall-detection"
"feichtenhofer/gpu_flow" -> "feichtenhofer/twostreamfusion"
"feichtenhofer/gpu_flow" -> "yjxiong/dense_flow"
"feichtenhofer/gpu_flow" -> "qijiezhao/py-denseflow"
"feichtenhofer/gpu_flow" -> "bryanyzhu/two-stream-pytorch"
"feichtenhofer/gpu_flow" -> "wanglimin/dense_flow"
"feichtenhofer/gpu_flow" -> "jeffreyhuang1/two-stream-action-recognition"
"feichtenhofer/gpu_flow" -> "yjxiong/temporal-segment-networks"
"feichtenhofer/gpu_flow" -> "yjxiong/tsn-pytorch"
"feichtenhofer/gpu_flow" -> "lmb-freiburg/flownet2-docker"
"feichtenhofer/gpu_flow" -> "deepmind/kinetics-i3d"
"feichtenhofer/gpu_flow" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"feichtenhofer/gpu_flow" -> "wzmsltw/BSN-boundary-sensitive-network"
"feichtenhofer/gpu_flow" -> "hassony2/kinetics_i3d_pytorch"
"feichtenhofer/gpu_flow" -> "jeffreyyihuang/two-stream-action-recognition"
"feichtenhofer/gpu_flow" -> "feichtenhofer/st-resnet"
"lood339/two_point_calib" -> "lood339/SCCvSD"
"vadimkantorov/mpegflow" -> "jishnujayakumar/MV-Tractus"
"vadimkantorov/mpegflow" -> "zbwglory/MV-release"
"vadimkantorov/mpegflow" -> "LukasBommes/mv-extractor"
"DirtyHarryLYL/HOI-Learning-List" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"DirtyHarryLYL/HOI-Learning-List" -> "YueLiao/PPDM"
"DirtyHarryLYL/HOI-Learning-List" -> "DirtyHarryLYL/HAKE-Action-Torch"
"DirtyHarryLYL/HOI-Learning-List" -> "s-gupta/v-coco"
"DirtyHarryLYL/HOI-Learning-List" -> "hitachi-rd-cv/qpic"
"DirtyHarryLYL/HOI-Learning-List" -> "DirtyHarryLYL/HAKE"
"DirtyHarryLYL/HOI-Learning-List" -> "DirtyHarryLYL/HAKE-Action"
"DirtyHarryLYL/HOI-Learning-List" -> "BigRedT/no_frills_hoi_det"
"DirtyHarryLYL/HOI-Learning-List" -> "vt-vl-lab/iCAN"
"DirtyHarryLYL/HOI-Learning-List" -> "vt-vl-lab/DRG"
"DirtyHarryLYL/HOI-Learning-List" -> "DirtyHarryLYL/DJ-RN"
"DirtyHarryLYL/HOI-Learning-List" -> "fredzzhang/upt"
"DirtyHarryLYL/HOI-Learning-List" -> "zhihou7/HOI-CL"
"DirtyHarryLYL/HOI-Learning-List" -> "ASMIftekhar/VSGNet"
"DirtyHarryLYL/HOI-Learning-List" -> "YueLiao/gen-vlkt"
"alexandonian/pretorched-x" -> "irhumshafkat/R2Plus1D-PyTorch"
"alexandonian/pretorched-x" -> "gsig/PyVideoResearch"
"alexandonian/pretorched-x" -> "cypw/PyTorch-MFNet"
"alexandonian/pretorched-x" -> "qijiezhao/s3d.pytorch"
"alexandonian/pretorched-x" -> "rohitgirdhar/ActionVLAD"
"alexandonian/pretorched-x" -> "RI-CH/SlowFastNetworks"
"alexandonian/pretorched-x" -> "ZhaofanQiu/local-and-global-diffusion-networks"
"alexandonian/pretorched-x" -> "mzolfaghari/ECO-efficient-video-understanding"
"alexandonian/pretorched-x" -> "Tushar-N/pytorch-resnet3d"
"alexandonian/pretorched-x" -> "qijiezhao/pseudo-3d-pytorch"
"alexandonian/pretorched-x" -> "facebookresearch/video-long-term-feature-banks"
"alexandonian/pretorched-x" -> "facebookresearch/R2Plus1D"
"alexandonian/pretorched-x" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"alexandonian/pretorched-x" -> "wzmsltw/BSN-boundary-sensitive-network"
"metalbubble/moments_models" -> "metalbubble/TRN-pytorch"
"metalbubble/moments_models" -> "hassony2/kinetics_i3d_pytorch"
"metalbubble/moments_models" -> "gsig/charades-algorithms"
"metalbubble/moments_models" -> "yoosan/video-understanding-dataset"
"metalbubble/moments_models" -> "facebookresearch/R2Plus1D"
"metalbubble/moments_models" -> "wanglimin/ARTNet"
"metalbubble/moments_models" -> "rohitgirdhar/AttentionalPoolingAction"
"metalbubble/moments_models" -> "gsig/PyVideoResearch"
"metalbubble/moments_models" -> "wanglimin/UntrimmedNet"
"metalbubble/moments_models" -> "qijiezhao/pseudo-3d-pytorch"
"metalbubble/moments_models" -> "chaoyuaw/pytorch-coviar"
"metalbubble/moments_models" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"metalbubble/moments_models" -> "jeffreyhuang1/two-stream-action-recognition"
"metalbubble/moments_models" -> "gsig/temporal-fields"
"metalbubble/moments_models" -> "MohsenFayyaz89/T3D"
"vt-vl-lab/iCAN" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"vt-vl-lab/iCAN" -> "ywchao/ho-rcnn"
"vt-vl-lab/iCAN" -> "s-gupta/v-coco"
"vt-vl-lab/iCAN" -> "SiyuanQi/gpnn"
"vt-vl-lab/iCAN" -> "BigRedT/no_frills_hoi_det"
"vt-vl-lab/iCAN" -> "bobwan1995/PMFNet"
"vt-vl-lab/iCAN" -> "YueLiao/PPDM"
"vt-vl-lab/iCAN" -> "vaesl/IP-Net"
"vt-vl-lab/iCAN" -> "vt-vl-lab/DRG"
"vt-vl-lab/iCAN" -> "chinancheng/awesome-human-object-interaction"
"vt-vl-lab/iCAN" -> "DirtyHarryLYL/HAKE"
"vt-vl-lab/iCAN" -> "DirtyHarryLYL/HOI-Learning-List"
"vt-vl-lab/iCAN" -> "ASMIftekhar/VSGNet"
"vt-vl-lab/iCAN" -> "DirtyHarryLYL/DJ-RN"
"vt-vl-lab/iCAN" -> "tfzhou/C-HOI"
"Finspire13/CMCS-Temporal-Action-Localization" -> "sujoyp/wtalc-pytorch"
"Finspire13/CMCS-Temporal-Action-Localization" -> "zhengshou/AutoLoc"
"Finspire13/CMCS-Temporal-Action-Localization" -> "bellos1203/STPN"
"Finspire13/CMCS-Temporal-Action-Localization" -> "naraysa/3c-net"
"Finspire13/CMCS-Temporal-Action-Localization" -> "Finspire13/pytorch-i3d-feature-extraction"
"Finspire13/CMCS-Temporal-Action-Localization" -> "HYPJUDY/Decouple-SSAD"
"Finspire13/CMCS-Temporal-Action-Localization" -> "Pilhyeon/BaSNet-pytorch"
"Finspire13/CMCS-Temporal-Action-Localization" -> "asrafulashiq/wsad"
"Finspire13/CMCS-Temporal-Action-Localization" -> "Rheelt/Materials-Temporal-Action-Detection"
"Finspire13/CMCS-Temporal-Action-Localization" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"Finspire13/CMCS-Temporal-Action-Localization" -> "bfshi/DGAM-Weakly-Supervised-Action-Localization"
"Finspire13/CMCS-Temporal-Action-Localization" -> "Alvin-Zeng/PGCN"
"Finspire13/CMCS-Temporal-Action-Localization" -> "demianzhang/weakly-action-localization"
"Finspire13/CMCS-Temporal-Action-Localization" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"Finspire13/CMCS-Temporal-Action-Localization" -> "Pilhyeon/Background-Modeling-via-Uncertainty-Estimation"
"MCG-NJU/RTD-Action" -> "HumamAlwassel/TSP"
"MCG-NJU/RTD-Action" -> "MCG-NJU/BasicTAD"
"MCG-NJU/RTD-Action" -> "TencentYoutuResearch/ActionDetection-AFSD"
"NVlabs/STEP" -> "aimagelab/STAGE_action_detection"
"NVlabs/STEP" -> "MVIG-SJTU/AlphAction"
"NVlabs/STEP" -> "MCG-NJU/MOC-Detector"
"NVlabs/STEP" -> "gurkirt/realtime-action-detection"
"NVlabs/STEP" -> "Rheelt/Materials-Temporal-Action-Detection"
"NVlabs/STEP" -> "cvdfoundation/ava-dataset"
"NVlabs/STEP" -> "oulutan/ACAM_Demo"
"NVlabs/STEP" -> "leaderj1001/Action-Localization"
"NVlabs/STEP" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"NVlabs/STEP" -> "JJBOY/BMN-Boundary-Matching-Network"
"NVlabs/STEP" -> "facebookresearch/video-long-term-feature-banks"
"NVlabs/STEP" -> "imatge-upc/Action-Tubelet-Detection-in-AVA"
"NVlabs/STEP" -> "Siyu-C/ACAR-Net"
"NVlabs/STEP" -> "wei-tim/YOWO"
"NVlabs/STEP" -> "kevinlin311tw/ava-dataset-tool"
"TencentYoutuResearch/ActionDetection-AFSD" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"TencentYoutuResearch/ActionDetection-AFSD" -> "xlliu7/E2E-TAD"
"TencentYoutuResearch/ActionDetection-AFSD" -> "HumamAlwassel/TSP"
"TencentYoutuResearch/ActionDetection-AFSD" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"TencentYoutuResearch/ActionDetection-AFSD" -> "MCG-NJU/RTD-Action"
"TencentYoutuResearch/ActionDetection-AFSD" -> "frostinassiky/gtad"
"TencentYoutuResearch/ActionDetection-AFSD" -> "zhang-can/UP-TAL"
"TencentYoutuResearch/ActionDetection-AFSD" -> "Flowerfan/SF-Net"
"TencentYoutuResearch/ActionDetection-AFSD" -> "Alvin-Zeng/PGCN"
"TencentYoutuResearch/ActionDetection-AFSD" -> "buxiangzhiren/ContextLoc"
"TencentYoutuResearch/ActionDetection-AFSD" -> "happyharrycn/actionformer_release"
"TencentYoutuResearch/ActionDetection-AFSD" -> "qinzhi-0110/Temporal-Context-Aggregation-Network-Pytorch"
"TencentYoutuResearch/ActionDetection-AFSD" -> "Finspire13/CMCS-Temporal-Action-Localization"
"TencentYoutuResearch/ActionDetection-AFSD" -> "xlliu7/MUSES"
"TencentYoutuResearch/ActionDetection-AFSD" -> "LeonHLJ/RSKP"
"kracwarlock/action-recognition-visual-attention" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"kracwarlock/action-recognition-visual-attention" -> "feichtenhofer/twostreamfusion"
"kracwarlock/action-recognition-visual-attention" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"kracwarlock/action-recognition-visual-attention" -> "hbilen/dynamic-image-nets"
"kracwarlock/action-recognition-visual-attention" -> "oswaldoludwig/Human-Action-Recognition-with-Keras"
"kracwarlock/action-recognition-visual-attention" -> "imatge-upc/activitynet-2016-cvprw"
"kracwarlock/action-recognition-visual-attention" -> "qijiezhao/Video-Classification-Action-Recognition"
"kracwarlock/action-recognition-visual-attention" -> "TaeSoo-Kim/TCNActionRecognition"
"kracwarlock/action-recognition-visual-attention" -> "rohitgirdhar/AttentionalPoolingAction"
"kracwarlock/action-recognition-visual-attention" -> "LisaAnne/lisa-caffe-public"
"kracwarlock/action-recognition-visual-attention" -> "yjxiong/caffe"
"kracwarlock/action-recognition-visual-attention" -> "frankgu/3d-DenseNet"
"kracwarlock/action-recognition-visual-attention" -> "yjxiong/temporal-segment-networks"
"kracwarlock/action-recognition-visual-attention" -> "zhengshou/scnn"
"kracwarlock/action-recognition-visual-attention" -> "facebook/C3D"
"xiaobai1217/Awesome-Video-Datasets" -> "TengdaHan/TemporalAlignNet" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "antoine77340/MIL-NCE_HowTo100M" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "TengdaHan/CoCLR" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "m-bain/frozen-in-time" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"xiaobai1217/Awesome-Video-Datasets" -> "okankop/vidaug"
"xiaobai1217/Awesome-Video-Datasets" -> "krantiparida/awesome-audio-visual" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "facebookresearch/pytorchvideo"
"xiaobai1217/Awesome-Video-Datasets" -> "Soldelli/Awesome-Temporal-Language-Grounding-in-Videos" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "lucidrains/TimeSformer-pytorch"
"xiaobai1217/Awesome-Video-Datasets" -> "facebookresearch/omnivore"
"xiaobai1217/Awesome-Video-Datasets" -> "jayleicn/ClipBERT" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "microsoft/XPretrain" ["e"=1]
"xiaobai1217/Awesome-Video-Datasets" -> "MCG-NJU/VideoMAE"
"xiaobai1217/Awesome-Video-Datasets" -> "HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis"
"Guocode/SlowFast-Networks" -> "RI-CH/SlowFastNetworks"
"Guocode/SlowFast-Networks" -> "ZhaofanQiu/local-and-global-diffusion-networks"
"ZhaofanQiu/local-and-global-diffusion-networks" -> "Guocode/SlowFast-Networks"
"ZhaofanQiu/local-and-global-diffusion-networks" -> "KevinDuarte/VideoCapsuleNet"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "qijiezhao/pseudo-3d-pytorch"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "facebook/C3D"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "wanglimin/ARTNet"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "deepmind/kinetics-i3d"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "rohitgirdhar/ActionVLAD"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "wanglimin/UntrimmedNet"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "VisionLearningGroup/R-C3D"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "yjxiong/action-detection"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "facebookresearch/R2Plus1D"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "activitynet/ActivityNet"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "mzolfaghari/ECO-efficient-video-understanding"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "yjxiong/tsn-pytorch"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "hx173149/C3D-tensorflow"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "yjxiong/anet2016-cuhk"
"ZhaofanQiu/pseudo-3d-residual-networks" -> "facebookresearch/VMZ"
"feiyunzhang/i3d-non-local-pytorch" -> "tomrunia/PyTorchConv3D"
"rohitgirdhar/ActionVLAD" -> "rohitgirdhar/AttentionalPoolingAction"
"rohitgirdhar/ActionVLAD" -> "qijiezhao/Video-Classification-Action-Recognition"
"rohitgirdhar/ActionVLAD" -> "wanglimin/ARTNet"
"rohitgirdhar/ActionVLAD" -> "bryanyzhu/Hidden-Two-Stream"
"rohitgirdhar/ActionVLAD" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"rohitgirdhar/ActionVLAD" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"rohitgirdhar/ActionVLAD" -> "gsig/actions-for-actions"
"rohitgirdhar/ActionVLAD" -> "feichtenhofer/st-resnet"
"rohitgirdhar/ActionVLAD" -> "shyamal-b/sst"
"rohitgirdhar/ActionVLAD" -> "antoine77340/LOUPE"
"rohitgirdhar/ActionVLAD" -> "bryanyzhu/two-stream-pytorch"
"rohitgirdhar/ActionVLAD" -> "gsig/temporal-fields"
"rohitgirdhar/ActionVLAD" -> "qijiezhao/py-denseflow"
"rohitgirdhar/ActionVLAD" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"rohitgirdhar/ActionVLAD" -> "gurkirt/realtime-action-detection"
"ttlmh/Bridge-Prompt" -> "ChinaYi/ASFormer"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "vt-vl-lab/iCAN"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "DirtyHarryLYL/HAKE"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "bobwan1995/PMFNet"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "s-gupta/v-coco"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "BigRedT/no_frills_hoi_det"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "DirtyHarryLYL/HOI-Learning-List"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "YueLiao/PPDM"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "DirtyHarryLYL/HAKE-Action"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "SiyuanQi/gpnn"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "ywchao/ho-rcnn"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "DirtyHarryLYL/DJ-RN"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "DirtyHarryLYL/HAKE-Action-Torch"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "ASMIftekhar/VSGNet"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "vaesl/IP-Net"
"DirtyHarryLYL/Transferable-Interactiveness-Network" -> "chinancheng/awesome-human-object-interaction"
"FesianXu/PLSTM" -> "fandulu/Keras-for-Co-occurrence-Feature-Learning-from-Skeleton-Data-for-Action-Recognition"
"coderSkyChen/Action_Recognition_Zoo" -> "hassony2/kinetics_i3d_pytorch"
"coderSkyChen/Action_Recognition_Zoo" -> "qijiezhao/s3d.pytorch"
"coderSkyChen/Action_Recognition_Zoo" -> "piergiaj/representation-flow-cvpr19"
"coderSkyChen/Action_Recognition_Zoo" -> "gurkirt/realtime-action-detection"
"coderSkyChen/Action_Recognition_Zoo" -> "gsig/PyVideoResearch"
"coderSkyChen/Action_Recognition_Zoo" -> "qijiezhao/Video-Classification-Action-Recognition"
"coderSkyChen/Action_Recognition_Zoo" -> "mzolfaghari/ECO-pytorch"
"coderSkyChen/Action_Recognition_Zoo" -> "metalbubble/TRN-pytorch"
"coderSkyChen/Action_Recognition_Zoo" -> "tomar840/two-stream-fusion-for-action-recognition-in-videos"
"coderSkyChen/Action_Recognition_Zoo" -> "kevin-ssy/Optical-Flow-Guided-Feature"
"coderSkyChen/Action_Recognition_Zoo" -> "USTC-Video-Understanding/I3D_Finetune"
"coderSkyChen/Action_Recognition_Zoo" -> "irhumshafkat/R2Plus1D-PyTorch"
"coderSkyChen/Action_Recognition_Zoo" -> "hassony2/inflated_convnets_pytorch"
"coderSkyChen/Action_Recognition_Zoo" -> "FingerRec/real_time_video_action_recognition"
"coderSkyChen/Action_Recognition_Zoo" -> "qijiezhao/py-denseflow"
"LisaAnne/lisa-caffe-public" -> "jeffdonahue/caffe" ["e"=1]
"LisaAnne/lisa-caffe-public" -> "junhyukoh/caffe-lstm" ["e"=1]
"LisaAnne/lisa-caffe-public" -> "garythung/torch-lrcn"
"LisaAnne/lisa-caffe-public" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"LisaAnne/lisa-caffe-public" -> "vsubhashini/caffe" ["e"=1]
"LisaAnne/lisa-caffe-public" -> "facebook/C3D"
"LisaAnne/lisa-caffe-public" -> "kracwarlock/action-recognition-visual-attention"
"LisaAnne/lisa-caffe-public" -> "yjxiong/caffe"
"LisaAnne/lisa-caffe-public" -> "wanglimin/dense_flow"
"LisaAnne/lisa-caffe-public" -> "chuckcho/video-caffe"
"chizhanyuefeng/FD-CNN" -> "chizhanyuefeng/Realtime-Fall-Detection-for-RNN"
"chizhanyuefeng/FD-CNN" -> "WJMatthew/SisFallAnalysis"
"Levigty/AimCLR" -> "czhaneva/MST-GCN"
"Levigty/AimCLR" -> "czhaneva/SkeleMixCLR"
"Levigty/AimCLR" -> "JHang2020/HiCLR"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "XiaoCode-er/Skeleton-Based-Action-Recognition-Papers"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "limaosen0/AS-GCN"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "huguyuehuhu/HCN-pytorch"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "shahroudy/NTURGB-D"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "kenziyuliu/DGNN-PyTorch"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "shuangshuangguo/skeleton-based-action-recognition-review"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "InwoongLee/TS-LSTM"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "hongsong-wang/RNN-for-skeletons"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "nkliuyifang/Skeleton-based-Human-Action-Recognition"
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" -> "lshiwjx/2s-AGCN"
"kchengiva/DecoupleGCN-DropGraph" -> "yfsong0709/ResGCNv1"
"kchengiva/DecoupleGCN-DropGraph" -> "kchengiva/Shift-GCN"
"kchengiva/DecoupleGCN-DropGraph" -> "microsoft/SGN"
"kchengiva/DecoupleGCN-DropGraph" -> "lshiwjx/DSTA-Net"
"kchengiva/DecoupleGCN-DropGraph" -> "Chiaraplizz/ST-TR"
"kchengiva/DecoupleGCN-DropGraph" -> "Uason-Chen/CTR-GCN"
"kchengiva/Shift-GCN" -> "kenziyuliu/MS-G3D"
"kchengiva/Shift-GCN" -> "microsoft/SGN"
"kchengiva/Shift-GCN" -> "xiaoiker/GCN-NAS"
"kchengiva/Shift-GCN" -> "lshiwjx/2s-AGCN"
"kchengiva/Shift-GCN" -> "yfsong0709/ResGCNv1"
"kchengiva/Shift-GCN" -> "limaosen0/AS-GCN"
"kchengiva/Shift-GCN" -> "Uason-Chen/CTR-GCN"
"kchengiva/Shift-GCN" -> "kchengiva/DecoupleGCN-DropGraph"
"kchengiva/Shift-GCN" -> "shlizee/Predict-Cluster"
"kchengiva/Shift-GCN" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"kchengiva/Shift-GCN" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"kchengiva/Shift-GCN" -> "Chiaraplizz/ST-TR"
"kchengiva/Shift-GCN" -> "shahroudy/NTURGB-D"
"kchengiva/Shift-GCN" -> "kenziyuliu/DGNN-PyTorch"
"kchengiva/Shift-GCN" -> "huguyuehuhu/HCN-pytorch"
"liu-zhy/temporal-adaptive-module" -> "Phoenix1327/tea-action-recognition"
"liu-zhy/temporal-adaptive-module" -> "MCG-NJU/TDN"
"liu-zhy/temporal-adaptive-module" -> "V-Sense/ACTION-Net"
"microsoft/SGN" -> "kchengiva/Shift-GCN"
"microsoft/SGN" -> "kenziyuliu/MS-G3D"
"microsoft/SGN" -> "Uason-Chen/CTR-GCN"
"microsoft/SGN" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"microsoft/SGN" -> "xiaoiker/GCN-NAS"
"microsoft/SGN" -> "yfsong0709/ResGCNv1"
"microsoft/SGN" -> "lshiwjx/2s-AGCN"
"microsoft/SGN" -> "kchengiva/DecoupleGCN-DropGraph"
"microsoft/SGN" -> "Chiaraplizz/ST-TR"
"microsoft/SGN" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"microsoft/SGN" -> "limaosen0/AS-GCN"
"microsoft/SGN" -> "shahroudy/NTURGB-D"
"microsoft/SGN" -> "yfsong0709/RA-GCNv1"
"microsoft/SGN" -> "fabro66/Online-Skeleton-based-Action-Recognition" ["e"=1]
"microsoft/SGN" -> "yfsong0709/EfficientGCNv1"
"stnoah1/infogcn" -> "Jho-Yonsei/HD-GCN" ["e"=1]
"stnoah1/infogcn" -> "MartinXM/LST"
"stnoah1/infogcn" -> "czhaneva/MST-GCN"
"stnoah1/infogcn" -> "Levigty/AimCLR"
"stnoah1/infogcn" -> "Uason-Chen/CTR-GCN"
"tomrunia/PyTorchConv3D" -> "hassony2/kinetics_i3d_pytorch"
"tomrunia/PyTorchConv3D" -> "feiyunzhang/i3d-non-local-pytorch"
"tomrunia/PyTorchConv3D" -> "piergiaj/pytorch-i3d"
"tomrunia/PyTorchConv3D" -> "Tushar-N/pytorch-resnet3d"
"tomrunia/PyTorchConv3D" -> "piergiaj/tgm-icml19"
"Rheelt/Materials-Temporal-Action-Detection" -> "sujoyp/wtalc-pytorch"
"Rheelt/Materials-Temporal-Action-Detection" -> "JJBOY/BMN-Boundary-Matching-Network"
"Rheelt/Materials-Temporal-Action-Detection" -> "Finspire13/CMCS-Temporal-Action-Localization"
"Rheelt/Materials-Temporal-Action-Detection" -> "Tencent/ActionDetection-DBG"
"Rheelt/Materials-Temporal-Action-Detection" -> "Alvin-Zeng/PGCN"
"Rheelt/Materials-Temporal-Action-Detection" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"Rheelt/Materials-Temporal-Action-Detection" -> "Pilhyeon/BaSNet-pytorch"
"Rheelt/Materials-Temporal-Action-Detection" -> "JiaHeeeee/Deep_Learning_Temporal_Action_Detection"
"Rheelt/Materials-Temporal-Action-Detection" -> "piergiaj/tgm-icml19"
"Rheelt/Materials-Temporal-Action-Detection" -> "zhengshou/AutoLoc"
"Rheelt/Materials-Temporal-Action-Detection" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"Rheelt/Materials-Temporal-Action-Detection" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"Rheelt/Materials-Temporal-Action-Detection" -> "HYPJUDY/Decouple-SSAD"
"Rheelt/Materials-Temporal-Action-Detection" -> "bellos1203/STPN"
"Rheelt/Materials-Temporal-Action-Detection" -> "yjxiong/action-detection"
"2012013382/C3D-Tensorflow-slim" -> "hx173149/C3D-tensorflow"
"2012013382/C3D-Tensorflow-slim" -> "TianzhongSong/C3D-keras"
"antoine77340/LOUPE" -> "antoine77340/Youtube-8M-WILLOW"
"antoine77340/LOUPE" -> "wangheda/youtube-8m"
"antoine77340/LOUPE" -> "baidu/Youtube-8M"
"antoine77340/LOUPE" -> "linrongc/youtube-8m"
"antoine77340/LOUPE" -> "rohitgirdhar/ActionVLAD"
"antoine77340/LOUPE" -> "miha-skalic/youtube8mchallenge"
"antoine77340/LOUPE" -> "Relja/netvlad" ["e"=1]
"antoine77340/LOUPE" -> "antoine77340/Mixture-of-Embedding-Experts" ["e"=1]
"antoine77340/LOUPE" -> "google/youtube-8m"
"antoine77340/LOUPE" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"antoine77340/LOUPE" -> "sitzikbs/netVLAD" ["e"=1]
"jeffreyhuang1/two-stream-action-recognition" -> "bryanyzhu/two-stream-pytorch"
"jeffreyhuang1/two-stream-action-recognition" -> "feichtenhofer/twostreamfusion"
"jeffreyhuang1/two-stream-action-recognition" -> "qijiezhao/Video-Classification-Action-Recognition"
"jeffreyhuang1/two-stream-action-recognition" -> "feichtenhofer/gpu_flow"
"jeffreyhuang1/two-stream-action-recognition" -> "yjxiong/tsn-pytorch"
"jeffreyhuang1/two-stream-action-recognition" -> "yjxiong/temporal-segment-networks"
"jeffreyhuang1/two-stream-action-recognition" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"jeffreyhuang1/two-stream-action-recognition" -> "metalbubble/TRN-pytorch"
"jeffreyhuang1/two-stream-action-recognition" -> "bryanyzhu/Hidden-Two-Stream"
"jeffreyhuang1/two-stream-action-recognition" -> "rohitgirdhar/AttentionalPoolingAction"
"jeffreyhuang1/two-stream-action-recognition" -> "yjxiong/dense_flow"
"jeffreyhuang1/two-stream-action-recognition" -> "yjxiong/action-detection"
"jeffreyhuang1/two-stream-action-recognition" -> "hx173149/C3D-tensorflow"
"jeffreyhuang1/two-stream-action-recognition" -> "lmb-freiburg/flownet2-docker"
"jeffreyhuang1/two-stream-action-recognition" -> "qijiezhao/py-denseflow"
"wangheda/youtube-8m" -> "antoine77340/Youtube-8M-WILLOW"
"wangheda/youtube-8m" -> "baidu/Youtube-8M"
"wangheda/youtube-8m" -> "antoine77340/LOUPE"
"wangheda/youtube-8m" -> "miha-skalic/youtube8mchallenge"
"wangheda/youtube-8m" -> "miha-skalic/youtube8mchallange"
"wangheda/youtube-8m" -> "forwchen/yt8m"
"wangheda/youtube-8m" -> "linrongc/youtube-8m"
"wushidonguc/two-stream-action-recognition-keras" -> "mohammed-elkomy/two-stream-action-recognition"
"wushidonguc/two-stream-action-recognition-keras" -> "tomar840/two-stream-fusion-for-action-recognition-in-videos"
"wushidonguc/two-stream-action-recognition-keras" -> "XiaoCode-er/Two-Stream-CNN"
"wushidonguc/two-stream-action-recognition-keras" -> "Yorwxue/Two-Stream-Convolutional-Networks"
"wushidonguc/two-stream-action-recognition-keras" -> "jeffreyyihuang/two-stream-action-recognition"
"wushidonguc/two-stream-action-recognition-keras" -> "TianzhongSong/C3D-keras"
"huguyuehuhu/Awesome-Group-Activity-Recognition" -> "ruiyan1995/HiGCIN"
"imsoo/fight_detection" -> "sayibet/fight-detection-surv-dataset"
"imsoo/fight_detection" -> "meet-soni5720/Fight-Detection"
"imsoo/fight_detection" -> "imsoo/darknet_server"
"imsoo/fight_detection" -> "Shiv-Kumar-Yadav9/Event-Detection-In-Classroom"
"imsoo/fight_detection" -> "stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
"ruiyan1995/Group-Activity-Recognition" -> "ruiyan1995/HiGCIN"
"wjchaoGit/Group-Activity-Recognition" -> "mostafa-saad/deep-activity-rec"
"wjchaoGit/Group-Activity-Recognition" -> "huguyuehuhu/Awesome-Group-Activity-Recognition"
"wjchaoGit/Group-Activity-Recognition" -> "ruiyan1995/Group-Activity-Recognition"
"wjchaoGit/Group-Activity-Recognition" -> "mostafa-saad/hierarchical-relational-network"
"wjchaoGit/Group-Activity-Recognition" -> "cvlab-epfl/social-scene-understanding"
"wjchaoGit/Group-Activity-Recognition" -> "ruiyan1995/HiGCIN"
"wjchaoGit/Group-Activity-Recognition" -> "mahsaep/Social-human-activity-understanding-and-grouping"
"wjchaoGit/Group-Activity-Recognition" -> "Alvin-Zeng/PGCN"
"Pilhyeon/BaSNet-pytorch" -> "Pilhyeon/Background-Modeling-via-Uncertainty-Estimation"
"Pilhyeon/BaSNet-pytorch" -> "sujoyp/wtalc-pytorch"
"Pilhyeon/BaSNet-pytorch" -> "Finspire13/CMCS-Temporal-Action-Localization"
"Pilhyeon/BaSNet-pytorch" -> "bellos1203/STPN"
"Pilhyeon/BaSNet-pytorch" -> "Pilhyeon/Learning-Action-Completeness-from-Points"
"Pilhyeon/BaSNet-pytorch" -> "Pilhyeon/WTAL-Uncertainty-Modeling"
"Pilhyeon/BaSNet-pytorch" -> "bfshi/DGAM-Weakly-Supervised-Action-Localization"
"Pilhyeon/BaSNet-pytorch" -> "naraysa/3c-net"
"Pilhyeon/BaSNet-pytorch" -> "MichiganCOG/A2CL-PT"
"Pilhyeon/BaSNet-pytorch" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"Pilhyeon/BaSNet-pytorch" -> "asrafulashiq/wsad"
"Pilhyeon/BaSNet-pytorch" -> "Rheelt/Materials-Temporal-Action-Detection"
"Pilhyeon/BaSNet-pytorch" -> "zhengshou/AutoLoc"
"Pilhyeon/BaSNet-pytorch" -> "Alvin-Zeng/PGCN"
"Pilhyeon/BaSNet-pytorch" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"ranjaykrishna/SST" -> "shyamal-b/sst"
"ranjaykrishna/SST" -> "shyamal-b/ss-tad"
"ranjaykrishna/SST" -> "escorciav/daps"
"ranjaykrishna/SST" -> "JaywongWang/SST-Tensorflow"
"VisionLearningGroup/R-C3D" -> "yjxiong/action-detection"
"VisionLearningGroup/R-C3D" -> "sunnyxiaohu/R-C3D.pytorch"
"VisionLearningGroup/R-C3D" -> "shyamal-b/ss-tad"
"VisionLearningGroup/R-C3D" -> "wzmsltw/BSN-boundary-sensitive-network"
"VisionLearningGroup/R-C3D" -> "jiyanggao/CBR"
"VisionLearningGroup/R-C3D" -> "piergiaj/super-events-cvpr18"
"VisionLearningGroup/R-C3D" -> "shyamal-b/sst"
"VisionLearningGroup/R-C3D" -> "zhengshou/scnn"
"VisionLearningGroup/R-C3D" -> "ranjaykrishna/SST"
"VisionLearningGroup/R-C3D" -> "jiyanggao/TURN-TAP"
"VisionLearningGroup/R-C3D" -> "escorciav/daps"
"VisionLearningGroup/R-C3D" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"VisionLearningGroup/R-C3D" -> "ColumbiaDVMM/CDC"
"VisionLearningGroup/R-C3D" -> "wanglimin/UntrimmedNet"
"VisionLearningGroup/R-C3D" -> "jiyanggao/CTAP"
"SilvioGiancola/SoccerNetv2-DevKit" -> "SilvioGiancola/SoccerNet-code"
"SilvioGiancola/SoccerNetv2-DevKit" -> "baidu-research/vidpress-sports"
"SilvioGiancola/SoccerNetv2-DevKit" -> "SoccerNet/sn-tracking"
"SilvioGiancola/SoccerNetv2-DevKit" -> "SoccerNet/sn-spotting"
"SilvioGiancola/SoccerNetv2-DevKit" -> "SoccerNet/sn-calibration"
"SilvioGiancola/SoccerNetv2-DevKit" -> "cioppaanthony/context-aware-loss"
"SilvioGiancola/SoccerNetv2-DevKit" -> "vcg-uvic/sportsfield_release"
"SilvioGiancola/SoccerNetv2-DevKit" -> "DonsetPG/narya" ["e"=1]
"SilvioGiancola/SoccerNetv2-DevKit" -> "lood339/SCCvSD"
"kevin-ssy/Optical-Flow-Guided-Feature" -> "coderSkyChen/Action_Recognition_Zoo"
"kevin-ssy/Optical-Flow-Guided-Feature" -> "ZhaofanQiu/local-and-global-diffusion-networks"
"kevin-ssy/Optical-Flow-Guided-Feature" -> "MohsenFayyaz89/T3D"
"Pilhyeon/Background-Modeling-via-Uncertainty-Estimation" -> "Pilhyeon/BaSNet-pytorch"
"Pilhyeon/Background-Modeling-via-Uncertainty-Estimation" -> "asrafulashiq/wsad"
"Pilhyeon/Background-Modeling-via-Uncertainty-Estimation" -> "Pilhyeon/weakly-supervised-temporal-action-localization"
"Pilhyeon/Background-Modeling-via-Uncertainty-Estimation" -> "MichiganCOG/A2CL-PT"
"Pilhyeon/Background-Modeling-via-Uncertainty-Estimation" -> "Pilhyeon/Learning-Action-Completeness-from-Points"
"Pilhyeon/Background-Modeling-via-Uncertainty-Estimation" -> "Finspire13/CMCS-Temporal-Action-Localization"
"tomar840/two-stream-fusion-for-action-recognition-in-videos" -> "wushidonguc/two-stream-action-recognition-keras"
"tomar840/two-stream-fusion-for-action-recognition-in-videos" -> "mohammed-elkomy/two-stream-action-recognition"
"tomar840/two-stream-fusion-for-action-recognition-in-videos" -> "bryanyzhu/two-stream-pytorch"
"Alpha-Video/AlphaVideo" -> "BoPang1996/TubeTK" ["e"=1]
"Alpha-Video/AlphaVideo" -> "MVIG-SJTU/AlphAction"
"Alpha-Video/AlphaVideo" -> "DirtyHarryLYL/HAKE-Action"
"Alpha-Video/AlphaVideo" -> "DirtyHarryLYL/HAKE-Action-Torch"
"Alpha-Video/AlphaVideo" -> "BoPang1996/Semi-Coupled-Structure-for-visual-sequental-tasks"
"Alpha-Video/AlphaVideo" -> "DirtyHarryLYL/HAKE"
"ZFTurbo/classification_models_3D" -> "ZFTurbo/efficientnet_3D"
"ZFTurbo/classification_models_3D" -> "ZFTurbo/segmentation_models_3D"
"ZFTurbo/classification_models_3D" -> "ZFTurbo/volumentations"
"harishrithish7/Fall-Detection" -> "qiaoguan/Fall-detection"
"harishrithish7/Fall-Detection" -> "AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow"
"harishrithish7/Fall-Detection" -> "chizhanyuefeng/FD-CNN"
"artest08/LateTemporalModeling3DCNN" -> "arunos728/MotionSqueeze"
"artest08/LateTemporalModeling3DCNN" -> "zhang-can/PAN-PyTorch"
"artest08/LateTemporalModeling3DCNN" -> "V-Sense/ACTION-Net"
"artest08/LateTemporalModeling3DCNN" -> "swathikirans/GSM"
"artest08/LateTemporalModeling3DCNN" -> "xhl-video/SmallBigNet"
"taufeeque9/HumanFallDetection" -> "cwlroda/falldetection_openpifpaf"
"taufeeque9/HumanFallDetection" -> "JJN123/Fall-Detection"
"taufeeque9/HumanFallDetection" -> "GajuuzZ/Human-Falling-Detect-Tracks"
"taufeeque9/HumanFallDetection" -> "ambianic/fall-detection"
"taufeeque9/HumanFallDetection" -> "AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow"
"taufeeque9/HumanFallDetection" -> "chizhanyuefeng/Realtime-Fall-Detection-for-RNN"
"USTC-Video-Understanding/I3D_Finetune" -> "LossNAN/I3D-Tensorflow"
"USTC-Video-Understanding/I3D_Finetune" -> "Rhythmblue/i3d_finetune"
"USTC-Video-Understanding/I3D_Finetune" -> "yangwangx/denseFlow_gpu"
"USTC-Video-Understanding/I3D_Finetune" -> "qijiezhao/py-denseflow"
"USTC-Video-Understanding/I3D_Finetune" -> "dlpbc/keras-kinetics-i3d"
"USTC-Video-Understanding/I3D_Finetune" -> "yoosan/i3d-tensorflow"
"USTC-Video-Understanding/I3D_Finetune" -> "hassony2/kinetics_i3d_pytorch"
"USTC-Video-Understanding/I3D_Finetune" -> "deepmind/kinetics-i3d"
"USTC-Video-Understanding/I3D_Finetune" -> "feichtenhofer/gpu_flow"
"HYPJUDY/Decouple-SSAD" -> "Finspire13/CMCS-Temporal-Action-Localization"
"HYPJUDY/Decouple-SSAD" -> "jiyanggao/CTAP"
"HYPJUDY/Decouple-SSAD" -> "bellos1203/STPN"
"HYPJUDY/Decouple-SSAD" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"HYPJUDY/Decouple-SSAD" -> "Frostinassiky/gtad"
"HYPJUDY/Decouple-SSAD" -> "zhengshou/AutoLoc"
"HYPJUDY/Decouple-SSAD" -> "Rheelt/Materials-Temporal-Action-Detection"
"HYPJUDY/Decouple-SSAD" -> "Alvin-Zeng/PGCN"
"HYPJUDY/Decouple-SSAD" -> "JiaHeeeee/Deep_Learning_Temporal_Action_Detection"
"HYPJUDY/Decouple-SSAD" -> "Rheelt/SSAD_pytorch"
"HYPJUDY/Decouple-SSAD" -> "piergiaj/tgm-icml19"
"HYPJUDY/Decouple-SSAD" -> "sujoyp/wtalc-pytorch"
"HYPJUDY/Decouple-SSAD" -> "demianzhang/weakly-action-localization"
"HYPJUDY/Decouple-SSAD" -> "shyamal-b/ss-tad"
"HYPJUDY/Decouple-SSAD" -> "jiyanggao/CBR"
"Tencent/ActionDetection-DBG" -> "JJBOY/BMN-Boundary-Matching-Network"
"Tencent/ActionDetection-DBG" -> "Rheelt/Materials-Temporal-Action-Detection"
"Tencent/ActionDetection-DBG" -> "Alvin-Zeng/PGCN"
"Tencent/ActionDetection-DBG" -> "frostinassiky/gtad"
"Tencent/ActionDetection-DBG" -> "wzmsltw/BSN-boundary-sensitive-network"
"Tencent/ActionDetection-DBG" -> "Frostinassiky/gtad"
"Tencent/ActionDetection-DBG" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"Tencent/ActionDetection-DBG" -> "sujoyp/wtalc-pytorch"
"Tencent/ActionDetection-DBG" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"Tencent/ActionDetection-DBG" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"Tencent/ActionDetection-DBG" -> "yjxiong/action-detection"
"Tencent/ActionDetection-DBG" -> "HYPJUDY/Decouple-SSAD"
"Tencent/ActionDetection-DBG" -> "bfshi/DGAM-Weakly-Supervised-Action-Localization"
"Tencent/ActionDetection-DBG" -> "Pilhyeon/BaSNet-pytorch"
"Tencent/ActionDetection-DBG" -> "TencentYoutuResearch/ActionDetection-AFSD"
"dronefreak/human-action-classification" -> "smellslikeml/ActionAI"
"dronefreak/human-action-classification" -> "hafizas101/Real-time-human-pose-estimation-and-classification"
"dronefreak/human-action-classification" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"dronefreak/human-action-classification" -> "stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
"dronefreak/human-action-classification" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"dronefreak/human-action-classification" -> "dluvizon/deephar"
"DirtyHarryLYL/DJ-RN" -> "DirtyHarryLYL/SymNet"
"DirtyHarryLYL/DJ-RN" -> "DirtyHarryLYL/HAKE-Action"
"DirtyHarryLYL/DJ-RN" -> "DirtyHarryLYL/HAKE-Action-Torch"
"DirtyHarryLYL/DJ-RN" -> "scwangdyd/zero_shot_hoi"
"DirtyHarryLYL/DJ-RN" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"BigRedT/no_frills_hoi_det" -> "bobwan1995/PMFNet"
"BigRedT/no_frills_hoi_det" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"BigRedT/no_frills_hoi_det" -> "vt-vl-lab/DRG"
"BigRedT/no_frills_hoi_det" -> "chinancheng/awesome-human-object-interaction"
"BigRedT/no_frills_hoi_det" -> "s-gupta/v-coco"
"BigRedT/no_frills_hoi_det" -> "vt-vl-lab/iCAN"
"BigRedT/no_frills_hoi_det" -> "Dong-JinKim/ActionCooccurrencePriors"
"BigRedT/no_frills_hoi_det" -> "vaesl/IP-Net"
"tfzhou/C-HOI" -> "vaesl/IP-Net"
"tfzhou/C-HOI" -> "bobwan1995/PMFNet"
"tfzhou/C-HOI" -> "fredzzhang/spatio-attentive-graphs"
"tfzhou/C-HOI" -> "YueLiao/PPDM"
"tfzhou/C-HOI" -> "yoyomimi/AS-Net"
"shlizee/Predict-Cluster" -> "kchengiva/Shift-GCN"
"shlizee/Predict-Cluster" -> "microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition"
"shlizee/Predict-Cluster" -> "LinguoLi/CrosSCLR"
"shlizee/Predict-Cluster" -> "microsoft/SGN"
"shlizee/Predict-Cluster" -> "Mikexu007/AS-CAL"
"yfsong0709/RA-GCNv1" -> "kalpitthakkar/pb-gcn"
"yfsong0709/RA-GCNv1" -> "limaosen0/AS-GCN"
"wangxiang1230/OadTR" -> "amazon-research/long-short-term-transformer"
"wangxiang1230/OadTR" -> "xumingze0308/TRN.pytorch"
"wangxiang1230/SSTAP" -> "qinzhi-0110/Temporal-Context-Aggregation-Network-Pytorch"
"wangxiang1230/SSTAP" -> "zhang-can/UP-TAL"
"irhumshafkat/R2Plus1D-PyTorch" -> "RI-CH/SlowFastNetworks"
"irhumshafkat/R2Plus1D-PyTorch" -> "facebookresearch/R2Plus1D"
"irhumshafkat/R2Plus1D-PyTorch" -> "qijiezhao/s3d.pytorch"
"irhumshafkat/R2Plus1D-PyTorch" -> "alexandonian/pretorched-x"
"irhumshafkat/R2Plus1D-PyTorch" -> "zhujiagang/DTPP"
"irhumshafkat/R2Plus1D-PyTorch" -> "Guocode/SlowFast-Networks"
"wanglimin/dense_flow" -> "yjxiong/dense_flow"
"wanglimin/dense_flow" -> "feichtenhofer/gpu_flow"
"wanglimin/dense_flow" -> "wanglimin/TDD"
"wanglimin/dense_flow" -> "qijiezhao/py-denseflow"
"wanglimin/dense_flow" -> "yjxiong/caffe"
"wanglimin/dense_flow" -> "yangwangx/denseFlow_gpu"
"wanglimin/dense_flow" -> "feichtenhofer/twostreamfusion"
"wanglimin/dense_flow" -> "wadhwasahil/Video-Classification-2-Stream-CNN"
"wanglimin/dense_flow" -> "yjxiong/temporal-segment-networks"
"wanglimin/dense_flow" -> "wanglimin/improved_trajectory"
"wanglimin/dense_flow" -> "USTC-Video-Understanding/I3D_Finetune"
"wanglimin/dense_flow" -> "jeffreyhuang1/two-stream-action-recognition"
"wanglimin/dense_flow" -> "yjxiong/tsn-pytorch"
"wanglimin/dense_flow" -> "agethen/dense-flow"
"Viblast/dash-proxy" -> "elv-peter/dash-proxy"
"stephanj/basketballVideoAnalysis" -> "simonefrancia/SpaceJam"
"stephanj/basketballVideoAnalysis" -> "cemunds/awesome-sports-camera-calibration"
"stephanj/basketballVideoAnalysis" -> "vcg-uvic/sportsfield_release"
"stephanj/basketballVideoAnalysis" -> "browlm13/Basketball-Shot-Detection"
"stephanj/basketballVideoAnalysis" -> "chonyy/basketball-shot-detection"
"stephanj/basketballVideoAnalysis" -> "nihal111/hawk_eye"
"stephanj/basketballVideoAnalysis" -> "OwlTing/AI_basketball_games_video_editor"
"stephanj/basketballVideoAnalysis" -> "chonyy/AI-basketball-analysis"
"stephanj/basketballVideoAnalysis" -> "lulufa390/Pan-tilt-zoom-SLAM"
"stephanj/basketballVideoAnalysis" -> "gchlebus/tennis-court-detection"
"stephanj/basketballVideoAnalysis" -> "lood339/two_point_calib"
"stephanj/basketballVideoAnalysis" -> "danielazevedo/Football-Analytics"
"stephanj/basketballVideoAnalysis" -> "lood339/SCCvSD"
"stephanj/basketballVideoAnalysis" -> "Esedicol/BasketballPlayerDetectection-BABPD"
"gulvarol/ltc" -> "jrbtaylor/ActivityNet"
"hbilen/dynamic-image-nets" -> "kracwarlock/action-recognition-visual-attention"
"hbilen/dynamic-image-nets" -> "bryanyzhu/Hidden-Two-Stream"
"hbilen/dynamic-image-nets" -> "jrbtaylor/ActivityNet"
"hbilen/dynamic-image-nets" -> "feichtenhofer/st-resnet"
"hbilen/dynamic-image-nets" -> "yifita/action.sr_cnn"
"hbilen/dynamic-image-nets" -> "wanglimin/TDD"
"xumingze0308/TRN.pytorch" -> "amazon-research/long-short-term-transformer"
"xumingze0308/TRN.pytorch" -> "wangxiang1230/OadTR"
"xumingze0308/TRN.pytorch" -> "hjeun/idu"
"RedisGears/EdgeRealtimeVideoAnalytics" -> "RedisGears/AnimalRecognitionDemo"
"baidu/Youtube-8M" -> "wangheda/youtube-8m"
"baidu/Youtube-8M" -> "antoine77340/Youtube-8M-WILLOW"
"baidu/Youtube-8M" -> "forwchen/yt8m"
"baidu/Youtube-8M" -> "antoine77340/LOUPE"
"harvitronix/continuous-online-video-classification-blog" -> "harvitronix/five-video-classification-methods"
"harvitronix/continuous-online-video-classification-blog" -> "sagarvegad/Video-Classification-CNN-and-LSTM-"
"harvitronix/continuous-online-video-classification-blog" -> "chen0040/keras-video-classifier"
"kasakun/Fall-Detection" -> "mgei/fall-detection"
"kasakun/Fall-Detection" -> "xiaobin1231/Fall-Detection-By-YOLOV3-and-LiteFlowNet"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "TianzhongSong/Real-Time-Action-Recognition"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "imsoo/fight_detection"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "dluvizon/deephar"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "ortegatron/liveposetracker"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "dronefreak/human-action-classification"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "smellslikeml/ActionAI"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "InwoongLee/TS-LSTM"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "felixchenfy/Realtime-Action-Recognition"
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" -> "dakenan1/Realtime-Action-Recognition-Openpose"
"yjxiong/action-detection" -> "wzmsltw/BSN-boundary-sensitive-network"
"yjxiong/action-detection" -> "VisionLearningGroup/R-C3D"
"yjxiong/action-detection" -> "yjxiong/temporal-segment-networks"
"yjxiong/action-detection" -> "activitynet/ActivityNet"
"yjxiong/action-detection" -> "Rheelt/Materials-Temporal-Action-Detection"
"yjxiong/action-detection" -> "yjxiong/tsn-pytorch"
"yjxiong/action-detection" -> "JJBOY/BMN-Boundary-Matching-Network"
"yjxiong/action-detection" -> "Alvin-Zeng/PGCN"
"yjxiong/action-detection" -> "gurkirt/realtime-action-detection"
"yjxiong/action-detection" -> "metalbubble/TRN-pytorch"
"yjxiong/action-detection" -> "yjxiong/anet2016-cuhk"
"yjxiong/action-detection" -> "zhengshou/scnn"
"yjxiong/action-detection" -> "sunnyxiaohu/R-C3D.pytorch"
"yjxiong/action-detection" -> "wzmsltw/BSN-boundary-sensitive-network.pytorch"
"yjxiong/action-detection" -> "sujoyp/wtalc-pytorch"
"axon-research/c3d-keras" -> "TianzhongSong/C3D-keras"
"axon-research/c3d-keras" -> "hx173149/C3D-tensorflow"
"axon-research/c3d-keras" -> "dlpbc/keras-kinetics-i3d"
"axon-research/c3d-keras" -> "wushidonguc/two-stream-action-recognition-keras"
"axon-research/c3d-keras" -> "facebook/C3D"
"axon-research/c3d-keras" -> "imatge-upc/activitynet-2016-cvprw"
"axon-research/c3d-keras" -> "qijiezhao/pseudo-3d-pytorch"
"axon-research/c3d-keras" -> "DavideA/c3d-pytorch"
"axon-research/c3d-keras" -> "2012013382/C3D-Tensorflow-slim"
"bryanyzhu/Hidden-Two-Stream" -> "bryanyzhu/two-stream-pytorch"
"bryanyzhu/Hidden-Two-Stream" -> "bryanyzhu/GuidedNet"
"bryanyzhu/Hidden-Two-Stream" -> "rohitgirdhar/ActionVLAD"
"bryanyzhu/Hidden-Two-Stream" -> "jeffreyhuang1/two-stream-action-recognition"
"bryanyzhu/Hidden-Two-Stream" -> "feichtenhofer/st-resnet"
"bryanyzhu/Hidden-Two-Stream" -> "wanglimin/ARTNet"
"bryanyzhu/Hidden-Two-Stream" -> "hbilen/dynamic-image-nets"
"bryanyzhu/Hidden-Two-Stream" -> "wanglimin/UntrimmedNet"
"bryanyzhu/Hidden-Two-Stream" -> "feichtenhofer/gpu_flow"
"bryanyzhu/Hidden-Two-Stream" -> "gurkirt/realtime-action-detection"
"bryanyzhu/Hidden-Two-Stream" -> "qijiezhao/Video-Classification-Action-Recognition"
"bryanyzhu/Hidden-Two-Stream" -> "feichtenhofer/twostreamfusion"
"SiyuanQi/gpnn" -> "vt-vl-lab/iCAN"
"SiyuanQi/gpnn" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"SiyuanQi/gpnn" -> "bobwan1995/PMFNet"
"SiyuanQi/gpnn" -> "ywchao/ho-rcnn"
"SiyuanQi/gpnn" -> "chinancheng/awesome-human-object-interaction"
"SiyuanQi/gpnn" -> "s-gupta/v-coco"
"SiyuanQi/gpnn" -> "BigRedT/no_frills_hoi_det"
"SiyuanQi/gpnn" -> "YueLiao/PPDM"
"SiyuanQi/gpnn" -> "Prof-Lu-Cewu/Visual-Relationship-Detection" ["e"=1]
"SiyuanQi/gpnn" -> "wjchaoGit/Group-Activity-Recognition"
"YueLiao/CDN" -> "hitachi-rd-cv/qpic"
"YueLiao/CDN" -> "YueLiao/gen-vlkt"
"YueLiao/CDN" -> "cjw2021/QAHOI"
"YueLiao/CDN" -> "yoyomimi/AS-Net"
"YueLiao/CDN" -> "mrwu-mac/EoID"
"chinancheng/awesome-human-object-interaction" -> "vaesl/IP-Net"
"chinancheng/awesome-human-object-interaction" -> "SHI-Labs/Human-Object-Interaction-Detection"
"chinancheng/awesome-human-object-interaction" -> "BigRedT/no_frills_hoi_det"
"chinancheng/awesome-human-object-interaction" -> "yoyomimi/AS-Net"
"chinancheng/awesome-human-object-interaction" -> "vt-vl-lab/DRG"
"hitachi-rd-cv/qpic" -> "YueLiao/CDN"
"hitachi-rd-cv/qpic" -> "yoyomimi/AS-Net"
"hitachi-rd-cv/qpic" -> "fredzzhang/upt"
"hitachi-rd-cv/qpic" -> "cjw2021/QAHOI"
"hitachi-rd-cv/qpic" -> "bbepoch/HoiTransformer"
"hitachi-rd-cv/qpic" -> "fredzzhang/spatially-conditioned-graphs"
"hitachi-rd-cv/qpic" -> "kakaobrain/HOTR"
"hitachi-rd-cv/qpic" -> "YueLiao/gen-vlkt"
"hitachi-rd-cv/qpic" -> "YueLiao/PPDM"
"hitachi-rd-cv/qpic" -> "vt-vl-lab/DRG"
"hitachi-rd-cv/qpic" -> "zyong812/STIP"
"hitachi-rd-cv/qpic" -> "fredzzhang/hicodet"
"hitachi-rd-cv/qpic" -> "zhihou7/HOI-CL"
"hitachi-rd-cv/qpic" -> "DirtyHarryLYL/HOI-Learning-List"
"vt-vl-lab/DRG" -> "zhihou7/VCL"
"vt-vl-lab/DRG" -> "BigRedT/no_frills_hoi_det"
"vt-vl-lab/DRG" -> "vaesl/IP-Net"
"vt-vl-lab/DRG" -> "fredzzhang/spatio-attentive-graphs"
"YueLiao/PPDM" -> "vaesl/IP-Net"
"YueLiao/PPDM" -> "bobwan1995/PMFNet"
"YueLiao/PPDM" -> "hitachi-rd-cv/qpic"
"YueLiao/PPDM" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"YueLiao/PPDM" -> "DirtyHarryLYL/HOI-Learning-List"
"YueLiao/PPDM" -> "DirtyHarryLYL/HAKE"
"YueLiao/PPDM" -> "tfzhou/C-HOI"
"YueLiao/PPDM" -> "vt-vl-lab/iCAN"
"YueLiao/PPDM" -> "YueLiao/CDN"
"YueLiao/PPDM" -> "vt-vl-lab/DRG"
"YueLiao/PPDM" -> "yoyomimi/AS-Net"
"YueLiao/PPDM" -> "s-gupta/v-coco"
"YueLiao/PPDM" -> "cjw2021/QAHOI"
"YueLiao/PPDM" -> "fredzzhang/upt"
"YueLiao/PPDM" -> "kakaobrain/HOTR"
"yiskw713/asrf" -> "ChinaYi/asrf_with_asformer"
"yiskw713/asrf" -> "yiskw713/video_feature_extractor"
"yiskw713/asrf" -> "MCG-NJU/BCN"
"JiaHeeeee/Deep_Learning_Temporal_Action_Detection" -> "jiyanggao/CTAP"
"JiaHeeeee/Deep_Learning_Temporal_Action_Detection" -> "jiyanggao/CBR"
"JiaHeeeee/Deep_Learning_Temporal_Action_Detection" -> "demianzhang/weakly-action-localization"
"JiaHeeeee/Deep_Learning_Temporal_Action_Detection" -> "Rheelt/Materials-Temporal-Action-Detection"
"JiaHeeeee/Deep_Learning_Temporal_Action_Detection" -> "zhengshou/AutoLoc"
"PeisenZhao/Bottom-Up-TAL-with-MR" -> "MichiganCOG/A2CL-PT"
"PeisenZhao/Bottom-Up-TAL-with-MR" -> "VividLe/A2Net"
"SilvioGiancola/SoccerNet-code" -> "SilvioGiancola/SoccerNetv2-DevKit"
"SilvioGiancola/SoccerNet-code" -> "cioppaanthony/context-aware-loss"
"asrafulashiq/wsad" -> "zhengshou/AutoLoc"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "sujoyp/wtalc-pytorch"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "Finspire13/CMCS-Temporal-Action-Localization"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "Pilhyeon/BaSNet-pytorch"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "asrafulashiq/wsad"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "bellos1203/STPN"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "Flowerfan/SF-Net"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "Pilhyeon/Background-Modeling-via-Uncertainty-Estimation"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "MichiganCOG/A2CL-PT"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "naraysa/3c-net"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "Rheelt/Materials-Temporal-Action-Detection"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "HumamAlwassel/TSP"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "zhengshou/AutoLoc"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "Alvin-Zeng/PGCN"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "ispc-lab/ACM-Net"
"bfshi/DGAM-Weakly-Supervised-Action-Localization" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"chensun11/dtfv" -> "bo-yang/dtf_fisher"
"chensun11/dtfv" -> "anenbergb/CS221_Project"
"chensun11/dtfv" -> "HuNiuC/iDT-FV-for-action-recogniton"
"jiyanggao/CTAP" -> "jiyanggao/CBR"
"jiyanggao/CTAP" -> "demianzhang/weakly-action-localization"
"jiyanggao/CTAP" -> "jiyanggao/TURN-TAP"
"jiyanggao/CTAP" -> "HYPJUDY/Decouple-SSAD"
"jiyanggao/CTAP" -> "asrafulashiq/wsad"
"jiyanggao/TURN-TAP" -> "jiyanggao/CBR"
"jiyanggao/TURN-TAP" -> "jiyanggao/CTAP"
"jiyanggao/TURN-TAP" -> "escorciav/daps"
"jiyanggao/TURN-TAP" -> "shyamal-b/sst"
"jiyanggao/TURN-TAP" -> "vdavid70619/TCN"
"jiyanggao/TURN-TAP" -> "shyamal-b/ss-tad"
"yangwangx/denseFlow_gpu" -> "LossNAN/I3D-Tensorflow"
"zhengshou/scnn" -> "shyamal-b/sst"
"zhengshou/scnn" -> "ColumbiaDVMM/CDC"
"zhengshou/scnn" -> "jiyanggao/TURN-TAP"
"zhengshou/scnn" -> "yjxiong/action-detection"
"zhengshou/scnn" -> "jiyanggao/CBR"
"zhengshou/scnn" -> "VisionLearningGroup/R-C3D"
"zhengshou/scnn" -> "wanglimin/UntrimmedNet"
"zhengshou/scnn" -> "escorciav/daps"
"zhengshou/scnn" -> "yjxiong/anet2016-cuhk"
"zhengshou/scnn" -> "wzmsltw/BSN-boundary-sensitive-network"
"zhengshou/scnn" -> "jiyanggao/CTAP"
"zhengshou/scnn" -> "Rheelt/Materials-Temporal-Action-Detection"
"zhengshou/scnn" -> "syyeung/frameglimpses"
"zhengshou/scnn" -> "JaywongWang/SST-Tensorflow"
"zhengshou/scnn" -> "Finspire13/CMCS-Temporal-Action-Localization"
"sj-li/MS-TCN2" -> "yabufarha/ms-tcn"
"sj-li/MS-TCN2" -> "ChinaYi/ASFormer"
"sj-li/MS-TCN2" -> "yiskw713/asrf"
"sj-li/MS-TCN2" -> "ahsaniqbal/Kinetics-FeatureExtractor"
"sanfooh/camera-openpose-keras" -> "quanhua92/human-pose-estimation-opencv"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "microsoft/SGN"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "xiaoiker/GCN-NAS"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "kchengiva/Shift-GCN"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "yfsong0709/RA-GCNv1"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "adeboissiere/FUSION-human-action-recognition"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "limaosen0/AS-GCN"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "shlizee/Predict-Cluster"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "nkliuyifang/Skeleton-based-Human-Action-Recognition"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "lshiwjx/2s-AGCN"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "kenziyuliu/MS-G3D"
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" -> "niais/Awesome-Skeleton-based-Action-Recognition"
"LukasBommes/mv-extractor" -> "jishnujayakumar/MV-Tractus"
"facebookresearch/mae_st" -> "MCG-NJU/VideoMAE"
"bbepoch/HoiTransformer" -> "kakaobrain/HOTR"
"bbepoch/HoiTransformer" -> "hitachi-rd-cv/qpic"
"bbepoch/HoiTransformer" -> "cjw2021/QAHOI"
"bbepoch/HoiTransformer" -> "yoyomimi/AS-Net"
"bbepoch/HoiTransformer" -> "SHI-Labs/Human-Object-Interaction-Detection"
"bbepoch/HoiTransformer" -> "vaesl/IP-Net"
"bbepoch/HoiTransformer" -> "fredzzhang/upt"
"bbepoch/HoiTransformer" -> "zhihou7/HOI-CL"
"bbepoch/HoiTransformer" -> "YueLiao/CDN"
"bbepoch/HoiTransformer" -> "YueLiao/PPDM"
"bbepoch/HoiTransformer" -> "zhihou7/VCL"
"bbepoch/HoiTransformer" -> "vt-vl-lab/DRG"
"okankop/vidaug" -> "hassony2/torch_videovision"
"okankop/vidaug" -> "okankop/Efficient-3DCNNs"
"okankop/vidaug" -> "craston/MARS"
"okankop/vidaug" -> "TengdaHan/DPC" ["e"=1]
"okankop/vidaug" -> "piergiaj/pytorch-i3d"
"okankop/vidaug" -> "holistic-video-understanding/HVU-Dataset"
"okankop/vidaug" -> "IBM/action-recognition-pytorch"
"okankop/vidaug" -> "gsig/PyVideoResearch"
"okankop/vidaug" -> "facebookresearch/VMZ"
"okankop/vidaug" -> "jayChung0302/videomix"
"okankop/vidaug" -> "okankop/MFF-pytorch" ["e"=1]
"okankop/vidaug" -> "wei-tim/YOWO"
"okankop/vidaug" -> "decisionforce/TPN"
"okankop/vidaug" -> "moabitcoin/ig65m-pytorch"
"okankop/vidaug" -> "xiaobai1217/Awesome-Video-Datasets"
"wanglimin/UntrimmedNet" -> "zhengshou/AutoLoc"
"wanglimin/UntrimmedNet" -> "sujoyp/wtalc-pytorch"
"wanglimin/UntrimmedNet" -> "bellos1203/STPN"
"wanglimin/UntrimmedNet" -> "Finspire13/CMCS-Temporal-Action-Localization"
"wanglimin/UntrimmedNet" -> "wanglimin/ARTNet"
"wanglimin/UntrimmedNet" -> "demianzhang/weakly-action-localization"
"wanglimin/UntrimmedNet" -> "yjxiong/action-detection"
"wanglimin/UntrimmedNet" -> "yjxiong/anet2016-cuhk"
"wanglimin/UntrimmedNet" -> "ColumbiaDVMM/CDC"
"wanglimin/UntrimmedNet" -> "Rheelt/Materials-Temporal-Action-Detection"
"wanglimin/UntrimmedNet" -> "escorciav/daps"
"wanglimin/UntrimmedNet" -> "zhengshou/scnn"
"wanglimin/UntrimmedNet" -> "VisionLearningGroup/R-C3D"
"wanglimin/UntrimmedNet" -> "jiyanggao/CTAP"
"syyeung/frameglimpses" -> "shyamal-b/sst"
"syyeung/frameglimpses" -> "escorciav/daps"
"syyeung/frameglimpses" -> "jiyanggao/TURN-TAP"
"LossNAN/I3D-Tensorflow" -> "USTC-Video-Understanding/I3D_Finetune"
"LossNAN/I3D-Tensorflow" -> "yangwangx/denseFlow_gpu"
"LossNAN/I3D-Tensorflow" -> "dlpbc/keras-kinetics-i3d"
"LossNAN/I3D-Tensorflow" -> "qijiezhao/py-denseflow"
"JJN123/Fall-Detection" -> "AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow"
"JJN123/Fall-Detection" -> "taufeeque9/HumanFallDetection"
"JJN123/Fall-Detection" -> "chizhanyuefeng/FD-CNN"
"JJN123/Fall-Detection" -> "cwlroda/falldetection_openpifpaf"
"JJN123/Fall-Detection" -> "ivineetm007/Fall-detection"
"JJN123/Fall-Detection" -> "vietdzung/fall-detection-two-stream-cnn"
"JJN123/Fall-Detection" -> "qiaoguan/Fall-detection"
"JJN123/Fall-Detection" -> "ambianic/fall-detection"
"JJN123/Fall-Detection" -> "SeanChen0220/PoseFall"
"JJN123/Fall-Detection" -> "kasakun/Fall-Detection"
"SoccerNet/sn-calibration" -> "SoccerNet/sn-tracking"
"SoccerNet/sn-calibration" -> "baidu-research/vidpress-sports"
"MohsenFayyaz89/PyTorch_Video_Dataset" -> "MohsenFayyaz89/SCT"
"gurkirt/corrected-UCF101-Annots" -> "vkalogeiton/caffe"
"gurkirt/corrected-UCF101-Annots" -> "gurkirt/realtime-action-detection"
"gurkirt/corrected-UCF101-Annots" -> "imatge-upc/Action-Tubelet-Detection-in-AVA"
"chuckcho/video-caffe" -> "facebook/C3D"
"chuckcho/video-caffe" -> "ColumbiaDVMM/CDC"
"chuckcho/video-caffe" -> "wanglimin/TDD"
"chuckcho/video-caffe" -> "yjxiong/anet2016-cuhk"
"frostinassiky/gtad" -> "Alvin-Zeng/PGCN"
"frostinassiky/gtad" -> "JJBOY/BMN-Boundary-Matching-Network"
"frostinassiky/gtad" -> "HumamAlwassel/TSP"
"frostinassiky/gtad" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"frostinassiky/gtad" -> "TencentYoutuResearch/ActionDetection-AFSD"
"frostinassiky/gtad" -> "xlliu7/MUSES"
"frostinassiky/gtad" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"frostinassiky/gtad" -> "MCG-NJU/RTD-Action"
"frostinassiky/gtad" -> "Tencent/ActionDetection-DBG"
"frostinassiky/gtad" -> "Rheelt/Materials-Temporal-Action-Detection"
"frostinassiky/gtad" -> "xlliu7/TadTR"
"frostinassiky/gtad" -> "Alvin-Zeng/Awesome-Temporal-Action-Localization"
"yoyomimi/AS-Net" -> "cjw2021/QAHOI"
"yoyomimi/AS-Net" -> "hitachi-rd-cv/qpic"
"yoyomimi/AS-Net" -> "fredzzhang/spatio-attentive-graphs"
"yoyomimi/AS-Net" -> "zhihou7/HOI-CL"
"zhihou7/HOI-CL" -> "yoyomimi/AS-Net"
"zhihou7/HOI-CL" -> "cjw2021/QAHOI"
"swathikirans/violence-recognition-pytorch" -> "liorsidi/ViolenceDetection_CNNLSTM"
"swathikirans/violence-recognition-pytorch" -> "eazydammy/violence-detection-with-C3D"
"amazon-research/long-short-term-transformer" -> "wangxiang1230/OadTR"
"amazon-research/long-short-term-transformer" -> "xumingze0308/TRN.pytorch"
"chizhanyuefeng/Realtime-Fall-Detection-for-RNN" -> "chizhanyuefeng/FD-CNN"
"chizhanyuefeng/Realtime-Fall-Detection-for-RNN" -> "dmr5bq/computer-vision-final"
"KevinDuarte/VideoCapsuleNet" -> "jiaozizhao/Two-in-One-ActionDetection"
"KevinDuarte/VideoCapsuleNet" -> "KevinDuarte/CapsuleVOS" ["e"=1]
"chen0040/keras-video-classifier" -> "sagarvegad/Video-Classification-CNN-and-LSTM-"
"ywchao/ho-rcnn" -> "s-gupta/v-coco"
"ywchao/ho-rcnn" -> "vt-vl-lab/iCAN"
"ywchao/ho-rcnn" -> "bobwan1995/PMFNet"
"ywchao/ho-rcnn" -> "ywchao/hico_benchmark"
"ywchao/ho-rcnn" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"gsig/charades-algorithms" -> "gsig/temporal-fields"
"gsig/charades-algorithms" -> "gsig/actions-for-actions"
"gsig/charades-algorithms" -> "metalbubble/moments_models"
"gsig/charades-algorithms" -> "piergiaj/super-events-cvpr18"
"gsig/charades-algorithms" -> "noureldien/timeception"
"gsig/charades-algorithms" -> "rohitgirdhar/AttentionalPoolingAction"
"gsig/charades-algorithms" -> "hangzhaomit/HACS-dataset"
"gsig/charades-algorithms" -> "rohitgirdhar/ActionVLAD"
"gsig/temporal-fields" -> "gsig/actions-for-actions"
"gsig/temporal-fields" -> "gsig/charades-algorithms"
"Finspire13/pytorch-i3d-feature-extraction" -> "Finspire13/CMCS-Temporal-Action-Localization"
"Finspire13/pytorch-i3d-feature-extraction" -> "happyharrycn/actionformer_release"
"HumamAlwassel/TSP" -> "MCG-NJU/RTD-Action"
"HumamAlwassel/TSP" -> "frostinassiky/gtad"
"HumamAlwassel/TSP" -> "TencentYoutuResearch/ActionDetection-AFSD"
"HumamAlwassel/TSP" -> "zhang-can/UP-TAL"
"HumamAlwassel/TSP" -> "xlliu7/MUSES"
"HumamAlwassel/TSP" -> "happyharrycn/actionformer_release"
"HumamAlwassel/TSP" -> "qinzhi-0110/Temporal-Context-Aggregation-Network-Pytorch"
"HumamAlwassel/TSP" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"kakaobrain/HOTR" -> "bbepoch/HoiTransformer"
"kakaobrain/HOTR" -> "hitachi-rd-cv/qpic"
"kakaobrain/HOTR" -> "cjw2021/QAHOI"
"kakaobrain/HOTR" -> "SherlockHolmes221/GGNet"
"kakaobrain/HOTR" -> "fredzzhang/upt"
"kakaobrain/HOTR" -> "yoyomimi/AS-Net"
"kakaobrain/HOTR" -> "fredzzhang/spatially-conditioned-graphs"
"lood339/SCCvSD" -> "lood339/pytorch-two-GAN"
"lood339/SCCvSD" -> "lood339/two_point_calib"
"lood339/SCCvSD" -> "lulufa390/Pan-tilt-zoom-SLAM"
"lood339/SCCvSD" -> "cemunds/awesome-sports-camera-calibration"
"lood339/SCCvSD" -> "vcg-uvic/sportsfield_release"
"liorsidi/ViolenceDetection_CNNLSTM" -> "swathikirans/violence-recognition-pytorch"
"liorsidi/ViolenceDetection_CNNLSTM" -> "JoshuaPiinRueyPan/ViolenceDetection"
"liorsidi/ViolenceDetection_CNNLSTM" -> "manan858/Detecting-Violence"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "ispc-lab/ACM-Net"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "zhang-can/CoLA"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "Pilhyeon/WTAL-Uncertainty-Modeling"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "Pilhyeon/Learning-Action-Completeness-from-Points"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "LeonHLJ/RSKP"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "zhang-can/UP-TAL"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "Pilhyeon/BaSNet-pytorch"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "boheumd/ASM-Loc"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "LeonHLJ/FAC-Net"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "MengyuanChen21/CVPR2022-FTCL"
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" -> "Flowerfan/SF-Net"
"Zephyr-D/TCFPN-ISBA" -> "alexanderrichard/action-sets"
"Zephyr-D/TCFPN-ISBA" -> "alexanderrichard/NeuralNetwork-Viterbi"
"shyamal-b/ss-tad" -> "shyamal-b/sst"
"shyamal-b/ss-tad" -> "ranjaykrishna/SST"
"shyamal-b/ss-tad" -> "escorciav/daps"
"shyamal-b/ss-tad" -> "vdavid70619/TCN"
"shyamal-b/ss-tad" -> "JaywongWang/SST-Tensorflow"
"shyamal-b/ss-tad" -> "jiyanggao/CBR"
"shyamal-b/ss-tad" -> "jiyanggao/TURN-TAP"
"shyamal-b/ss-tad" -> "VisionLearningGroup/R-C3D"
"shyamal-b/ss-tad" -> "jiyanggao/CTAP"
"shyamal-b/ss-tad" -> "HYPJUDY/Decouple-SSAD"
"shyamal-b/ss-tad" -> "cabaf/sparseprop"
"shyamal-b/ss-tad" -> "ColumbiaDVMM/CDC"
"shyamal-b/sst" -> "ranjaykrishna/SST"
"shyamal-b/sst" -> "shyamal-b/ss-tad"
"shyamal-b/sst" -> "escorciav/daps"
"shyamal-b/sst" -> "JaywongWang/SST-Tensorflow"
"shyamal-b/sst" -> "jiyanggao/TURN-TAP"
"shyamal-b/sst" -> "jiyanggao/CBR"
"shyamal-b/sst" -> "vdavid70619/TCN"
"shyamal-b/sst" -> "jiyanggao/CTAP"
"shyamal-b/sst" -> "cabaf/sparseprop"
"shyamal-b/sst" -> "zhengshou/scnn"
"shyamal-b/sst" -> "syyeung/frameglimpses"
"mamonraab/Real-Time-Violence-Detection-in-Video-" -> "mamonraab/violance-detection-in-video-with-pytroch"
"mamonraab/Real-Time-Violence-Detection-in-Video-" -> "eazydammy/violence-detection-with-C3D"
"mamonraab/Real-Time-Violence-Detection-in-Video-" -> "hasnainnaeem/Violence-Detection-in-Videos"
"mamonraab/Real-Time-Violence-Detection-in-Video-" -> "TheAnkurGoswami/Human-Violence-Detection"
"mamonraab/Real-Time-Violence-Detection-in-Video-" -> "sukhitashvili/violence-detection"
"eazydammy/violence-detection-with-C3D" -> "TheAnkurGoswami/Human-Violence-Detection"
"AtomScott/SoccerTrack" -> "nanikamado/cotton"
"AtomScott/SoccerTrack" -> "samuro95/Self-Supervised-Small-Soccer-Player-Detection-Tracking"
"AtomScott/SoccerTrack" -> "SoccerNet/sn-tracking"
"SoccerNet/sn-tracking" -> "SoccerNet/sn-grounding"
"SoccerNet/sn-tracking" -> "SoccerNet/sn-calibration"
"SoccerNet/sn-tracking" -> "SoccerNet/sn-spotting"
"DirtyHarryLYL/HAKE-Action" -> "DirtyHarryLYL/HAKE"
"DirtyHarryLYL/HAKE-Action" -> "DirtyHarryLYL/DJ-RN"
"DirtyHarryLYL/HAKE-Action" -> "DirtyHarryLYL/SymNet"
"DirtyHarryLYL/HAKE-Action" -> "DirtyHarryLYL/HAKE-Action-Torch"
"DirtyHarryLYL/HAKE-Action" -> "DirtyHarryLYL/Transferable-Interactiveness-Network"
"DirtyHarryLYL/HAKE-Action" -> "DirtyHarryLYL/HOI-Learning-List"
"DirtyHarryLYL/HAKE-Action" -> "bobwan1995/PMFNet"
"DirtyHarryLYL/HAKE-Action" -> "YueLiao/PPDM"
"DirtyHarryLYL/HAKE-Action" -> "chinancheng/awesome-human-object-interaction"
"zhengshou/AutoLoc" -> "sujoyp/wtalc-pytorch"
"zhengshou/AutoLoc" -> "Finspire13/CMCS-Temporal-Action-Localization"
"zhengshou/AutoLoc" -> "bellos1203/STPN"
"zhengshou/AutoLoc" -> "demianzhang/weakly-action-localization"
"zhengshou/AutoLoc" -> "asrafulashiq/wsad"
"zhengshou/AutoLoc" -> "naraysa/3c-net"
"zhengshou/AutoLoc" -> "wanglimin/UntrimmedNet"
"zhengshou/AutoLoc" -> "MichiganCOG/A2CL-PT"
"IDKiro/action-recognition" -> "bpeck81/CNN_RNN_Human_Action_Recognition"
"IDKiro/action-recognition" -> "siqinli/GestureRecognition-PyTorch"
"feichtenhofer/st-resnet" -> "wanglimin/ARTNet"
"feichtenhofer/st-resnet" -> "wanglimin/UntrimmedNet"
"feichtenhofer/st-resnet" -> "feichtenhofer/twostreamfusion"
"feichtenhofer/st-resnet" -> "bryanyzhu/Hidden-Two-Stream"
"feichtenhofer/st-resnet" -> "rohitgirdhar/ActionVLAD"
"feichtenhofer/st-resnet" -> "feichtenhofer/gpu_flow"
"feichtenhofer/st-resnet" -> "hbilen/dynamic-image-nets"
"feichtenhofer/st-resnet" -> "ZhaofanQiu/pseudo-3d-residual-networks"
"feichtenhofer/st-resnet" -> "chihyaoma/Activity-Recognition-with-CNN-and-RNN"
"feichtenhofer/st-resnet" -> "rohitgirdhar/AttentionalPoolingAction"
"wanglimin/TDD" -> "wanglimin/improved_trajectory"
"hassony2/torch_videovision" -> "hassony2/inflated_convnets_pytorch"
"hassony2/torch_videovision" -> "hassony2/kinetics_i3d_pytorch"
"hassony2/torch_videovision" -> "okankop/vidaug"
"hassony2/torch_videovision" -> "Tushar-N/pytorch-resnet3d"
"hassony2/torch_videovision" -> "gsig/PyVideoResearch"
"hassony2/torch_videovision" -> "coderSkyChen/Action_Recognition_Zoo"
"hassony2/torch_videovision" -> "vt-vl-lab/SDN"
"hassony2/torch_videovision" -> "dlpbc/keras-kinetics-i3d"
"hassony2/torch_videovision" -> "rimchang/kinetics-i3d-Pytorch"
"bellos1203/STPN" -> "sujoyp/wtalc-pytorch"
"bellos1203/STPN" -> "zhengshou/AutoLoc"
"bellos1203/STPN" -> "Finspire13/CMCS-Temporal-Action-Localization"
"bellos1203/STPN" -> "asrafulashiq/wsad"
"bellos1203/STPN" -> "demianzhang/weakly-action-localization"
"bellos1203/STPN" -> "Pilhyeon/BaSNet-pytorch"
"bellos1203/STPN" -> "naraysa/3c-net"
"bellos1203/STPN" -> "HYPJUDY/Decouple-SSAD"
"bellos1203/STPN" -> "jiyanggao/CTAP"
"bellos1203/STPN" -> "bfshi/DGAM-Weakly-Supervised-Action-Localization"
"demianzhang/weakly-action-localization" -> "dazhang-cv/S3D"
"demianzhang/weakly-action-localization" -> "zhengshou/AutoLoc"
"miha-skalic/youtube8mchallenge" -> "linrongc/youtube-8m"
"miha-skalic/youtube8mchallenge" -> "antoine77340/Youtube-8M-WILLOW"
"miha-skalic/youtube8mchallenge" -> "wangheda/youtube-8m"
"miha-skalic/youtube8mchallenge" -> "antoine77340/LOUPE"
"mamonraab/violance-detection-in-video-with-pytroch" -> "mamonraab/Real-Time-Violence-Detection-in-Video-"
"auduno/deepdraw" -> "yjxiong/temporal-segment-networks"
"auduno/deepdraw" -> "yjxiong/dense_flow"
"auduno/deepdraw" -> "kylemcdonald/deepdream"
"auduno/deepdraw" -> "yjxiong/caffe"
"auduno/deepdraw" -> "yjxiong/action-detection"
"auduno/deepdraw" -> "qijiezhao/pseudo-3d-pytorch"
"auduno/deepdraw" -> "yjxiong/anet2016-cuhk"
"auduno/deepdraw" -> "MohsenFayyaz89/T3D"
"auduno/deepdraw" -> "facebook/C3D"
"auduno/deepdraw" -> "wanglimin/UntrimmedNet"
"auduno/deepdraw" -> "rohitgirdhar/ActionVLAD"
"auduno/deepdraw" -> "feichtenhofer/twostreamfusion"
"auduno/deepdraw" -> "metalbubble/TRN-pytorch"
"auduno/deepdraw" -> "bryanyzhu/two-stream-pytorch"
"auduno/deepdraw" -> "yjxiong/tsn-pytorch"
"dlpbc/keras-kinetics-i3d" -> "OanaIgnat/i3d_keras"
"dlpbc/keras-kinetics-i3d" -> "USTC-Video-Understanding/I3D_Finetune"
"dlpbc/keras-kinetics-i3d" -> "qijiezhao/py-denseflow"
"dlpbc/keras-kinetics-i3d" -> "LossNAN/I3D-Tensorflow"
"dlpbc/keras-kinetics-i3d" -> "JihongJu/keras-resnet3d"
"dlpbc/keras-kinetics-i3d" -> "Rhythmblue/i3d_finetune"
"dlpbc/keras-kinetics-i3d" -> "yoosan/i3d-tensorflow"
"dlpbc/keras-kinetics-i3d" -> "axon-research/c3d-keras"
"dlpbc/keras-kinetics-i3d" -> "TianzhongSong/C3D-keras"
"dlpbc/keras-kinetics-i3d" -> "FrederikSchorr/sign-language" ["e"=1]
"wizyoung/Optical-Flow-GPU-Docker" -> "willprice/flowty"
"alexanderrichard/squirrel" -> "alexanderrichard/NeuralNetwork-Viterbi"
"escorciav/daps" -> "shyamal-b/sst"
"escorciav/daps" -> "shyamal-b/ss-tad"
"escorciav/daps" -> "JaywongWang/SST-Tensorflow"
"escorciav/daps" -> "jiyanggao/TURN-TAP"
"escorciav/daps" -> "escorciav/deep-action-proposals"
"escorciav/daps" -> "ranjaykrishna/SST"
"escorciav/daps" -> "syyeung/frameglimpses"
"Nmegha2601/activitygraph_transformer" -> "MCG-NJU/RTD-Action"
"Nmegha2601/activitygraph_transformer" -> "VividLe/A2Net"
"JunLi-Galios/CDFL" -> "alexanderrichard/action-sets"
"JunLi-Galios/CDFL" -> "alexanderrichard/NeuralNetwork-Viterbi"
"noboevbo/ehpi_action_recognition" -> "ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition"
"cvlab-epfl/social-scene-understanding" -> "ruiyan1995/Group-Activity-Recognition"
"cvlab-epfl/social-scene-understanding" -> "mostafa-saad/deep-activity-rec"
"cvlab-epfl/social-scene-understanding" -> "ruiyan1995/HiGCIN"
"yfsong0709/ResGCNv1" -> "yfsong0709/EfficientGCNv1"
"yfsong0709/ResGCNv1" -> "kchengiva/Shift-GCN"
"yfsong0709/ResGCNv1" -> "kchengiva/DecoupleGCN-DropGraph"
"yfsong0709/ResGCNv1" -> "microsoft/SGN"
"yfsong0709/ResGCNv1" -> "xiaoiker/GCN-NAS"
"yfsong0709/ResGCNv1" -> "kenziyuliu/MS-G3D"
"yfsong0709/ResGCNv1" -> "yfsong0709/RA-GCNv1"
"bomquote/transistor" -> "eabglobal/minik"
"SHI-Labs/Human-Object-Interaction-Detection" -> "trevorbergstrom/HOI-Toolkit"
"hassony2/inflated_convnets_pytorch" -> "hassony2/kinetics_i3d_pytorch"
"MohsenFayyaz89/SCT" -> "yassersouri/fandak"
"shuangshuangguo/skeleton-based-action-recognition-review" -> "InwoongLee/TS-LSTM"
"cmhungsteve/SSTDA" -> "MCG-NJU/BCN"
"cmhungsteve/SSTDA" -> "cmhungsteve/TA3N"
"cmhungsteve/SSTDA" -> "alexanderrichard/NeuralNetwork-Viterbi"
"cmhungsteve/SSTDA" -> "yabufarha/ms-tcn"
"cmhungsteve/SSTDA" -> "JunLi-Galios/CDFL"
"cmhungsteve/SSTDA" -> "ZheLi2020/TimestampActionSeg"
"lucidrains/STAM-pytorch" -> "Alibaba-MIIL/STAM"
"vcg-uvic/sportsfield_release" -> "cemunds/awesome-sports-camera-calibration"
"chonyy/basketball-shot-detection" -> "browlm13/Basketball-Shot-Detection"
"lulufa390/Pan-tilt-zoom-SLAM" -> "lood339/SCCvSD"
"harlanhong/MM2021-CO2-Net" -> "MengyuanChen21/ECCV2022-DELU"
"ispc-lab/ACM-Net" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"ispc-lab/ACM-Net" -> "boheumd/ASM-Loc"
"ispc-lab/ACM-Net" -> "harlanhong/MM2021-CO2-Net"
"ispc-lab/ACM-Net" -> "zhang-can/CoLA"
"asrafulashiq/hamnet" -> "MichiganCOG/A2CL-PT"
"MCG-NJU/BCN" -> "yiskw713/asrf"
"MCG-NJU/BCN" -> "cmhungsteve/SSTDA"
"MCG-NJU/BCN" -> "ZheLi2020/TimestampActionSeg"
"MCG-NJU/BCN" -> "cotton-ahn/HASR_iccv2021"
"jiyanggao/CBR" -> "jiyanggao/TURN-TAP"
"jiyanggao/CBR" -> "vdavid70619/TCN"
"jiyanggao/CBR" -> "jiyanggao/CTAP"
"jiyanggao/CBR" -> "shyamal-b/sst"
"jiyanggao/CBR" -> "JaywongWang/SST-Tensorflow"
"lood339/pytorch-two-GAN" -> "lood339/SCCvSD"
"YueLiao/gen-vlkt" -> "cjw2021/QAHOI"
"YueLiao/gen-vlkt" -> "YueLiao/CDN"
"YueLiao/gen-vlkt" -> "zyong812/STIP"
"YueLiao/gen-vlkt" -> "fredzzhang/upt"
"YueLiao/gen-vlkt" -> "mrwu-mac/EoID"
"ChinaYi/ASFormer" -> "ChinaYi/asrf_with_asformer"
"ChinaYi/ASFormer" -> "ttlmh/Bridge-Prompt"
"ChinaYi/ASFormer" -> "yiskw713/asrf"
"alexanderrichard/NeuralNetwork-Viterbi" -> "alexanderrichard/squirrel"
"alexanderrichard/NeuralNetwork-Viterbi" -> "Zephyr-D/TCFPN-ISBA"
"alexanderrichard/NeuralNetwork-Viterbi" -> "JunLi-Galios/CDFL"
"alexanderrichard/NeuralNetwork-Viterbi" -> "alexanderrichard/action-sets"
"cemunds/awesome-sports-camera-calibration" -> "vcg-uvic/sportsfield_release"
"cemunds/awesome-sports-camera-calibration" -> "lood339/SCCvSD"
"cemunds/awesome-sports-camera-calibration" -> "lulufa390/Pan-tilt-zoom-SLAM"
"MartinXM/LST" -> "ZhouYuxuanYX/Hypergraph-Transformer-for-Skeleton-based-Action-Recognition"
"simonefrancia/SpaceJam" -> "browlm13/Basketball-Shot-Detection"
"simonefrancia/SpaceJam" -> "stephanj/basketballVideoAnalysis"
"simonefrancia/SpaceJam" -> "chonyy/basketball-shot-detection"
"simonefrancia/SpaceJam" -> "hkair/Basketball-Action-Recognition"
"ZFTurbo/efficientnet_3D" -> "ZFTurbo/classification_models_3D"
"deepaktalwardt/badminton-pose-analysis" -> "Chang-Chia-Chi/TrackNet-Badminton-Tracking-tensorflow2"
"RomeroBarata/human_object_interaction" -> "GuangmingZhu/STIGPN"
"coldmanck/VidHOI" -> "ShuangLI59/weakly-supervised-human-object-detection-video"
"coldmanck/VidHOI" -> "RomeroBarata/human_object_interaction"
"coldmanck/VidHOI" -> "NingWang2049/STIGPN"
"wangzheallen/vsad" -> "wanglimin/MRCNN-Scene-Recognition"
"LinguoLi/CrosSCLR" -> "LanglandsLin/MS2L"
"vaesl/IP-Net" -> "bobwan1995/PMFNet"
"vaesl/IP-Net" -> "YueLiao/PPDM"
"vaesl/IP-Net" -> "tfzhou/C-HOI"
"vaesl/IP-Net" -> "SherlockHolmes221/GGNet"
"vaesl/IP-Net" -> "chinancheng/awesome-human-object-interaction"
"vaesl/IP-Net" -> "vt-vl-lab/DRG"
"vaesl/IP-Net" -> "fredzzhang/spatio-attentive-graphs"
"vaesl/IP-Net" -> "BigRedT/no_frills_hoi_det"
"xiaobin1231/Fall-Detection-By-YOLOV3-and-LiteFlowNet" -> "mgei/fall-detection"
"xiaobin1231/Fall-Detection-By-YOLOV3-and-LiteFlowNet" -> "kasakun/Fall-Detection"
"Chang-Chia-Chi/TrackNet-Badminton-Tracking-tensorflow2" -> "deepaktalwardt/badminton-pose-analysis"
"Chang-Chia-Chi/TrackNet-Badminton-Tracking-tensorflow2" -> "gchlebus/tennis-court-detection"
"Chang-Chia-Chi/TrackNet-Badminton-Tracking-tensorflow2" -> "weekenddeeplearning/TrackNet"
"KimManjin/RSA" -> "arunos728/SELFY"
"vdavid70619/TCN" -> "jiyanggao/CBR"
"browlm13/Basketball-Shot-Detection" -> "simonefrancia/SpaceJam"
"browlm13/Basketball-Shot-Detection" -> "chonyy/basketball-shot-detection"
"cjw2021/QAHOI" -> "fredzzhang/upt"
"cjw2021/QAHOI" -> "yoyomimi/AS-Net"
"cjw2021/QAHOI" -> "YueLiao/gen-vlkt"
"cjw2021/QAHOI" -> "zyong812/STIP"
"cjw2021/QAHOI" -> "enlighten0707/Body-Part-Map-for-Interactiveness"
"cjw2021/QAHOI" -> "hitachi-rd-cv/qpic"
"cjw2021/QAHOI" -> "ShuangLI59/weakly-supervised-human-object-detection-video"
"cjw2021/QAHOI" -> "SherlockHolmes221/GGNet"
"JacobYuan7/RLIP" -> "zyong812/STIP"
"JacobYuan7/RLIP" -> "enlighten0707/Body-Part-Map-for-Interactiveness"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "Pilhyeon/BaSNet-pytorch"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "Pilhyeon/WTAL-Uncertainty-Modeling"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "zhang-can/UP-TAL"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "LeonHLJ/FAC-Net"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "Pilhyeon/Background-Modeling-via-Uncertainty-Estimation"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "ispc-lab/ACM-Net"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "Flowerfan/SF-Net"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "zhang-can/CoLA"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "LeonHLJ/RSKP"
"Pilhyeon/Learning-Action-Completeness-from-Points" -> "harlanhong/MM2021-CO2-Net"
"JaywongWang/SST-Tensorflow" -> "shyamal-b/sst"
"JaywongWang/SST-Tensorflow" -> "escorciav/daps"
"JaywongWang/SST-Tensorflow" -> "jiyanggao/CBR"
"MengyuanChen21/CVPR2022-FTCL" -> "MengyuanChen21/ECCV2022-DELU"
"fredzzhang/spatially-conditioned-graphs" -> "cjw2021/QAHOI"
"fredzzhang/spatially-conditioned-graphs" -> "fredzzhang/hicodet"
"fredzzhang/spatially-conditioned-graphs" -> "hitachi-rd-cv/qpic"
"czhaneva/SkeleMixCLR" -> "Levigty/AimCLR-v2"
"leftthomas/R2Plus1D-C3D" -> "irhum/R2Plus1D-PyTorch"
"MaximeBataille/tennis_tracking" -> "avivcaspi/TennisProject"
"MichiganCOG/A2CL-PT" -> "asrafulashiq/hamnet"
"MichiganCOG/A2CL-PT" -> "naraysa/3c-net"
"MichiganCOG/A2CL-PT" -> "VividLe/A2Net"
"MichiganCOG/A2CL-PT" -> "asrafulashiq/wsad"
"MichiganCOG/A2CL-PT" -> "PeisenZhao/Bottom-Up-TAL-with-MR"
"gsig/actions-for-actions" -> "gsig/temporal-fields"
"gsig/actions-for-actions" -> "gsig/charades-algorithms"
"LeonHLJ/RSKP" -> "zhang-can/UP-TAL"
"LeonHLJ/RSKP" -> "boheumd/ASM-Loc"
"LeonHLJ/RSKP" -> "harlanhong/MM2021-CO2-Net"
"LeonHLJ/RSKP" -> "zhang-can/CoLA"
"boheumd/ASM-Loc" -> "LeonHLJ/RSKP"
"boheumd/ASM-Loc" -> "ispc-lab/ACM-Net"
"zhang-can/UP-TAL" -> "LeonHLJ/RSKP"
"rohitgirdhar/AttentionalPoolingAction" ["l"="32.478,34.805"]
"rohitgirdhar/ActionVLAD" ["l"="32.494,34.811"]
"jeffreyhuang1/two-stream-action-recognition" ["l"="32.521,34.832"]
"frankgu/3d-DenseNet" ["l"="32.556,34.772"]
"gsig/charades-algorithms" ["l"="32.441,34.809"]
"kracwarlock/action-recognition-visual-attention" ["l"="32.549,34.789"]
"gsig/actions-for-actions" ["l"="32.447,34.781"]
"gurkirt/realtime-action-detection" ["l"="32.435,34.885"]
"wanglimin/UntrimmedNet" ["l"="32.422,34.837"]
"qijiezhao/Video-Classification-Action-Recognition" ["l"="32.553,34.816"]
"feichtenhofer/st-resnet" ["l"="32.506,34.805"]
"metalbubble/moments_models" ["l"="32.467,34.835"]
"wanglimin/ARTNet" ["l"="32.474,34.828"]
"VisionLearningGroup/R-C3D" ["l"="32.433,34.828"]
"ZhaofanQiu/pseudo-3d-residual-networks" ["l"="32.49,34.835"]
"gsig/temporal-fields" ["l"="32.454,34.794"]
"yysijie/st-gcn" ["l"="32.685,34.9"]
"open-mmlab/mmskeleton" ["l"="32.709,34.908"]
"lshiwjx/2s-AGCN" ["l"="32.762,34.907"]
"shahroudy/NTURGB-D" ["l"="32.744,34.92"]
"jinwchoi/awesome-action-recognition" ["l"="32.602,34.912"]
"niais/Awesome-Skeleton-based-Action-Recognition" ["l"="32.752,34.894"]
"limaosen0/AS-GCN" ["l"="32.747,34.909"]
"yjxiong/temporal-segment-networks" ["l"="32.529,34.868"]
"kenziyuliu/MS-G3D" ["l"="32.76,34.922"]
"MVIG-SJTU/AlphaPose" ["l"="36.05,35.183"]
"open-mmlab/mmaction" ["l"="32.546,34.933"]
"kenshohara/3D-ResNets-PyTorch" ["l"="32.569,34.915"]
"leoxiaobin/deep-high-resolution-net.pytorch" ["l"="36.045,35.137"]
"XiaoCode-er/Skeleton-Based-Action-Recognition-Papers" ["l"="32.735,34.896"]
"yjxiong/tsn-pytorch" ["l"="32.513,34.88"]
"GajuuzZ/Human-Falling-Detect-Tracks" ["l"="32.794,34.875"]
"google-research/scenic" ["l"="32.503,35.062"]
"microsoft/GLIP" ["l"="31.754,34.849"]
"rishikksh20/ViViT-pytorch" ["l"="32.451,35.072"]
"SwinTransformer/Video-Swin-Transformer" ["l"="32.478,35.024"]
"MCG-NJU/VideoMAE" ["l"="32.446,35.041"]
"facebookresearch/TimeSformer" ["l"="32.487,35.041"]
"mlfoundations/open_clip" ["l"="31.811,34.814"]
"open-mmlab/mmaction2" ["l"="32.566,34.986"]
"facebookresearch/Mask2Former" ["l"="34.733,35.856"]
"google/flax" ["l"="23.509,33.746"]
"google-research/vision_transformer" ["l"="34.476,35.866"]
"google-research/big_vision" ["l"="31.812,34.87"]
"facebookresearch/Detic" ["l"="31.772,34.878"]
"facebookresearch/SlowFast" ["l"="32.54,34.973"]
"facebookresearch/pytorchvideo" ["l"="32.522,35.021"]
"OFA-Sys/OFA" ["l"="31.744,34.759"]
"OpenGVLab/InternVideo" ["l"="32.324,35.016"]
"cvdfoundation/kinetics-dataset" ["l"="32.489,34.995"]
"Sense-X/UniFormer" ["l"="32.407,35.056"]
"facebookresearch/omnivore" ["l"="32.404,35.078"]
"sallymmx/ActionCLIP" ["l"="32.407,35.037"]
"MCG-NJU/TDN" ["l"="32.451,34.979"]
"facebookresearch/mae_st" ["l"="32.449,35.089"]
"happyharrycn/actionformer_release" ["l"="32.311,34.947"]
"facebookresearch/mae" ["l"="34.492,35.902"]
"microsoft/VideoX" ["l"="32.375,35.078"]
"OpenGVLab/UniFormerV2" ["l"="32.312,35.05"]
"OpenGVLab/unmasked_teacher" ["l"="32.269,35.058"]
"OpenGVLab/VideoMAEv2" ["l"="32.289,35.046"]
"ZFTurbo/volumentations" ["l"="32.719,35.052"]
"ZFTurbo/classification_models_3D" ["l"="32.7,35.033"]
"ZFTurbo/segmentation_models_3D" ["l"="32.723,35.037"]
"ZFTurbo/efficientnet_3D" ["l"="32.692,35.023"]
"MVIG-SJTU/AlphAction" ["l"="32.465,34.997"]
"Siyu-C/ACAR-Net" ["l"="32.399,34.957"]
"NVlabs/STEP" ["l"="32.406,34.933"]
"wei-tim/YOWO" ["l"="32.446,34.947"]
"MCG-NJU/MOC-Detector" ["l"="32.407,34.947"]
"Alpha-Video/AlphaVideo" ["l"="32.557,35.104"]
"facebookresearch/video-long-term-feature-banks" ["l"="32.445,34.913"]
"DirtyHarryLYL/HAKE-Action" ["l"="32.602,35.154"]
"decisionforce/TPN" ["l"="32.469,34.944"]
"DirtyHarryLYL/HAKE-Action-Torch" ["l"="32.609,35.173"]
"DirtyHarryLYL/HAKE" ["l"="32.616,35.164"]
"cvdfoundation/ava-dataset" ["l"="32.422,34.94"]
"oulutan/ACAM_Demo" ["l"="32.39,34.942"]
"frostinassiky/gtad" ["l"="32.348,34.922"]
"abhiTronix/vidgear" ["l"="32.479,35.189"]
"aminyazdanpanah/python-ffmpeg-video-streaming" ["l"="32.429,35.235"]
"kkroening/ffmpeg-python" ["l"="23.144,4.278"]
"jeffbass/imagezmq" ["l"="32.158,36.095"]
"videoflow/videoflow" ["l"="32.495,35.229"]
"aiortc/aiortc" ["l"="-28.585,12.041"]
"AdamSpannbauer/python_video_stab" ["l"="-13.428,27.813"]
"PyAV-Org/PyAV" ["l"="32.503,35.12"]
"NVIDIA/VideoProcessingFramework" ["l"="29.967,38.09"]
"Zulko/moviepy" ["l"="22.971,4.37"]
"Breakthrough/PySceneDetect" ["l"="32.557,35.047"]
"tryolabs/norfair" ["l"="34.609,35.665"]
"NVIDIA-AI-IOT/deepstream_python_apps" ["l"="29.934,38.075"]
"mifi/editly" ["l"="26.405,-19.364"]
"wmuron/motpy" ["l"="32.221,36.151"]
"sudheerachary/Mesh-Flow-Video-Stabilization" ["l"="-13.444,27.839"]
"RaivoKoot/Video-Dataset-Loading-Pytorch" ["l"="32.426,35.019"]
"YuxinZhaozyx/pytorch-VideoDataset" ["l"="32.371,35.053"]
"IBM/action-recognition-pytorch" ["l"="32.408,34.995"]
"hassony2/torch_videovision" ["l"="32.434,34.919"]
"open-mmlab/denseflow" ["l"="34.894,35.822"]
"xiaobai1217/Awesome-Video-Datasets" ["l"="32.447,35.007"]
"dmlc/decord" ["l"="32.51,35.002"]
"okankop/vidaug" ["l"="32.461,34.959"]
"mit-han-lab/temporal-shift-module" ["l"="32.519,34.943"]
"facebookresearch/detr" ["l"="34.415,35.715"]
"microsoft/Swin-Transformer" ["l"="34.463,35.776"]
"facebookresearch/moco" ["l"="34.484,35.975"]
"xingyizhou/CenterNet" ["l"="34.436,35.461"]
"facebookresearch/detectron2" ["l"="34.249,35.548"]
"facebookresearch/video-nonlocal-net" ["l"="32.537,34.905"]
"lucidrains/vit-pytorch" ["l"="34.403,35.805"]
"lucidrains/TimeSformer-pytorch" ["l"="32.453,35.024"]
"ArrowLuo/CLIP4Clip" ["l"="31.728,33.779"]
"jayleicn/ClipBERT" ["l"="31.654,34.705"]
"facebookresearch/Motionformer" ["l"="32.423,35.089"]
"piergiaj/representation-flow-cvpr19" ["l"="32.462,34.888"]
"craston/MARS" ["l"="32.483,34.941"]
"noureldien/timeception" ["l"="32.423,34.887"]
"chaoyuaw/pytorch-coviar" ["l"="32.47,34.872"]
"mzolfaghari/ECO-pytorch" ["l"="32.474,34.893"]
"cypw/PyTorch-MFNet" ["l"="32.451,34.87"]
"LijieFan/tvnet" ["l"="32.463,34.816"]
"coderSkyChen/Action_Recognition_Zoo" ["l"="32.486,34.849"]
"dukebw/lintel" ["l"="32.416,34.874"]
"r1ch88/SlowFastNetworks" ["l"="32.445,34.898"]
"irhum/R2Plus1D-PyTorch" ["l"="32.482,34.921"]
"qijiezhao/s3d.pytorch" ["l"="32.451,34.846"]
"facebookresearch/VMZ" ["l"="32.515,34.907"]
"wzmsltw/BSN-boundary-sensitive-network" ["l"="32.437,34.872"]
"ppriyank/Video-Action-Transformer-Network-Pytorch-" ["l"="32.285,35.008"]
"joaanna/something_else" ["l"="32.367,34.981"]
"InwoongLee/TS-LSTM" ["l"="32.724,34.874"]
"shuangshuangguo/skeleton-based-action-recognition-review" ["l"="32.751,34.875"]
"fandulu/Keras-for-Co-occurrence-Feature-Learning-from-Skeleton-Data-for-Action-Recognition" ["l"="32.703,34.86"]
"kinect59/Spatio-Temporal-LSTM" ["l"="32.708,34.928"]
"FesianXu/PLSTM" ["l"="32.722,34.861"]
"TaeSoo-Kim/TCNActionRecognition" ["l"="32.648,34.85"]
"yfsong0709/RA-GCNv1" ["l"="32.782,34.898"]
"huguyuehuhu/HCN-pytorch" ["l"="32.742,34.886"]
"XiaoCode-er/Two-Stream-CNN" ["l"="32.675,34.849"]
"Gasoonjia/tvnet_pytorch" ["l"="32.513,34.74"]
"bryanyzhu/two-stream-pytorch" ["l"="32.552,34.849"]
"zhengshou/scnn" ["l"="32.425,34.816"]
"yjxiong/action-detection" ["l"="32.458,34.86"]
"metalbubble/TRN-pytorch" ["l"="32.482,34.865"]
"hbilen/dynamic-image-nets" ["l"="32.521,34.765"]
"kevin-ssy/Optical-Flow-Guided-Feature" ["l"="32.435,34.794"]
"AlexHex7/Non-local_pytorch" ["l"="31.669,37.128"]
"deepmind/kinetics-i3d" ["l"="32.545,34.874"]
"activitynet/ActivityNet" ["l"="32.502,34.897"]
"xvjiarui/GCNet" ["l"="31.661,37.11"]
"piergiaj/pytorch-i3d" ["l"="32.495,34.91"]
"hassony2/kinetics_i3d_pytorch" ["l"="32.49,34.88"]
"msracver/Deformable-ConvNets" ["l"="34.396,35.26"]
"feichtenhofer/twostreamfusion" ["l"="32.554,34.837"]
"facebook/C3D" ["l"="32.521,34.817"]
"yjxiong/anet2016-cuhk" ["l"="32.457,34.827"]
"taufeeque9/HumanFallDetection" ["l"="32.839,34.853"]
"cwlroda/falldetection_openpifpaf" ["l"="32.859,34.855"]
"felixchenfy/Realtime-Action-Recognition" ["l"="32.742,34.856"]
"Amanbhandula/AlphaPose" ["l"="32.843,34.884"]
"kennymckormick/pyskl" ["l"="32.73,34.935"]
"LZQthePlane/Online-Realtime-Action-Recognition-based-on-OpenPose" ["l"="32.771,34.851"]
"xqZhang-Strong/Human-Falling-Detect-Tracks-master" ["l"="32.83,34.874"]
"Daniil-Osokin/lightweight-human-pose-estimation.pytorch" ["l"="36.041,35.104"]
"AdrianNunez/Fall-Detection-with-CNNs-and-Optical-Flow" ["l"="32.835,34.837"]
"BlackFeatherQQ/openpose_fall_detect" ["l"="32.877,34.88"]
"JJN123/Fall-Detection" ["l"="32.866,34.844"]
"HHTseng/video-classification" ["l"="32.601,34.866"]
"kenshohara/video-classification-3d-cnn-pytorch" ["l"="32.566,34.878"]
"jeffreyyihuang/two-stream-action-recognition" ["l"="32.592,34.855"]
"jfzhang95/pytorch-video-recognition" ["l"="32.544,34.89"]
"harvitronix/five-video-classification-methods" ["l"="32.582,34.833"]
"sagarvegad/Video-Classification-CNN-and-LSTM-" ["l"="32.612,34.808"]
"woodfrog/ActionRecognition" ["l"="32.606,34.837"]
"pranoyr/cnn-lstm" ["l"="32.657,34.816"]
"sujiongming/UCF-101_video_classification" ["l"="32.586,34.812"]
"okankop/Efficient-3DCNNs" ["l"="32.533,34.923"]
"eriklindernoren/Action-Recognition" ["l"="32.652,34.829"]
"chonyy/AI-basketball-analysis" ["l"="32.998,34.781"]
"chonyy/basketball-shot-detection" ["l"="33.064,34.765"]
"stephanj/basketballVideoAnalysis" ["l"="33.1,34.754"]
"simonefrancia/SpaceJam" ["l"="33.077,34.746"]
"browlm13/Basketball-Shot-Detection" ["l"="33.057,34.753"]
"chonyy/ML-auto-baseball-pitching-overlay" ["l"="33.049,34.793"]
"homerchen19/nba-go" ["l"="33.028,34.81"]
"dluvizon/deephar" ["l"="32.788,34.831"]
"neeilan/DeepPlayByPlay" ["l"="24.579,-27.948"]
"ry-werth/nba-automation" ["l"="33.01,34.756"]
"OwlTing/AI_basketball_games_video_editor" ["l"="33.047,34.767"]
"danchyy/Basketball_Analytics" ["l"="24.523,-27.959"]
"augmentedstartups/Pose-Estimation" ["l"="32.934,34.775"]
"Guanghan/lighttrack" ["l"="36.092,35.082"]
"facebookresearch/vissl" ["l"="34.44,35.967"]
"facebookresearch/deit" ["l"="34.543,35.888"]
"facebookresearch/dino" ["l"="34.483,35.939"]
"fredzzhang/upt" ["l"="32.635,35.234"]
"cjw2021/QAHOI" ["l"="32.647,35.235"]
"hitachi-rd-cv/qpic" ["l"="32.633,35.224"]
"YueLiao/gen-vlkt" ["l"="32.629,35.248"]
"fredzzhang/spatially-conditioned-graphs" ["l"="32.623,35.242"]
"zyong812/STIP" ["l"="32.645,35.259"]
"YueLiao/CDN" ["l"="32.643,35.246"]
"yoyomimi/AS-Net" ["l"="32.653,35.218"]
"zhihou7/HOI-CL" ["l"="32.663,35.23"]
"kakaobrain/HOTR" ["l"="32.657,35.242"]
"fredzzhang/hicodet" ["l"="32.614,35.229"]
"bbepoch/HoiTransformer" ["l"="32.651,35.227"]
"YueLiao/PPDM" ["l"="32.636,35.206"]
"vt-vl-lab/DRG" ["l"="32.644,35.201"]
"DavideA/c3d-pytorch" ["l"="32.507,34.864"]
"qijiezhao/pseudo-3d-pytorch" ["l"="32.515,34.856"]
"sunnyxiaohu/R-C3D.pytorch" ["l"="32.419,34.859"]
"Uason-Chen/CTR-GCN" ["l"="32.776,34.95"]
"Chiaraplizz/ST-TR" ["l"="32.764,34.938"]
"microsoft/SGN" ["l"="32.774,34.927"]
"kchengiva/Shift-GCN" ["l"="32.782,34.92"]
"stnoah1/infogcn" ["l"="32.786,34.972"]
"Jho-Yonsei/HD-GCN" ["l"="31.985,33.348"]
"xiaoiker/GCN-NAS" ["l"="32.794,34.924"]
"kenziyuliu/DGNN-PyTorch" ["l"="32.79,34.909"]
"microsoft/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition" ["l"="32.78,34.909"]
"cagbal/Skeleton-Based-Action-Recognition-Papers-and-Notes" ["l"="32.767,34.89"]
"open-mmlab/mmpose" ["l"="35.982,35.09"]
"open-mmlab/mmcv" ["l"="34.484,35.647"]
"PaddlePaddle/PaddleVideo" ["l"="-25.789,18.98"]
"microsoft/human-pose-estimation.pytorch" ["l"="36.05,35.12"]
"scivision/PyLivestream" ["l"="32.396,35.305"]
"317070/python-twitch-stream" ["l"="32.386,35.335"]
"torch2424/live-stream-radio" ["l"="32.37,35.361"]
"MD3XTER/Twitch-Farmer" ["l"="-4.674,-44.8"]
"jprjr/multistreamer" ["l"="-26.049,12.001"]
"Niek/obs-web" ["l"="-33.535,-16.511"]
"jprjr/docker-multistreamer" ["l"="-26.006,12.01"]
"Xingtao/FFdynamic" ["l"="-35.83,-17.469"]
"IDKiro/action-recognition" ["l"="32.679,34.795"]
"Keiku/Action-Recognition-CNN-LSTM" ["l"="32.684,34.817"]
"peachman05/action-recognition-tutorial" ["l"="32.693,34.809"]
"OValery16/Tutorial-about-3D-convolutional-network" ["l"="32.589,34.93"]
"kcct-fujimotolab/3DCNN" ["l"="32.573,34.859"]
"ms3001/DeepHandGestureRecognition" ["l"="35.979,34.474"]
"tomrunia/PyTorchConv3D" ["l"="32.465,34.91"]
"hx173149/C3D-tensorflow" ["l"="32.546,34.827"]
"chuckcho/video-caffe" ["l"="32.47,34.771"]
"yjxiong/caffe" ["l"="32.532,34.785"]
"wadhwasahil/Video-Classification-2-Stream-CNN" ["l"="32.553,34.806"]
"facebookresearch/R2Plus1D" ["l"="32.446,34.833"]
"irhumshafkat/R2Plus1D-PyTorch" ["l"="32.411,34.827"]
"hassony2/inflated_convnets_pytorch" ["l"="32.45,34.885"]
"shyamal-b/sst" ["l"="32.41,34.8"]
"starsdeep/R2Plus1D-MXNet" ["l"="32.399,34.822"]
"mzolfaghari/ECO-efficient-video-understanding" ["l"="32.469,34.851"]
"roytseng-tw/mask-rcnn.pytorch" ["l"="34.599,35.202"]
"ignacio-rocco/detectorch" ["l"="34.5,35.251"]
"MCG-NJU/MultiSports" ["l"="32.3,34.987"]
"MCG-NJU/SportsMOT" ["l"="32.251,35.001"]
"maxstrobel/HCN-PrototypeLoss-PyTorch" ["l"="32.747,34.942"]
"facebookarchive/C3D" ["l"="32.529,34.884"]
"WaqasSultani/AnomalyDetectionCVPR2018" ["l"="22.543,35.001"]
"TianzhongSong/C3D-keras" ["l"="32.59,34.801"]
"zhoubolei/TRN-pytorch" ["l"="32.457,34.936"]
"rajanjitenpatel/C3D_feature_extraction" ["l"="22.486,34.987"]
"xiadingZ/video-caption.pytorch" ["l"="31.809,33.932"]
"TianzhongSong/3D-ConvNets-for-Action-Recognition" ["l"="32.437,34.676"]
"gudongfeng/3d-DenseNet" ["l"="32.423,34.644"]
"bryanyzhu/Hidden-Two-Stream" ["l"="32.506,34.815"]
"yjxiong/dense_flow" ["l"="32.534,34.844"]
"feichtenhofer/gpu_flow" ["l"="32.533,34.835"]
"tomar840/two-stream-fusion-for-action-recognition-in-videos" ["l"="32.598,34.828"]
"wushidonguc/two-stream-action-recognition-keras" ["l"="32.627,34.822"]
"mohammed-elkomy/two-stream-action-recognition" ["l"="32.633,34.835"]
"TianzhongSong/Real-Time-Action-Recognition" ["l"="32.709,34.841"]
"MRzzm/action-recognition-models-pytorch" ["l"="32.519,34.893"]
"gsig/PyVideoResearch" ["l"="32.475,34.904"]
"arunos728/MotionSqueeze" ["l"="32.411,34.979"]
"Phoenix1327/tea-action-recognition" ["l"="32.422,34.976"]
"swathikirans/GSM" ["l"="32.435,34.968"]
"V-Sense/ACTION-Net" ["l"="32.438,34.979"]
"mengyuest/AR-Net" ["l"="31.14,33.791"]
"xhl-video/SmallBigNet" ["l"="32.403,34.972"]
"ortegatron/liveposetracker" ["l"="32.81,34.76"]
"hugozanini/openPoseTracking" ["l"="32.822,34.74"]
"zhuzhuxia1994/CK-TensorFlow" ["l"="32.623,34.76"]
"sujiongming/awesome-video-understanding" ["l"="32.636,34.738"]
"anenbergb/CS221_Project" ["l"="32.636,34.714"]
"imatge-upc/activitynet-2016-cvprw" ["l"="32.483,34.795"]
"chihyaoma/Activity-Recognition-with-CNN-and-RNN" ["l"="32.538,34.8"]
"wanglimin/dense_flow" ["l"="32.525,34.804"]
"qiaoguan/Fall-detection" ["l"="32.881,34.831"]
"chizhanyuefeng/FD-CNN" ["l"="32.882,34.817"]
"chizhanyuefeng/Realtime-Fall-Detection-for-RNN" ["l"="32.863,34.826"]
"harishrithish7/Fall-Detection" ["l"="32.866,34.811"]
"kasakun/Fall-Detection" ["l"="32.898,34.834"]
"vietdzung/fall-detection-two-stream-cnn" ["l"="32.886,34.844"]
"DirtyHarryLYL/DJ-RN" ["l"="32.632,35.162"]
"DirtyHarryLYL/HOI-Learning-List" ["l"="32.62,35.197"]
"DirtyHarryLYL/Transferable-Interactiveness-Network" ["l"="32.632,35.176"]
"vaesl/IP-Net" ["l"="32.655,35.201"]
"BigRedT/no_frills_hoi_det" ["l"="32.651,35.177"]
"chinancheng/awesome-human-object-interaction" ["l"="32.628,35.186"]
"DirtyHarryLYL/SymNet" ["l"="32.621,35.149"]
"s-gupta/v-coco" ["l"="32.637,35.193"]
"fredzzhang/spatio-attentive-graphs" ["l"="32.664,35.195"]
"bobwan1995/PMFNet" ["l"="32.657,35.185"]
"Chuhanxx/Temporal_Query_Networks" ["l"="32.347,35.024"]
"zhang-can/PAN-PyTorch" ["l"="32.422,34.991"]
"s9xie/Mini-Kinetics-200" ["l"="32.422,34.962"]
"kkahatapitiya/X3D-Multigrid" ["l"="32.358,35.036"]
"laura-wang/video-pace" ["l"="31.998,33.118"]
"liu-zhy/temporal-adaptive-module" ["l"="32.426,35.002"]
"MCG-NJU/CPD-Video" ["l"="32.387,35.026"]
"deepcs233/TIN" ["l"="32.398,34.986"]
"StanfordVL/RubiksNet" ["l"="32.38,34.996"]
"imageio/imageio-ffmpeg" ["l"="32.526,35.159"]
"imageio/imageio" ["l"="32.545,35.131"]
"vadimkantorov/mpegflow" ["l"="32.596,35.072"]
"abhiTronix/deffcode" ["l"="32.486,35.154"]
"Showmax/kinetics-downloader" ["l"="32.465,34.924"]
"piaxar/kinetics-downloader" ["l"="32.473,34.977"]
"dancelogue/kinetics-datasets-downloader" ["l"="32.471,34.967"]
"qijiezhao/py-denseflow" ["l"="32.489,34.826"]
"antoine77340/MIL-NCE_HowTo100M" ["l"="31.734,33.821"]
"haofanwang/video-swin-transformer-pytorch" ["l"="32.474,35.079"]
"Tushar-N/pytorch-resnet3d" ["l"="32.425,34.908"]
"seominseok0429/Real-world-Anomaly-Detection-in-Surveillance-Videos-pytorch" ["l"="22.513,35.015"]
"Roc-Ng/XDVioDet" ["l"="22.501,35.025"]
"GowthamGottimukkala/I3D_Feature_Extraction_resnet" ["l"="32.368,34.93"]
"tianyu0207/RTFM" ["l"="22.531,34.992"]
"feiyunzhang/i3d-non-local-pytorch" ["l"="32.422,34.927"]
"louisYen/S3R" ["l"="22.485,35.055"]
"jx-zhong-for-academic-purpose/GCN-Anomaly-Detection" ["l"="22.55,35.014"]
"fjchange/MIST_VAD" ["l"="22.538,35.023"]
"USTC-Video-Understanding/I3D_Finetune" ["l"="32.482,34.816"]
"tianyuan168326/EAN-Pytorch" ["l"="32.399,35.014"]
"artest08/LateTemporalModeling3DCNN" ["l"="32.437,34.992"]
"KimManjin/RSA" ["l"="32.359,35.013"]
"arunos728/SELFY" ["l"="32.367,35.001"]
"Andy1621/CT-Net" ["l"="32.351,35.001"]
"chenxuluo/GST-video" ["l"="32.396,35.001"]
"bomri/SlowFast" ["l"="32.427,35.135"]
"elb3k/vtn" ["l"="32.414,35.161"]
"facebookresearch/dmc-net" ["l"="32.425,34.803"]
"yoosan/video-understanding-dataset" ["l"="32.495,34.855"]
"Rheelt/Materials-Temporal-Action-Detection" ["l"="32.394,34.888"]
"Sense-X/X-Temporal" ["l"="21.86,27.396"]
"Alvin-Zeng/PGCN" ["l"="32.395,34.901"]
"NVIDIA/nvvl" ["l"="32.403,34.851"]
"airsplay/vimpac" ["l"="32.398,35.128"]
"fpv-iplab/rulstm" ["l"="35.712,35.647"]
"moabitcoin/ig65m-pytorch" ["l"="32.497,34.951"]
"axon-research/c3d-keras" ["l"="32.542,34.812"]
"2012013382/C3D-Tensorflow-slim" ["l"="32.576,34.793"]
"leftthomas/R2Plus1D-C3D" ["l"="32.482,34.955"]
"juenkhaw/action_recognition_project" ["l"="32.449,34.959"]
"gorjanradevski/revisiting-spatial-temporal-layouts" ["l"="32.324,34.998"]
"JingweiJ/ActionGenome" ["l"="31.341,34.476"]
"ju-chen/Efficient-Prompt" ["l"="32.342,35.048"]
"TengdaHan/TemporalAlignNet" ["l"="31.698,33.78"]
"OpenGVLab/efficient-video-recognition" ["l"="32.347,35.071"]
"sauradip/STALE" ["l"="32.317,35.078"]
"ttlmh/Bridge-Prompt" ["l"="32.309,34.974"]
"jayleicn/singularity" ["l"="31.683,33.753"]
"kylemin/S3D" ["l"="32.39,34.812"]
"antoine77340/S3D_HowTo100M" ["l"="31.747,33.814"]
"sjenni/temporal-ssl" ["l"="31.976,33.109"]
"MichiganCOG/TASED-Net" ["l"="32.085,33.273"]
"Alibaba-MIIL/STAM" ["l"="32.425,35.043"]
"davide-coccomini/TimeSformer-Video-Classification" ["l"="32.39,35.05"]
"lucidrains/STAM-pytorch" ["l"="32.43,35.068"]
"yitu-opensource/T2T-ViT" ["l"="34.636,35.913"]
"m-bain/frozen-in-time" ["l"="31.712,33.78"]
"mx-mark/VideoTransformer-pytorch" ["l"="32.451,35.107"]
"piergiaj/tgm-icml19" ["l"="32.382,34.857"]
"Alvin-Zeng/Awesome-Temporal-Action-Localization" ["l"="32.37,34.91"]
"Finspire13/CMCS-Temporal-Action-Localization" ["l"="32.371,34.87"]
"JiaHeeeee/Deep_Learning_Temporal_Action_Detection" ["l"="32.368,34.849"]
"JunLi-Galios/CDFL" ["l"="32.288,34.788"]
"demianzhang/weakly-action-localization" ["l"="32.356,34.84"]
"sujoyp/wtalc-pytorch" ["l"="32.366,34.874"]
"HYPJUDY/Decouple-SSAD" ["l"="32.371,34.859"]
"jiyanggao/CTAP" ["l"="32.386,34.837"]
"bellos1203/STPN" ["l"="32.358,34.854"]
"JJBOY/SlowFast-Network" ["l"="32.392,34.917"]
"Guocode/SlowFast-Networks" ["l"="32.376,34.837"]
"xuzheyuan624/slowfast-keras" ["l"="32.352,34.886"]
"ZhaofanQiu/local-and-global-diffusion-networks" ["l"="32.399,34.834"]
"drv-agwl/ViViT-pytorch" ["l"="32.43,35.114"]
"facebookresearch/AVT" ["l"="35.71,35.622"]
"wangxiang1230/OadTR" ["l"="32.374,35.154"]
"raoyongming/DenseCLIP" ["l"="31.722,34.855"]
"CryhanFang/CLIP2Video" ["l"="31.739,33.766"]
"HumamAlwassel/TSP" ["l"="32.323,34.934"]
"KaiyangZhou/CoOp" ["l"="31.718,34.817"]
"scikit-video/scikit-video" ["l"="32.573,35.01"]
"lidq92/VSFA" ["l"="35.21,32.291"]
"vztu/BVQA_Benchmark" ["l"="35.195,32.267"]
"phoenix104104/fast_blind_video_consistency" ["l"="35.225,30.727"]
"smellslikeml/ActionAI" ["l"="32.79,34.845"]
"dronefreak/human-action-classification" ["l"="32.8,34.817"]
"ChengeYang/Human-Pose-Estimation-Benchmarking-and-Action-Recognition" ["l"="32.77,34.827"]
"stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input" ["l"="32.782,34.807"]
"NVIDIA-AI-IOT/trt_pose" ["l"="29.885,38.047"]
"noboevbo/ehpi_action_recognition" ["l"="32.752,34.829"]
"NVIDIA-AI-IOT/deepstream_pose_estimation" ["l"="29.955,38.038"]
"IBM/bLVNet-TAM" ["l"="32.378,35.013"]
"LisaAnne/LocalizingMoments" ["l"="31.627,33.86"]
"antoine77340/Youtube-8M-WILLOW" ["l"="32.487,34.774"]
"microsoft/XPretrain" ["l"="31.712,33.756"]
"MikeWangWZHL/VidIL" ["l"="32.339,35.11"]
"muzairkhattak/ViFi-CLIP" ["l"="31.627,34.891"]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" ["l"="32.49,34.968"]
"antoine77340/video_feature_extractor" ["l"="31.77,33.837"]
"danieljf24/awesome-video-text-retrieval" ["l"="31.742,33.792"]
"krantiparida/awesome-audio-visual" ["l"="26.507,-20.667"]
"alexandonian/pretorched-x" ["l"="32.434,34.861"]
"pliang279/awesome-multimodal-ml" ["l"="31.618,34.721"]
"MichiganCOG/ViP" ["l"="32.083,33.3"]
"aminyazdanpanah/PHP-FFmpeg-video-streaming" ["l"="32.37,35.274"]
"krzemienski/awesome-video" ["l"="-26.105,11.98"]
"vincentbernat/video2hls" ["l"="32.382,35.246"]
"axiomatic-systems/Bento4" ["l"="-26.213,11.92"]
"escaped/django-video-encoding" ["l"="32.411,35.266"]
"kaltura/nginx-vod-module" ["l"="-26.169,11.909"]
"Viblast/dash-proxy" ["l"="32.429,35.283"]
"bbc/brave" ["l"="-35.832,-17.493"]
"globocom/m3u8" ["l"="-26.152,12.144"]
"just-work/django-video-transcoding" ["l"="32.407,35.247"]
"chen0040/keras-video-classifier" ["l"="32.644,34.781"]
"SBoyNumber1/LSTM-video-classification" ["l"="32.644,34.763"]
"harvitronix/continuous-online-video-classification-blog" ["l"="32.636,34.799"]
"vighneshvnkt/keras-deep-learning" ["l"="32.633,34.771"]
"talhasaruhan/video-action-classification" ["l"="32.657,34.787"]
"alxcnwy/Deep-Neural-Networks-for-Video-Classification" ["l"="32.661,34.767"]
"chris104957/maildown" ["l"="32.479,35.281"]
"perone/euclidesdb" ["l"="32.529,35.278"]
"RedisGears/EdgeRealtimeVideoAnalytics" ["l"="32.482,35.314"]
"bomquote/transistor" ["l"="32.521,35.306"]
"videoflow/videoflow-contrib" ["l"="32.497,35.251"]
"facebookresearch/pythia" ["l"="29.848,32.531"]
"codeforequity-at/botium-speech-processing" ["l"="-24.66,-20.602"]
"sail-sg/poolformer" ["l"="34.67,35.919"]
"xxxnell/how-do-vits-work" ["l"="34.589,35.985"]
"dingmyu/davit" ["l"="31.928,35.028"]
"SHI-Labs/Neighborhood-Attention-Transformer" ["l"="31.893,34.988"]
"NVlabs/FAN" ["l"="31.896,35.015"]
"czczup/ViT-Adapter" ["l"="31.793,34.954"]
"vt-vl-lab/iCAN" ["l"="32.644,35.183"]
"Fang-Haoshu/Halpe-FullBody" ["l"="35.895,35.014"]
"ASMIftekhar/VSGNet" ["l"="32.651,35.193"]
"scikit-image/scikit-image" ["l"="23.029,4.468"]
"pydata/numexpr" ["l"="21.698,28.738"]
"vispy/vispy" ["l"="-10.27,21.557"]
"letmaik/rawpy" ["l"="36.086,32.207"]
"h5py/h5py" ["l"="21.668,28.712"]
"napari/napari" ["l"="16.205,37.641"]
"maartenbreddels/ipyvolume" ["l"="21.33,28.879"]
"cgohlke/tifffile" ["l"="16.239,37.631"]
"hgrecco/pint" ["l"="21.557,34.626"]
"python-pillow/Pillow" ["l"="22.899,4.256"]
"colour-science/colour" ["l"="-12.046,27.417"]
"ambianic/fall-detection" ["l"="32.878,34.862"]
"uttej2001/Image-based-Human-Fall-Detection" ["l"="32.899,34.864"]
"zhuoxiangpang/ism_person_openpose" ["l"="32.909,34.882"]
"ivineetm007/Fall-detection" ["l"="32.89,34.855"]
"shyamal-b/ss-tad" ["l"="32.404,34.815"]
"wzmsltw/BSN-boundary-sensitive-network.pytorch" ["l"="32.391,34.868"]
"ranjaykrishna/SST" ["l"="32.415,34.789"]
"vkalogeiton/caffe" ["l"="32.41,34.907"]
"wanglimin/TDD" ["l"="32.505,34.757"]
"zbwglory/MV-release" ["l"="32.578,34.962"]
"yongqyu/st-gcn-pytorch" ["l"="32.849,34.946"]
"1zgh/st-gcn" ["l"="32.877,34.954"]
"kdkalvik/ST-GCN" ["l"="32.895,34.967"]
"XinzeWu/st-GCN" ["l"="32.873,34.968"]
"JJBOY/BMN-Boundary-Matching-Network" ["l"="32.38,34.89"]
"Tencent/ActionDetection-DBG" ["l"="32.366,34.894"]
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" ["l"="32.34,34.912"]
"Frostinassiky/gtad" ["l"="32.351,34.894"]
"Pilhyeon/BaSNet-pytorch" ["l"="32.332,34.882"]
"oulutan/ActorConditionedAttentionMaps" ["l"="32.339,34.956"]
"google/youtube-8m" ["l"="32.511,34.79"]
"wangheda/youtube-8m" ["l"="32.494,34.727"]
"antoine77340/LOUPE" ["l"="32.487,34.753"]
"linrongc/youtube-8m" ["l"="32.479,34.736"]
"miha-skalic/youtube8mchallenge" ["l"="32.498,34.74"]
"facebook/fb.resnet.torch" ["l"="34.268,35.084"]
"NoniDOTio/LiveStreamRadio" ["l"="32.351,35.381"]
"macedonga/lofi.twitch.auto.stream" ["l"="32.371,35.385"]
"OpenGVLab/Ask-Anything" ["l"="32.223,35.081"]
"ArtLabss/tennis-tracking" ["l"="33.171,34.683"]
"MaximeBataille/tennis_tracking" ["l"="33.2,34.657"]
"avivcaspi/TennisProject" ["l"="33.183,34.66"]
"vishaltiwari/bmvc-tennis-analytics" ["l"="33.164,34.659"]
"gchlebus/tennis-court-detection" ["l"="33.14,34.708"]
"ckjellson/tt_tracker" ["l"="33.15,34.689"]
"weekenddeeplearning/TrackNet" ["l"="33.167,34.699"]
"maudzung/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch" ["l"="33.154,34.717"]
"hampen2929/survey_on_tennis_tech" ["l"="33.199,34.675"]
"Chang-Chia-Chi/TrackNet-Badminton-Tracking-tensorflow2" ["l"="33.182,34.701"]
"TencentYoutuResearch/ActionDetection-DBG" ["l"="32.376,34.878"]
"mitmul/pynvvl" ["l"="32.32,34.825"]
"hangzhaomit/HACS-dataset" ["l"="32.4,34.875"]
"NVIDIA/DALI" ["l"="34.321,35.609"]
"cvondrick/soundnet" ["l"="26.484,-20.625"]
"jerryli27/TwinGAN" ["l"="34.141,30.233"]
"MohsenFayyaz89/PyTorch_Video_Dataset" ["l"="32.272,34.835"]
"ankurhanda/gvnn" ["l"="26.828,34.374"]
"colincsl/TemporalConvolutionalNetworks" ["l"="32.352,34.811"]
"yabufarha/ms-tcn" ["l"="32.296,34.814"]
"MCG-NJU/BCN" ["l"="32.271,34.795"]
"Zephyr-D/TCFPN-ISBA" ["l"="32.293,34.766"]
"Finspire13/pytorch-i3d-feature-extraction" ["l"="32.317,34.891"]
"ZheLi2020/TimestampActionSeg" ["l"="32.295,34.781"]
"vdavid70619/TCN" ["l"="32.371,34.796"]
"ahsaniqbal/Kinetics-FeatureExtractor" ["l"="32.289,34.803"]
"yiskw713/asrf" ["l"="32.273,34.82"]
"sj-li/MS-TCN2" ["l"="32.259,34.821"]
"cmhungsteve/SSTDA" ["l"="32.253,34.777"]
"alexanderrichard/action-sets" ["l"="32.275,34.775"]
"ChinaYi/ASFormer" ["l"="32.273,34.873"]
"piergiaj/AViD" ["l"="32.24,34.798"]
"piergiaj/super-events-cvpr18" ["l"="32.371,34.816"]
"microsoft/2D-TAN" ["l"="31.663,33.832"]
"kevinlin311tw/ava-dataset-tool" ["l"="32.37,34.944"]
"alainray/ava_downloader" ["l"="32.323,34.966"]
"leaderj1001/Action-Localization" ["l"="32.358,34.952"]
"baidu/Youtube-8M" ["l"="32.481,34.72"]
"miha-skalic/youtube8mchallange" ["l"="32.466,34.716"]
"jiyanggao/CBR" ["l"="32.384,34.821"]
"kchengiva/DecoupleGCN-DropGraph" ["l"="32.792,34.946"]
"lshiwjx/DSTA-Net" ["l"="32.802,34.964"]
"yfsong0709/ResGCNv1" ["l"="32.798,34.935"]
"wanglimin/MRCNN-Scene-Recognition" ["l"="32.558,34.707"]
"soeaver/caffe-model" ["l"="34.479,35.12"]
"sanghoon/pva-faster-rcnn" ["l"="34.496,35.079"]
"shicai/DenseNet-Caffe" ["l"="34.567,35.061"]
"craftGBD/craftGBD" ["l"="34.499,35.018"]
"LisaAnne/lisa-caffe-public" ["l"="32.544,34.762"]
"quanhua92/human-pose-estimation-opencv" ["l"="32.85,34.786"]
"sanfooh/camera-openpose-keras" ["l"="32.871,34.764"]
"YangZeyu95/unofficial-implement-of-openpose" ["l"="36.176,35.138"]
"ilovepose/DarkPose" ["l"="36.041,35.059"]
"wondonghyeon/protest-detection-violence-estimation" ["l"="32.928,34.573"]
"JoshuaPiinRueyPan/ViolenceDetection" ["l"="32.925,34.606"]
"swathikirans/violence-recognition-pytorch" ["l"="32.925,34.59"]
"wondonghyeon/face-classification" ["l"="34.693,33.265"]
"vmarquet/table-tennis-computer-vision" ["l"="33.188,34.722"]
"vcg-uvic/sportsfield_release" ["l"="33.166,34.746"]
"wangzheallen/vsad" ["l"="32.566,34.679"]
"wanglimin/Places205-VGGNet" ["l"="32.568,34.66"]
"yifita/action.sr_cnn" ["l"="32.542,34.718"]
"kalpitthakkar/pb-gcn" ["l"="32.821,34.902"]
"carloscaetano/skeleton-images" ["l"="32.849,34.916"]
"yyuanad/Pytorch_C3D_Feature_Extractor" ["l"="31.603,33.86"]
"rimchang/kinetics-i3d-Pytorch" ["l"="32.412,34.918"]
"escorciav/daps" ["l"="32.402,34.788"]
"syyeung/frameglimpses" ["l"="32.403,34.773"]
"jrbtaylor/ActivityNet" ["l"="32.509,34.715"]
"cabaf/sparseprop" ["l"="32.418,34.771"]
"JihongJu/keras-resnet3d" ["l"="32.466,34.741"]
"jibikbam/CNN-3D-images-Tensorflow" ["l"="35.498,34.281"]
"dipakkr/3d-cnn-action-recognition" ["l"="32.641,34.865"]
"dlpbc/keras-kinetics-i3d" ["l"="32.491,34.789"]
"bityangke/3DCNN" ["l"="32.621,34.854"]
"Ectsang/3D-CNN-Keras" ["l"="32.639,34.879"]
"imankgoyal/NonDeepNetworks" ["l"="32.313,35.124"]
"zimoqingfeng/UMOP" ["l"="32.284,35.143"]
"DingXiaoH/RepLKNet-pytorch" ["l"="31.864,35.039"]
"ildoonet/tf-pose-estimation" ["l"="36.09,35.183"]
"mostafa-saad/deep-activity-rec" ["l"="32.598,35.031"]
"cvlab-epfl/social-scene-understanding" ["l"="32.625,35.037"]
"wjchaoGit/Group-Activity-Recognition" ["l"="32.594,35.049"]
"mostafa-saad/hierarchical-relational-network" ["l"="32.635,35.054"]
"huguyuehuhu/Awesome-Group-Activity-Recognition" ["l"="32.618,35.06"]
"ruiyan1995/Group-Activity-Recognition" ["l"="32.624,35.048"]
"ruiyan1995/HiGCIN" ["l"="32.613,35.047"]
"gurkirt/corrected-UCF101-Annots" ["l"="32.442,34.933"]
"xingyizhou/pytorch-pose-hg-3d" ["l"="36.014,35.15"]
"garyzhao/SemGCN" ["l"="35.955,35.126"]
"JimmySuen/integral-human-pose" ["l"="36.006,35.132"]
"weigq/3d_pose_baseline_pytorch" ["l"="35.977,35.144"]
"DenisTome/Lifting-from-the-Deep-release" ["l"="36.026,35.19"]
"una-dinosauria/3d-pose-baseline" ["l"="35.979,35.165"]
"lmb-freiburg/flownet2-docker" ["l"="32.57,34.81"]
"lmb-freiburg/flownet2" ["l"="31.775,43.13"]
"xlliu7/E2E-TAD" ["l"="32.277,34.941"]
"xlliu7/TadTR" ["l"="32.292,34.939"]
"MCG-NJU/BasicTAD" ["l"="32.271,34.957"]
"TencentYoutuResearch/ActionDetection-AFSD" ["l"="32.313,34.917"]
"xlliu7/MUSES" ["l"="32.295,34.928"]
"klauscc/TALLFormer" ["l"="32.26,34.95"]
"zhang-can/UP-TAL" ["l"="32.275,34.912"]
"pantheon5100/3D-CNN-resnet-keras" ["l"="32.441,34.703"]
"JihongJu/lung-cancer-detector" ["l"="32.446,34.715"]
"shijianjian/EfficientNet-PyTorch-3D" ["l"="32.631,34.982"]
"hasnainnaeem/Violence-Detection-in-Videos" ["l"="32.946,34.606"]
"liorsidi/ViolenceDetection_CNNLSTM" ["l"="32.907,34.595"]
"mchengny/RWF2000-Video-Database-for-Violence-Detection" ["l"="32.933,34.623"]
"sayibet/fight-detection-surv-dataset" ["l"="32.903,34.646"]
"eazydammy/violence-detection-with-C3D" ["l"="32.944,34.595"]
"mamonraab/Real-Time-Violence-Detection-in-Video-" ["l"="32.961,34.589"]
"imsoo/fight_detection" ["l"="32.867,34.699"]
"liorsidi/violence-detection-deep-learning-cnnlstm" ["l"="32.977,34.618"]
"TheAnkurGoswami/Human-Violence-Detection" ["l"="32.961,34.605"]
"airtlab/A-Dataset-for-Automatic-Violence-Detection-in-Videos" ["l"="32.942,34.644"]
"zahid58/TwoStreamSepConvLSTM_ViolenceDetection" ["l"="32.96,34.62"]
"pedrofrodenas/Violence-Detection-CNN-LSTM" ["l"="32.968,34.634"]
"aitikgupta/violence_detection" ["l"="32.953,34.634"]
"Pilhyeon/WTAL-Uncertainty-Modeling" ["l"="32.285,34.882"]
"zhang-can/CoLA" ["l"="32.261,34.895"]
"Pilhyeon/Awesome-Weakly-Supervised-Temporal-Action-Localization" ["l"="32.285,34.899"]
"Pilhyeon/Learning-Action-Completeness-from-Points" ["l"="32.276,34.888"]
"ywchao/ho-rcnn" ["l"="32.669,35.177"]
"SiyuanQi/gpnn" ["l"="32.648,35.16"]
"SHI-Labs/Human-Object-Interaction-Detection" ["l"="32.618,35.216"]
"MVIG-SJTU/DIRV" ["l"="32.693,35.213"]
"zhengshou/AutoLoc" ["l"="32.358,34.862"]
"yfsong0709/EfficientGCNv1" ["l"="32.812,34.951"]
"EPFL-VILAB/MultiMAE" ["l"="34.705,36.031"]
"facebookresearch/long_seq_mae" ["l"="32.37,35.117"]
"showlab/EgoVLP" ["l"="31.645,33.711"]
"google-research/pix2seq" ["l"="31.796,34.881"]
"facebookresearch/LaViLa" ["l"="31.583,33.701"]
"jayleicn/moment_detr" ["l"="31.674,33.821"]
"Hrener/3D-Action-recognition" ["l"="32.776,34.936"]
"jpeyre/analogy" ["l"="32.697,35.194"]
"tfzhou/C-HOI" ["l"="32.671,35.204"]
"gtoderici/sports-1m-dataset" ["l"="32.53,34.697"]
"TengdaHan/CoCLR" ["l"="31.977,33.093"]
"cg1177/DCAN" ["l"="32.231,34.966"]
"qinzhi-0110/Temporal-Context-Aggregation-Network-Pytorch" ["l"="32.277,34.931"]
"MCG-NJU/RTD-Action" ["l"="32.311,34.934"]
"dingfengshi/TriDet" ["l"="32.257,34.97"]
"MartinXM/LST" ["l"="32.815,34.979"]
"tailin1009/DualHead-Network" ["l"="32.798,34.979"]
"heleiqiu/STTFormer" ["l"="32.784,34.989"]
"Levigty/AimCLR" ["l"="32.811,34.998"]
"limaosen0/DMGNN" ["l"="35.974,35.308"]
"xintao222/PoseDetect" ["l"="32.941,34.887"]
"PeisenZhao/Bottom-Up-TAL-with-MR" ["l"="32.33,34.894"]
"FingerRec/real_time_video_action_recognition" ["l"="32.621,34.793"]
"kenziyuliu/Unofficial-DGNN-PyTorch" ["l"="32.841,34.962"]
"wizyoung/Optical-Flow-GPU-Docker" ["l"="32.426,34.743"]
"yangwangx/denseFlow_gpu" ["l"="32.475,34.787"]
"junyongyou/Attention-boosted-deep-networks-for-video-classification" ["l"="32.696,34.794"]
"oswaldoludwig/Human-Action-Recognition-with-Keras" ["l"="32.574,34.765"]
"fomorians/distracted-drivers-keras" ["l"="32.594,34.728"]
"dakenan1/Realtime-Action-Recognition-Openpose" ["l"="32.786,34.789"]
"ColumbiaDVMM/CDC" ["l"="32.399,34.805"]
"naraysa/3c-net" ["l"="32.346,34.86"]
"danbochman/Real-Time-Action-Recognition" ["l"="32.66,34.75"]
"RI-CH/SlowFastNetworks" ["l"="32.368,34.826"]
"hongsong-wang/RNN-for-skeletons" ["l"="32.704,34.871"]
"MIT-HAN-LAB/temporal-shift-module" ["l"="32.502,34.843"]
"pengxj/action-faster-rcnn" ["l"="32.339,34.844"]
"Feynman27/realtime-action-detection" ["l"="32.384,34.848"]
"jiaozizhao/Two-in-One-ActionDetection" ["l"="32.351,34.828"]
"hjjpku/Action_Detection_DQN" ["l"="32.336,34.805"]
"zhang-can/ECO-pytorch" ["l"="32.438,34.848"]
"Adopteruf/Action_Recognition_using_Visual_Attention" ["l"="32.594,34.762"]
"imatge-upc/Action-Tubelet-Detection-in-AVA" ["l"="32.388,34.928"]
"xiaolonw/TimeCycle" ["l"="32.497,34.927"]
"zlai0/CorrFlow" ["l"="31.938,33.155"]
"Liusifei/UVC" ["l"="31.957,33.168"]
"zlai0/MAST" ["l"="31.906,33.206"]
"facebookresearch/fair_self_supervision_benchmark" ["l"="34.494,36.139"]
"ajabri/videowalk" ["l"="31.932,33.177"]
"google/revisiting-self-supervised" ["l"="34.492,36.184"]
"TengdaHan/DPC" ["l"="31.978,33.125"]
"StrangerZhang/pyECO" ["l"="32.569,36.177"]
"jishnujayakumar/MV-Tractus" ["l"="32.624,35.094"]
"LukasBommes/mv-extractor" ["l"="32.644,35.1"]
"Flowerfan/SF-Net" ["l"="32.307,34.883"]
"asrafulashiq/hamnet" ["l"="32.289,34.861"]
"zhangyaoyuan/NextVLAD-Attention-Model" ["l"="32.469,34.686"]
"linrongc/solution_youtube8m_v3" ["l"="32.465,34.698"]
"lyakaap/NetVLAD-pytorch" ["l"="32.62,42.307"]
"meet-soni5720/Fight-Detection" ["l"="32.889,34.67"]
"AnyiRao/SceneSeg" ["l"="31.316,42.71"]
"soCzech/TransNetV2" ["l"="31.339,42.742"]
"CSAILVision/places365" ["l"="34.262,35.256"]
"yahoo/hecate" ["l"="31.372,42.779"]
"johmathe/shotdetect" ["l"="32.576,35.087"]
"movienet/movienet-tools" ["l"="31.295,42.718"]
"open-mmlab/mmediting" ["l"="35.928,32.332"]
"OpenGVLab/ego4d-eccv2022-solutions" ["l"="32.263,35.032"]
"klauscc/VindLU" ["l"="32.279,35.033"]
"adamcasson/c3d" ["l"="32.609,34.751"]
"rekon/T3D-keras" ["l"="32.612,34.771"]
"aimagelab/STAGE_action_detection" ["l"="32.371,34.957"]
"MCG-NJU/CRCNN-Action" ["l"="32.364,34.968"]
"LeonHLJ/RSKP" ["l"="32.259,34.905"]
"LeonHLJ/FAC-Net" ["l"="32.245,34.901"]
"cmhungsteve/TA3N" ["l"="32.202,34.751"]
"junyuGao/Zero-Shot-Action-Recognition-with-Two-Stream-GCN" ["l"="23.631,35.498"]
"jonmun/MM-SADA-code" ["l"="32.169,34.732"]
"aminyazdanpanah/shaka-php" ["l"="32.335,35.286"]
"pascalbaljetmedia/laravel-ffmpeg" ["l"="-26.399,-41.236"]
"protonemedia/laravel-ffmpeg" ["l"="-25.843,-40.296"]
"PHP-FFMpeg/PHP-FFMpeg" ["l"="-27.222,-42.974"]
"warren-bank/HLS-Proxy" ["l"="32.336,35.307"]
"MCG-NJU/MMN" ["l"="31.69,33.828"]
"MCG-NJU/FCOT" ["l"="32.56,36.291"]
"Nmegha2601/activitygraph_transformer" ["l"="32.288,34.916"]
"zhihou7/VCL" ["l"="32.673,35.217"]
"SmartPorridge/google-AVA-Dataset-downloader" ["l"="32.346,34.968"]
"cvlab-columbia/oops" ["l"="32.342,34.981"]
"asrafulashiq/wsad" ["l"="32.335,34.859"]
"MichiganCOG/A2CL-PT" ["l"="32.32,34.868"]
"bfshi/DGAM-Weakly-Supervised-Action-Localization" ["l"="32.339,34.875"]
"KimChwee/Fall-Detection-Py-Raspberry" ["l"="32.924,34.837"]
"mgei/fall-detection" ["l"="32.914,34.821"]
"lood339/two_point_calib" ["l"="33.142,34.773"]
"lood339/SCCvSD" ["l"="33.162,34.763"]
"MohsenFayyaz89/T3D" ["l"="32.438,34.772"]
"Pilhyeon/Background-Modeling-via-Uncertainty-Estimation" ["l"="32.308,34.868"]
"buxiangzhiren/ContextLoc" ["l"="32.259,34.925"]
"Soldelli/Awesome-Temporal-Language-Grounding-in-Videos" ["l"="31.619,33.804"]
"KevinDuarte/VideoCapsuleNet" ["l"="32.343,34.792"]
"jeffdonahue/caffe" ["l"="26.807,34.205"]
"junhyukoh/caffe-lstm" ["l"="26.876,34.145"]
"garythung/torch-lrcn" ["l"="32.582,34.703"]
"vsubhashini/caffe" ["l"="31.86,33.956"]
"WJMatthew/SisFallAnalysis" ["l"="32.913,34.799"]
"czhaneva/MST-GCN" ["l"="32.822,34.99"]
"czhaneva/SkeleMixCLR" ["l"="32.843,35.02"]
"JHang2020/HiCLR" ["l"="32.826,35.018"]
"nkliuyifang/Skeleton-based-Human-Action-Recognition" ["l"="32.808,34.895"]
"shlizee/Predict-Cluster" ["l"="32.821,34.925"]
"fabro66/Online-Skeleton-based-Action-Recognition" ["l"="35.927,35.019"]
"Relja/netvlad" ["l"="32.605,42.312"]
"antoine77340/Mixture-of-Embedding-Experts" ["l"="31.765,33.817"]
"sitzikbs/netVLAD" ["l"="32.652,42.311"]
"forwchen/yt8m" ["l"="32.487,34.695"]
"Yorwxue/Two-Stream-Convolutional-Networks" ["l"="32.677,34.778"]
"imsoo/darknet_server" ["l"="32.891,34.692"]
"Shiv-Kumar-Yadav9/Event-Detection-In-Classroom" ["l"="32.867,34.678"]
"mahsaep/Social-human-activity-understanding-and-grouping" ["l"="32.624,35.072"]
"JaywongWang/SST-Tensorflow" ["l"="32.387,34.79"]
"jiyanggao/TURN-TAP" ["l"="32.387,34.8"]
"SilvioGiancola/SoccerNetv2-DevKit" ["l"="33.233,34.756"]
"SilvioGiancola/SoccerNet-code" ["l"="33.253,34.771"]
"baidu-research/vidpress-sports" ["l"="33.249,34.741"]
"SoccerNet/sn-tracking" ["l"="33.285,34.749"]
"SoccerNet/sn-spotting" ["l"="33.267,34.757"]
"SoccerNet/sn-calibration" ["l"="33.266,34.743"]
"cioppaanthony/context-aware-loss" ["l"="33.237,34.777"]
"DonsetPG/narya" ["l"="-10.859,23.912"]
"Pilhyeon/weakly-supervised-temporal-action-localization" ["l"="32.265,34.857"]
"BoPang1996/TubeTK" ["l"="32.343,36.214"]
"BoPang1996/Semi-Coupled-Structure-for-visual-sequental-tasks" ["l"="32.578,35.119"]
"LossNAN/I3D-Tensorflow" ["l"="32.463,34.782"]
"Rhythmblue/i3d_finetune" ["l"="32.463,34.76"]
"yoosan/i3d-tensorflow" ["l"="32.45,34.76"]
"Rheelt/SSAD_pytorch" ["l"="32.321,34.843"]
"hafizas101/Real-time-human-pose-estimation-and-classification" ["l"="32.818,34.793"]
"scwangdyd/zero_shot_hoi" ["l"="32.676,35.154"]
"Dong-JinKim/ActionCooccurrencePriors" ["l"="32.695,35.175"]
"LinguoLi/CrosSCLR" ["l"="32.885,34.934"]
"Mikexu007/AS-CAL" ["l"="32.857,34.93"]
"amazon-research/long-short-term-transformer" ["l"="32.362,35.175"]
"xumingze0308/TRN.pytorch" ["l"="32.344,35.176"]
"wangxiang1230/SSTAP" ["l"="32.235,34.929"]
"zhujiagang/DTPP" ["l"="32.358,34.766"]
"wanglimin/improved_trajectory" ["l"="32.534,34.748"]
"agethen/dense-flow" ["l"="32.557,34.745"]
"elv-peter/dash-proxy" ["l"="32.431,35.307"]
"cemunds/awesome-sports-camera-calibration" ["l"="33.147,34.751"]
"nihal111/hawk_eye" ["l"="33.109,34.732"]
"lulufa390/Pan-tilt-zoom-SLAM" ["l"="33.136,34.762"]
"danielazevedo/Football-Analytics" ["l"="33.113,34.775"]
"Esedicol/BasketballPlayerDetectection-BABPD" ["l"="33.117,34.745"]
"gulvarol/ltc" ["l"="32.506,34.657"]
"hjeun/idu" ["l"="32.321,35.195"]
"RedisGears/AnimalRecognitionDemo" ["l"="32.479,35.342"]
"xiaobin1231/Fall-Detection-By-YOLOV3-and-LiteFlowNet" ["l"="32.932,34.826"]
"bryanyzhu/GuidedNet" ["l"="32.524,34.751"]
"Prof-Lu-Cewu/Visual-Relationship-Detection" ["l"="31.402,34.539"]
"mrwu-mac/EoID" ["l"="32.633,35.269"]
"ChinaYi/asrf_with_asformer" ["l"="32.252,34.844"]
"yiskw713/video_feature_extractor" ["l"="32.233,34.814"]
"VividLe/A2Net" ["l"="32.296,34.891"]
"ispc-lab/ACM-Net" ["l"="32.26,34.883"]
"chensun11/dtfv" ["l"="32.661,34.655"]
"bo-yang/dtf_fisher" ["l"="32.665,34.628"]
"HuNiuC/iDT-FV-for-action-recogniton" ["l"="32.679,34.636"]
"adeboissiere/FUSION-human-action-recognition" ["l"="32.833,34.913"]
"holistic-video-understanding/HVU-Dataset" ["l"="32.386,34.976"]
"jayChung0302/videomix" ["l"="32.412,34.967"]
"okankop/MFF-pytorch" ["l"="36.002,34.48"]
"SeanChen0220/PoseFall" ["l"="32.913,34.851"]
"MohsenFayyaz89/SCT" ["l"="32.209,34.825"]
"dmr5bq/computer-vision-final" ["l"="32.891,34.803"]
"KevinDuarte/CapsuleVOS" ["l"="31.821,33.231"]
"ywchao/hico_benchmark" ["l"="32.716,35.187"]
"SherlockHolmes221/GGNet" ["l"="32.677,35.236"]
"lood339/pytorch-two-GAN" ["l"="33.182,34.774"]
"manan858/Detecting-Violence" ["l"="32.895,34.574"]
"boheumd/ASM-Loc" ["l"="32.244,34.893"]
"MengyuanChen21/CVPR2022-FTCL" ["l"="32.221,34.899"]
"alexanderrichard/NeuralNetwork-Viterbi" ["l"="32.267,34.76"]
"mamonraab/violance-detection-in-video-with-pytroch" ["l"="32.984,34.577"]
"sukhitashvili/violence-detection" ["l"="32.97,34.565"]
"AtomScott/SoccerTrack" ["l"="33.332,34.742"]
"nanikamado/cotton" ["l"="33.357,34.73"]
"samuro95/Self-Supervised-Small-Soccer-Player-Detection-Tracking" ["l"="33.354,34.751"]
"SoccerNet/sn-grounding" ["l"="33.305,34.749"]
"bpeck81/CNN_RNN_Human_Action_Recognition" ["l"="32.705,34.773"]
"siqinli/GestureRecognition-PyTorch" ["l"="32.713,34.755"]
"vt-vl-lab/SDN" ["l"="32.347,34.944"]
"dazhang-cv/S3D" ["l"="32.316,34.808"]
"auduno/deepdraw" ["l"="32.502,34.829"]
"kylemcdonald/deepdream" ["l"="32.506,34.77"]
"OanaIgnat/i3d_keras" ["l"="32.446,34.732"]
"FrederikSchorr/sign-language" ["l"="31.181,32.335"]
"willprice/flowty" ["l"="32.406,34.714"]
"alexanderrichard/squirrel" ["l"="32.247,34.738"]
"escorciav/deep-action-proposals" ["l"="32.372,34.746"]
"eabglobal/minik" ["l"="32.532,35.341"]
"trevorbergstrom/HOI-Toolkit" ["l"="32.597,35.231"]
"yassersouri/fandak" ["l"="32.178,34.819"]
"harlanhong/MM2021-CO2-Net" ["l"="32.232,34.888"]
"MengyuanChen21/ECCV2022-DELU" ["l"="32.201,34.891"]
"cotton-ahn/HASR_iccv2021" ["l"="32.235,34.783"]
"ZhouYuxuanYX/Hypergraph-Transformer-for-Skeleton-based-Action-Recognition" ["l"="32.843,34.995"]
"hkair/Basketball-Action-Recognition" ["l"="33.08,34.726"]
"deepaktalwardt/badminton-pose-analysis" ["l"="33.208,34.697"]
"RomeroBarata/human_object_interaction" ["l"="32.716,35.34"]
"GuangmingZhu/STIGPN" ["l"="32.723,35.354"]
"coldmanck/VidHOI" ["l"="32.707,35.316"]
"ShuangLI59/weakly-supervised-human-object-detection-video" ["l"="32.683,35.281"]
"NingWang2049/STIGPN" ["l"="32.726,35.327"]
"LanglandsLin/MS2L" ["l"="32.914,34.941"]
"enlighten0707/Body-Part-Map-for-Interactiveness" ["l"="32.663,35.27"]
"JacobYuan7/RLIP" ["l"="32.657,35.287"]
"Levigty/AimCLR-v2" ["l"="32.862,35.033"]
}