digraph G {
"IoSR-Surrey/untwist" -> "interactiveaudiolab/nussl"
"GregorR/rnnoise-nu" -> "GregorR/rnnoise-models"
"GregorR/rnnoise-nu" -> "jagger2048/rnnoise-windows"
"Ryuk17/SpeechAlgorithms" -> "jzi040941/PercepNet"
"Ryuk17/SpeechAlgorithms" -> "funcwj/setk"
"Ryuk17/SpeechAlgorithms" -> "athena-team/athena-signal"
"Ryuk17/SpeechAlgorithms" -> "aliutkus/speechmetrics"
"Ryuk17/SpeechAlgorithms" -> "nanahou/Awesome-Speech-Enhancement"
"Ryuk17/SpeechAlgorithms" -> "Wenzhe-Liu/awesome-speech-enhancement"
"Ryuk17/SpeechAlgorithms" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"Ryuk17/SpeechAlgorithms" -> "microsoft/AEC-Challenge"
"Ryuk17/SpeechAlgorithms" -> "microsoft/DNS-Challenge"
"Ryuk17/SpeechAlgorithms" -> "breizhn/DTLN-aec"
"Ryuk17/SpeechAlgorithms" -> "huyanxin/DeepComplexCRN"
"Ryuk17/SpeechAlgorithms" -> "ewan-xu/pyaec"
"Ryuk17/SpeechAlgorithms" -> "anicolson/DeepXi"
"Ryuk17/SpeechAlgorithms" -> "breizhn/DTLN"
"Ryuk17/SpeechAlgorithms" -> "ZitengWang/MASP"
"busyyang/python_sound_open" -> "bastamon/sound_signal_process-matlab-"
"busyyang/python_sound_open" -> "Ryuk17/SpeechAlgorithms"
"busyyang/python_sound_open" -> "ewan-xu/pyaec"
"busyyang/python_sound_open" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"busyyang/python_sound_open" -> "Zhangtingyuxuan/AcousticFeatureExtraction"
"busyyang/python_sound_open" -> "anicolson/DeepXi"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "yongxuUSTC/sednn"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "jtkim-kaist/Speech-enhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "hyli666/DNN-SpeechEnhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "eesungkim/Speech_Enhancement_MMSE-STSA"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "yongxuUSTC/DNN-for-speech-enhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "santi-pdp/segan_pytorch"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "seanwood/gcc-nmf"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "anicolson/DeepXi"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "fgnt/nn-gev"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"facebookresearch/denoiser" -> "microsoft/DNS-Challenge"
"facebookresearch/denoiser" -> "breizhn/DTLN"
"facebookresearch/denoiser" -> "asteroid-team/asteroid"
"facebookresearch/denoiser" -> "nanahou/Awesome-Speech-Enhancement"
"facebookresearch/denoiser" -> "aliutkus/speechmetrics"
"facebookresearch/denoiser" -> "haoxiangsnr/FullSubNet"
"facebookresearch/denoiser" -> "facebookresearch/WavAugment" ["e"=1]
"facebookresearch/denoiser" -> "huyanxin/DeepComplexCRN"
"facebookresearch/denoiser" -> "Wenzhe-Liu/awesome-speech-enhancement"
"facebookresearch/denoiser" -> "anicolson/DeepXi"
"facebookresearch/denoiser" -> "jzi040941/PercepNet"
"facebookresearch/denoiser" -> "jik876/hifi-gan" ["e"=1]
"facebookresearch/denoiser" -> "facebookresearch/svoice"
"facebookresearch/denoiser" -> "snakers4/silero-vad" ["e"=1]
"facebookresearch/denoiser" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"haoxiangsnr/FullSubNet" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"haoxiangsnr/FullSubNet" -> "jzi040941/PercepNet"
"haoxiangsnr/FullSubNet" -> "huyanxin/DeepComplexCRN"
"haoxiangsnr/FullSubNet" -> "breizhn/DTLN"
"haoxiangsnr/FullSubNet" -> "microsoft/DNS-Challenge"
"haoxiangsnr/FullSubNet" -> "huyanxin/phasen"
"haoxiangsnr/FullSubNet" -> "Wenzhe-Liu/awesome-speech-enhancement"
"haoxiangsnr/FullSubNet" -> "nanahou/Awesome-Speech-Enhancement"
"haoxiangsnr/FullSubNet" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"haoxiangsnr/FullSubNet" -> "maggie0830/DCCRN"
"haoxiangsnr/FullSubNet" -> "echocatzh/MTFAA-Net"
"haoxiangsnr/FullSubNet" -> "microsoft/MS-SNSD"
"haoxiangsnr/FullSubNet" -> "Rikorose/DeepFilterNet"
"haoxiangsnr/FullSubNet" -> "aliutkus/speechmetrics"
"haoxiangsnr/FullSubNet" -> "microsoft/AEC-Challenge"
"jzi040941/PercepNet" -> "breizhn/DTLN-aec"
"jzi040941/PercepNet" -> "microsoft/AEC-Challenge"
"jzi040941/PercepNet" -> "huyanxin/DeepComplexCRN"
"jzi040941/PercepNet" -> "ewan-xu/pyaec"
"jzi040941/PercepNet" -> "breizhn/DTLN"
"jzi040941/PercepNet" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"jzi040941/PercepNet" -> "haoxiangsnr/FullSubNet"
"jzi040941/PercepNet" -> "echocatzh/MTFAA-Net"
"jzi040941/PercepNet" -> "nay0648/unified2021"
"jzi040941/PercepNet" -> "felixfuyihui/Uformer"
"jzi040941/PercepNet" -> "cookcodes/Percepnet-Keras"
"jzi040941/PercepNet" -> "huyanxin/phasen"
"jzi040941/PercepNet" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"jzi040941/PercepNet" -> "microsoft/DNS-Challenge"
"jzi040941/PercepNet" -> "fjiang9/NKF-AEC"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "linan2/TensorFlow-speech-enhancement"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "haoxiangsnr/Speech_Enhancement_Tools"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "boozyguo/ClearWave"
"ludlows/python-pesq" -> "mpariente/pystoi"
"ludlows/python-pesq" -> "vBaiCai/python-pesq"
"ludlows/python-pesq" -> "aliutkus/speechmetrics"
"ludlows/python-pesq" -> "schmiph2/pysepm"
"ludlows/python-pesq" -> "microsoft/DNS-Challenge"
"ludlows/python-pesq" -> "gabrielmittag/NISQA"
"ludlows/python-pesq" -> "DavidDiazGuerra/gpuRIR"
"ludlows/python-pesq" -> "huyanxin/phasen"
"ludlows/python-pesq" -> "microsoft/MS-SNSD"
"ludlows/python-pesq" -> "microsoft/AEC-Challenge"
"ludlows/python-pesq" -> "Wenzhe-Liu/awesome-speech-enhancement"
"ludlows/python-pesq" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"ludlows/python-pesq" -> "huyanxin/DeepComplexCRN"
"ludlows/python-pesq" -> "kaituoxu/Conv-TasNet"
"ludlows/python-pesq" -> "haoxiangsnr/FullSubNet"
"majianjia/nnom" -> "microsoft/MS-SNSD"
"majianjia/nnom" -> "ARM-software/ML-KWS-for-MCU" ["e"=1]
"majianjia/nnom" -> "xboot/libonnx" ["e"=1]
"majianjia/nnom" -> "jzi040941/PercepNet"
"majianjia/nnom" -> "athena-team/athena-signal"
"majianjia/nnom" -> "microsoft/DNS-Challenge"
"majianjia/nnom" -> "tensorflow/tflite-micro" ["e"=1]
"majianjia/nnom" -> "huyanxin/DeepComplexCRN"
"majianjia/nnom" -> "ai-techsystems/deepC" ["e"=1]
"majianjia/nnom" -> "Ryuk17/SpeechAlgorithms"
"majianjia/nnom" -> "ARM-software/ML-examples" ["e"=1]
"majianjia/nnom" -> "breizhn/DTLN"
"majianjia/nnom" -> "xiph/rnnoise"
"majianjia/nnom" -> "Wenzhe-Liu/awesome-speech-enhancement"
"majianjia/nnom" -> "microsoft/AEC-Challenge"
"microsoft/MS-SNSD" -> "microsoft/DNS-Challenge"
"microsoft/MS-SNSD" -> "huyanxin/DeepComplexCRN"
"microsoft/MS-SNSD" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"microsoft/MS-SNSD" -> "anicolson/DeepXi"
"microsoft/MS-SNSD" -> "jzi040941/PercepNet"
"microsoft/MS-SNSD" -> "microsoft/P.808"
"microsoft/MS-SNSD" -> "Wenzhe-Liu/awesome-speech-enhancement"
"microsoft/MS-SNSD" -> "haoxiangsnr/FullSubNet"
"microsoft/MS-SNSD" -> "aliutkus/speechmetrics"
"microsoft/MS-SNSD" -> "microsoft/AEC-Challenge"
"microsoft/MS-SNSD" -> "breizhn/DTLN"
"microsoft/MS-SNSD" -> "ludlows/python-pesq"
"microsoft/MS-SNSD" -> "nanahou/Awesome-Speech-Enhancement"
"microsoft/MS-SNSD" -> "schmiph2/pysepm"
"microsoft/MS-SNSD" -> "funcwj/setk"
"schmiph2/pysepm" -> "aliutkus/speechmetrics"
"schmiph2/pysepm" -> "vBaiCai/python-pesq"
"schmiph2/pysepm" -> "ludlows/python-pesq"
"schmiph2/pysepm" -> "mpariente/pystoi"
"schmiph2/pysepm" -> "mpariente/pytorch_stoi"
"schmiph2/pysepm" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"schmiph2/pysepm" -> "microsoft/DNS-Challenge"
"schmiph2/pysepm" -> "jzi040941/PercepNet"
"schmiph2/pysepm" -> "anicolson/DeepXi"
"schmiph2/pysepm" -> "haoxiangsnr/FullSubNet"
"schmiph2/pysepm" -> "Wenzhe-Liu/awesome-speech-enhancement"
"schmiph2/pysepm" -> "huyanxin/phasen"
"schmiph2/pysepm" -> "DavidDiazGuerra/gpuRIR"
"schmiph2/pysepm" -> "huyanxin/DeepComplexCRN"
"schmiph2/pysepm" -> "nanahou/Awesome-Speech-Enhancement"
"xiph/rnnoise" -> "microsoft/DNS-Challenge"
"xiph/rnnoise" -> "werman/noise-suppression-for-voice" ["e"=1]
"xiph/rnnoise" -> "santi-pdp/segan"
"xiph/rnnoise" -> "drethage/speech-denoising-wavenet"
"xiph/rnnoise" -> "athena-team/athena-signal"
"xiph/rnnoise" -> "cpuimage/rnnoise"
"xiph/rnnoise" -> "jzi040941/PercepNet"
"xiph/rnnoise" -> "breizhn/DTLN"
"xiph/rnnoise" -> "LCAV/pyroomacoustics"
"xiph/rnnoise" -> "mozilla/LPCNet" ["e"=1]
"xiph/rnnoise" -> "jtkim-kaist/VAD" ["e"=1]
"xiph/rnnoise" -> "facebookresearch/denoiser"
"xiph/rnnoise" -> "aliutkus/speechmetrics"
"xiph/rnnoise" -> "anicolson/DeepXi"
"xiph/rnnoise" -> "fgnt/nara_wpe"
"yongxuUSTC/sednn" -> "yongxuUSTC/DNN-for-speech-enhancement"
"yongxuUSTC/sednn" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"yongxuUSTC/sednn" -> "santi-pdp/segan"
"yongxuUSTC/sednn" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"yongxuUSTC/sednn" -> "santi-pdp/segan_pytorch"
"yongxuUSTC/sednn" -> "anicolson/DeepXi"
"yongxuUSTC/sednn" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"yongxuUSTC/sednn" -> "funcwj/setk"
"yongxuUSTC/sednn" -> "fgnt/pb_chime5"
"yongxuUSTC/sednn" -> "jtkim-kaist/Speech-enhancement"
"yongxuUSTC/sednn" -> "fgnt/nn-gev"
"yongxuUSTC/sednn" -> "drethage/speech-denoising-wavenet"
"yongxuUSTC/sednn" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"yongxuUSTC/sednn" -> "hyli666/DNN-SpeechEnhancement"
"yongxuUSTC/sednn" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"ChihebTrabelsi/deep_complex_networks" -> "wavefrontshaping/complexPyTorch"
"ChihebTrabelsi/deep_complex_networks" -> "litcoderr/ComplexCNN"
"ChihebTrabelsi/deep_complex_networks" -> "JesperDramsch/keras-complex"
"ChihebTrabelsi/deep_complex_networks" -> "MRSRL/complex-networks-release"
"ChihebTrabelsi/deep_complex_networks" -> "ivannz/cplxmodule"
"ChihebTrabelsi/deep_complex_networks" -> "huyanxin/DeepComplexCRN"
"ChihebTrabelsi/deep_complex_networks" -> "NEGU93/cvnn"
"ChihebTrabelsi/deep_complex_networks" -> "huyanxin/phasen"
"ChihebTrabelsi/deep_complex_networks" -> "kaituoxu/Conv-TasNet"
"ChihebTrabelsi/deep_complex_networks" -> "microsoft/DNS-Challenge"
"ChihebTrabelsi/deep_complex_networks" -> "DavidDiazGuerra/gpuRIR"
"ChihebTrabelsi/deep_complex_networks" -> "maggie0830/DCCRN"
"ChihebTrabelsi/deep_complex_networks" -> "naplab/Conv-TasNet"
"ChihebTrabelsi/deep_complex_networks" -> "zhongyuanzhao/dl_ofdm" ["e"=1]
"ChihebTrabelsi/deep_complex_networks" -> "mpariente/asteroid"
"fgnt/nara_wpe" -> "funcwj/setk"
"fgnt/nara_wpe" -> "helianvine/fdndlp"
"fgnt/nara_wpe" -> "kkumatani/distant_speech_recognition"
"fgnt/nara_wpe" -> "ehabets/RIR-Generator"
"fgnt/nara_wpe" -> "DavidDiazGuerra/gpuRIR"
"fgnt/nara_wpe" -> "fgnt/pb_bss"
"fgnt/nara_wpe" -> "fgnt/nn-gev"
"fgnt/nara_wpe" -> "aliutkus/speechmetrics"
"fgnt/nara_wpe" -> "anicolson/DeepXi"
"fgnt/nara_wpe" -> "fgnt/pb_chime5"
"fgnt/nara_wpe" -> "nttcslab-sp/dnn_wpe"
"fgnt/nara_wpe" -> "microsoft/DNS-Challenge"
"fgnt/nara_wpe" -> "LCAV/pyroomacoustics"
"fgnt/nara_wpe" -> "jzi040941/PercepNet"
"fgnt/nara_wpe" -> "athena-team/athena-signal"
"fgnt/pb_chime5" -> "fgnt/nn-gev"
"fgnt/pb_chime5" -> "funcwj/cgmm-mask-estimator"
"fgnt/pb_chime5" -> "fgnt/pb_bss"
"fgnt/pb_chime5" -> "funcwj/setk"
"fgnt/pb_chime5" -> "yluo42/TAC"
"mpariente/asteroid" -> "kaituoxu/Conv-TasNet"
"mpariente/asteroid" -> "microsoft/DNS-Challenge"
"mpariente/asteroid" -> "funcwj/setk"
"mpariente/asteroid" -> "fgnt/nara_wpe"
"mpariente/asteroid" -> "speechLabBcCuny/onssen"
"mpariente/asteroid" -> "yluo42/TAC"
"mpariente/asteroid" -> "anicolson/DeepXi"
"mpariente/asteroid" -> "naplab/Conv-TasNet"
"mpariente/asteroid" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"mpariente/asteroid" -> "DavidDiazGuerra/gpuRIR"
"mpariente/asteroid" -> "funcwj/conv-tasnet"
"mpariente/asteroid" -> "JorisCos/LibriMix"
"mpariente/asteroid" -> "huyanxin/phasen"
"mpariente/asteroid" -> "pchao6/LSTM_PIT_Speech_Separation"
"mpariente/asteroid" -> "ludlows/python-pesq"
"echocatzh/MTFAA-Net" -> "felixfuyihui/Uformer"
"echocatzh/MTFAA-Net" -> "Andong-Li-speech/EaBNet"
"fjiang9/NKF-AEC" -> "vkothapally/JAECBF"
"fjiang9/NKF-AEC" -> "yuguochencuc/SF-Net"
"fjiang9/NKF-AEC" -> "adobe-research/MetaAF"
"fjiang9/NKF-AEC" -> "echocatzh/MTFAA-Net"
"fjiang9/NKF-AEC" -> "vkothapally/Subband-Beamformer"
"fjiang9/NKF-AEC" -> "yluo42/FRA-RIR"
"google/lyra" -> "facebookresearch/encodec" ["e"=1]
"google/lyra" -> "xiph/rnnoise"
"google/lyra" -> "mozilla/LPCNet" ["e"=1]
"google/lyra" -> "microsoft/DNS-Challenge"
"google/lyra" -> "xiph/opus" ["e"=1]
"google/lyra" -> "jik876/hifi-gan" ["e"=1]
"google/lyra" -> "facebookresearch/denoiser"
"google/lyra" -> "kan-bayashi/ParallelWaveGAN" ["e"=1]
"google/lyra" -> "espnet/espnet" ["e"=1]
"google/lyra" -> "lucidrains/audiolm-pytorch" ["e"=1]
"google/lyra" -> "speechbrain/speechbrain" ["e"=1]
"google/lyra" -> "aliutkus/speechmetrics"
"google/lyra" -> "google/oboe" ["e"=1]
"google/lyra" -> "athena-team/athena-signal"
"google/lyra" -> "fatchord/WaveRNN" ["e"=1]
"f90/Wave-U-Net" -> "f90/Wave-U-Net-Pytorch"
"f90/Wave-U-Net" -> "kaituoxu/Conv-TasNet"
"f90/Wave-U-Net" -> "francesclluis/source-separation-wavenet"
"f90/Wave-U-Net" -> "andabi/music-source-separation"
"f90/Wave-U-Net" -> "santi-pdp/segan_pytorch"
"f90/Wave-U-Net" -> "sigsep/open-unmix-pytorch" ["e"=1]
"f90/Wave-U-Net" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"f90/Wave-U-Net" -> "MTG/DeepConvSep"
"f90/Wave-U-Net" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"f90/Wave-U-Net" -> "santi-pdp/segan"
"f90/Wave-U-Net" -> "craffel/mir_eval" ["e"=1]
"f90/Wave-U-Net" -> "seanwood/gcc-nmf"
"f90/Wave-U-Net" -> "anicolson/DeepXi"
"f90/Wave-U-Net" -> "aliutkus/speechmetrics"
"f90/Wave-U-Net" -> "pchao6/LSTM_PIT_Speech_Separation"
"facebookresearch/svoice" -> "facebookresearch/denoiser"
"facebookresearch/svoice" -> "kaituoxu/Conv-TasNet"
"facebookresearch/svoice" -> "JorisCos/LibriMix"
"facebookresearch/svoice" -> "aliutkus/speechmetrics"
"facebookresearch/svoice" -> "asteroid-team/asteroid"
"facebookresearch/svoice" -> "facebookresearch/WavAugment" ["e"=1]
"facebookresearch/svoice" -> "haoxiangsnr/FullSubNet"
"facebookresearch/svoice" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"facebookresearch/svoice" -> "mindslab-ai/voicefilter"
"facebookresearch/svoice" -> "yluo42/TAC"
"facebookresearch/svoice" -> "JusperLee/Conv-TasNet"
"facebookresearch/svoice" -> "microsoft/DNS-Challenge"
"facebookresearch/svoice" -> "etzinis/sudo_rm_rf"
"facebookresearch/svoice" -> "gemengtju/Tutorial_Separation"
"facebookresearch/svoice" -> "speechbrain/speechbrain" ["e"=1]
"jim-schwoebel/voice_datasets" -> "nanahou/Awesome-Speech-Enhancement"
"jim-schwoebel/voice_datasets" -> "aliutkus/speechmetrics"
"jim-schwoebel/voice_datasets" -> "JRMeyer/open-speech-corpora" ["e"=1]
"jim-schwoebel/voice_datasets" -> "facebookresearch/WavAugment" ["e"=1]
"jim-schwoebel/voice_datasets" -> "microsoft/DNS-Challenge"
"jim-schwoebel/voice_datasets" -> "jik876/hifi-gan" ["e"=1]
"jim-schwoebel/voice_datasets" -> "facebookresearch/denoiser"
"jim-schwoebel/voice_datasets" -> "kan-bayashi/ParallelWaveGAN" ["e"=1]
"jim-schwoebel/voice_datasets" -> "s3prl/s3prl" ["e"=1]
"jim-schwoebel/voice_datasets" -> "speechbrain/speechbrain" ["e"=1]
"jim-schwoebel/voice_datasets" -> "iver56/audiomentations" ["e"=1]
"jim-schwoebel/voice_datasets" -> "auspicious3000/autovc" ["e"=1]
"jim-schwoebel/voice_datasets" -> "asteroid-team/torch-audiomentations" ["e"=1]
"jim-schwoebel/voice_datasets" -> "auspicious3000/SpeechSplit" ["e"=1]
"jim-schwoebel/voice_datasets" -> "microsoft/MS-SNSD"
"kuleshov/audio-super-res" -> "jhetherly/EnglishSpeechUpsampler"
"kuleshov/audio-super-res" -> "santi-pdp/segan"
"kuleshov/audio-super-res" -> "f90/Wave-U-Net"
"kuleshov/audio-super-res" -> "haoheliu/voicefixer"
"kuleshov/audio-super-res" -> "descriptinc/melgan-neurips" ["e"=1]
"kuleshov/audio-super-res" -> "mindslab-ai/nuwave" ["e"=1]
"kuleshov/audio-super-res" -> "santi-pdp/segan_pytorch"
"kuleshov/audio-super-res" -> "aliutkus/speechmetrics"
"kuleshov/audio-super-res" -> "mozilla/LPCNet" ["e"=1]
"kuleshov/audio-super-res" -> "nanahou/Awesome-Speech-Enhancement"
"kuleshov/audio-super-res" -> "mindslab-ai/nuwave2" ["e"=1]
"kuleshov/audio-super-res" -> "auspicious3000/autovc" ["e"=1]
"kuleshov/audio-super-res" -> "facebookresearch/denoiser"
"kuleshov/audio-super-res" -> "zkx06111/WSRGlow"
"kuleshov/audio-super-res" -> "anicolson/DeepXi"
"mindslab-ai/voicefilter" -> "kaituoxu/Conv-TasNet"
"mindslab-ai/voicefilter" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"mindslab-ai/voicefilter" -> "pchao6/LSTM_PIT_Speech_Separation"
"mindslab-ai/voicefilter" -> "HarryVolek/PyTorch_Speaker_Verification" ["e"=1]
"mindslab-ai/voicefilter" -> "aliutkus/speechmetrics"
"mindslab-ai/voicefilter" -> "anicolson/DeepXi"
"mindslab-ai/voicefilter" -> "gemengtju/Tutorial_Separation"
"mindslab-ai/voicefilter" -> "mpariente/asteroid"
"mindslab-ai/voicefilter" -> "wq2012/awesome-diarization" ["e"=1]
"mindslab-ai/voicefilter" -> "microsoft/DNS-Challenge"
"mindslab-ai/voicefilter" -> "google/uis-rnn" ["e"=1]
"mindslab-ai/voicefilter" -> "fgnt/nara_wpe"
"mindslab-ai/voicefilter" -> "Edresson/VoiceSplit"
"mindslab-ai/voicefilter" -> "naplab/Conv-TasNet"
"mindslab-ai/voicefilter" -> "asteroid-team/asteroid"
"LCAV/pyroomacoustics" -> "DavidDiazGuerra/gpuRIR"
"LCAV/pyroomacoustics" -> "microsoft/DNS-Challenge"
"LCAV/pyroomacoustics" -> "ehabets/RIR-Generator"
"LCAV/pyroomacoustics" -> "fgnt/nara_wpe"
"LCAV/pyroomacoustics" -> "aliutkus/speechmetrics"
"LCAV/pyroomacoustics" -> "microsoft/AEC-Challenge"
"LCAV/pyroomacoustics" -> "athena-team/athena-signal"
"LCAV/pyroomacoustics" -> "anicolson/DeepXi"
"LCAV/pyroomacoustics" -> "acoular/acoular"
"LCAV/pyroomacoustics" -> "xanguera/BeamformIt"
"LCAV/pyroomacoustics" -> "asteroid-team/asteroid"
"LCAV/pyroomacoustics" -> "funcwj/setk"
"LCAV/pyroomacoustics" -> "fgnt/nn-gev"
"LCAV/pyroomacoustics" -> "nanahou/Awesome-Speech-Enhancement"
"LCAV/pyroomacoustics" -> "python-acoustics/python-acoustics"
"audiolabs/webMUSHRA" -> "BrechtDeMan/WebAudioEvaluationTool"
"csteinmetz1/pyloudnorm" -> "csteinmetz1/auraloss" ["e"=1]
"csteinmetz1/pyloudnorm" -> "facebookresearch/WavAugment" ["e"=1]
"csteinmetz1/pyloudnorm" -> "carlthome/python-audio-effects" ["e"=1]
"csteinmetz1/pyloudnorm" -> "LCAV/pyroomacoustics"
"csteinmetz1/pyloudnorm" -> "pranaymanocha/PerceptualAudio"
"csteinmetz1/pyloudnorm" -> "justinsalamon/scaper" ["e"=1]
"csteinmetz1/pyloudnorm" -> "audiolabs/webMUSHRA"
"csteinmetz1/pyloudnorm" -> "aliutkus/speechmetrics"
"csteinmetz1/pyloudnorm" -> "microsoft/AEC-Challenge"
"csteinmetz1/pyloudnorm" -> "fgnt/nara_wpe"
"csteinmetz1/pyloudnorm" -> "BrechtDeMan/loudness.py"
"csteinmetz1/pyloudnorm" -> "funcwj/setk"
"csteinmetz1/pyloudnorm" -> "microsoft/DNS-Challenge"
"csteinmetz1/pyloudnorm" -> "KinWaiCheuk/nnAudio" ["e"=1]
"csteinmetz1/pyloudnorm" -> "iver56/audiomentations" ["e"=1]
"python-acoustics/python-acoustics" -> "LCAV/pyroomacoustics"
"python-acoustics/python-acoustics" -> "spatialaudio/computational_acoustics" ["e"=1]
"python-acoustics/python-acoustics" -> "PyTTAmaster/PyTTa"
"python-acoustics/python-acoustics" -> "SiggiGue/pyfilterbank" ["e"=1]
"python-acoustics/python-acoustics" -> "timmahrt/pyAcoustics"
"python-acoustics/python-acoustics" -> "DavidDiazGuerra/gpuRIR"
"python-acoustics/python-acoustics" -> "fgnt/nara_wpe"
"python-acoustics/python-acoustics" -> "RoyJames/room-impulse-responses"
"python-acoustics/python-acoustics" -> "audiolabs/webMUSHRA"
"python-acoustics/python-acoustics" -> "Ifsttar/I-Simpa"
"python-acoustics/python-acoustics" -> "csteinmetz1/pyloudnorm"
"python-acoustics/python-acoustics" -> "pyfar/pyfar"
"python-acoustics/python-acoustics" -> "spatialaudio/digital-signal-processing-lecture" ["e"=1]
"python-acoustics/python-acoustics" -> "acoular/acoular"
"python-acoustics/python-acoustics" -> "spatialaudio/python-sounddevice" ["e"=1]
"madebyollin/acapellabot" -> "laserb/deep-vocal-isolation"
"madebyollin/acapellabot" -> "MTG/DeepConvSep"
"santi-pdp/segan" -> "santi-pdp/segan_pytorch"
"santi-pdp/segan" -> "drethage/speech-denoising-wavenet"
"santi-pdp/segan" -> "yongxuUSTC/sednn"
"santi-pdp/segan" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"santi-pdp/segan" -> "anicolson/DeepXi"
"santi-pdp/segan" -> "yongxuUSTC/DNN-for-speech-enhancement"
"santi-pdp/segan" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"santi-pdp/segan" -> "seanwood/gcc-nmf"
"santi-pdp/segan" -> "kaituoxu/Conv-TasNet"
"santi-pdp/segan" -> "aliutkus/speechmetrics"
"santi-pdp/segan" -> "jtkim-kaist/Speech-enhancement"
"santi-pdp/segan" -> "leftthomas/SEGAN"
"santi-pdp/segan" -> "jtkim-kaist/VAD" ["e"=1]
"santi-pdp/segan" -> "Wenzhe-Liu/awesome-speech-enhancement"
"santi-pdp/segan" -> "vbelz/Speech-enhancement"
"NEGU93/cvnn" -> "JesperDramsch/keras-complex"
"NEGU93/cvnn" -> "JesperDramsch/Complex-CNN-Seismic"
"wavefrontshaping/complexPyTorch" -> "ChihebTrabelsi/deep_complex_networks"
"wavefrontshaping/complexPyTorch" -> "litcoderr/ComplexCNN"
"wavefrontshaping/complexPyTorch" -> "ivannz/cplxmodule"
"wavefrontshaping/complexPyTorch" -> "NEGU93/cvnn"
"wavefrontshaping/complexPyTorch" -> "JesperDramsch/keras-complex"
"wavefrontshaping/complexPyTorch" -> "MRSRL/complex-networks-release"
"wavefrontshaping/complexPyTorch" -> "sweetcocoa/DeepComplexUNetPyTorch"
"wavefrontshaping/complexPyTorch" -> "williamFalcon/pytorch-complex-tensor"
"wavefrontshaping/complexPyTorch" -> "omrijsharon/torchlex"
"wavefrontshaping/complexPyTorch" -> "huyanxin/DeepComplexCRN"
"wavefrontshaping/complexPyTorch" -> "zhongyuanzhao/dl_ofdm" ["e"=1]
"wavefrontshaping/complexPyTorch" -> "maggie0830/DCCRN"
"wavefrontshaping/complexPyTorch" -> "muqiaoy/dl_signal"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "santi-pdp/segan_pytorch"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "anicolson/DeepXi"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "speechLabBcCuny/onssen"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "vBaiCai/python-pesq"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "yongxuUSTC/sednn"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "JasonSWFu/MetricGAN"
"drethage/speech-denoising-wavenet" -> "santi-pdp/segan"
"drethage/speech-denoising-wavenet" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"drethage/speech-denoising-wavenet" -> "santi-pdp/segan_pytorch"
"drethage/speech-denoising-wavenet" -> "yongxuUSTC/sednn"
"drethage/speech-denoising-wavenet" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"drethage/speech-denoising-wavenet" -> "anicolson/DeepXi"
"drethage/speech-denoising-wavenet" -> "seanwood/gcc-nmf"
"drethage/speech-denoising-wavenet" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"drethage/speech-denoising-wavenet" -> "auspicious3000/WaveNet-Enhancement"
"drethage/speech-denoising-wavenet" -> "fgnt/nara_wpe"
"drethage/speech-denoising-wavenet" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"drethage/speech-denoising-wavenet" -> "yongxuUSTC/DNN-for-speech-enhancement"
"drethage/speech-denoising-wavenet" -> "vBaiCai/python-pesq"
"drethage/speech-denoising-wavenet" -> "vbelz/Speech-enhancement"
"drethage/speech-denoising-wavenet" -> "aliutkus/speechmetrics"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "drethage/speech-denoising-wavenet"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "mosheman5/DNP"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "anicolson/DeepXi"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "JasonSWFu/MetricGAN"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "santi-pdp/segan_pytorch"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "fgnt/nara_wpe"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "speechLabBcCuny/onssen"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "yongxuUSTC/sednn"
"funcwj/conv-tasnet" -> "naplab/Conv-TasNet"
"funcwj/conv-tasnet" -> "kaituoxu/Conv-TasNet"
"funcwj/conv-tasnet" -> "huyanxin/phasen"
"funcwj/conv-tasnet" -> "kaituoxu/TasNet"
"funcwj/conv-tasnet" -> "funcwj/voice-filter"
"funcwj/conv-tasnet" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"funcwj/conv-tasnet" -> "funcwj/setk"
"funcwj/conv-tasnet" -> "funcwj/CGMM-MVDR"
"funcwj/conv-tasnet" -> "yluo42/TAC"
"gabrielmittag/NISQA" -> "lochenchou/MOSNet"
"gabrielmittag/NISQA" -> "aliutkus/speechmetrics"
"gabrielmittag/NISQA" -> "JasonSWFu/Quality-Net"
"gabrielmittag/NISQA" -> "google/visqol"
"gabrielmittag/NISQA" -> "ludlows/python-pesq"
"gabrielmittag/NISQA" -> "pranaymanocha/PerceptualAudio"
"gabrielmittag/NISQA" -> "microsoft/DNS-Challenge"
"gabrielmittag/NISQA" -> "maxrmorrison/torchcrepe" ["e"=1]
"gabrielmittag/NISQA" -> "facebookresearch/speech-resynthesis" ["e"=1]
"gabrielmittag/NISQA" -> "microsoft/P.808"
"gabrielmittag/NISQA" -> "facebookresearch/WavAugment" ["e"=1]
"gabrielmittag/NISQA" -> "LEEYOONHYUNG/BVAE-TTS" ["e"=1]
"gabrielmittag/NISQA" -> "ivanvovk/WaveGrad" ["e"=1]
"gabrielmittag/NISQA" -> "schmiph2/pysepm"
"gabrielmittag/NISQA" -> "vBaiCai/python-pesq"
"haoheliu/voicefixer" -> "haoheliu/voicefixer_main"
"haoheliu/voicefixer" -> "Rikorose/DeepFilterNet"
"haoheliu/voicefixer" -> "NVIDIA/BigVGAN" ["e"=1]
"haoheliu/voicefixer" -> "brentspell/hifi-gan-bwe" ["e"=1]
"haoheliu/voicefixer" -> "ruizhecao96/CMGAN"
"haoheliu/voicefixer" -> "sp-uhh/sgmse"
"haoheliu/voicefixer" -> "mindslab-ai/nuwave" ["e"=1]
"haoheliu/voicefixer" -> "rishikksh20/HiFiplusplus-pytorch" ["e"=1]
"haoheliu/voicefixer" -> "lmnt-com/diffwave" ["e"=1]
"haoheliu/voicefixer" -> "jzi040941/PercepNet"
"haoheliu/voicefixer" -> "gabrielmittag/NISQA"
"haoheliu/voicefixer" -> "haoheliu/ssr_eval" ["e"=1]
"haoheliu/voicefixer" -> "aliutkus/speechmetrics"
"haoheliu/voicefixer" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"haoheliu/voicefixer" -> "facebookresearch/denoiser"
"kaituoxu/Conv-TasNet" -> "naplab/Conv-TasNet"
"kaituoxu/Conv-TasNet" -> "funcwj/conv-tasnet"
"kaituoxu/Conv-TasNet" -> "JusperLee/Dual-Path-RNN-Pytorch"
"kaituoxu/Conv-TasNet" -> "kaituoxu/TasNet"
"kaituoxu/Conv-TasNet" -> "yluo42/TAC"
"kaituoxu/Conv-TasNet" -> "JusperLee/Conv-TasNet"
"kaituoxu/Conv-TasNet" -> "huyanxin/DeepComplexCRN"
"kaituoxu/Conv-TasNet" -> "pchao6/LSTM_PIT_Speech_Separation"
"kaituoxu/Conv-TasNet" -> "gemengtju/Tutorial_Separation"
"kaituoxu/Conv-TasNet" -> "mpariente/asteroid"
"kaituoxu/Conv-TasNet" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"kaituoxu/Conv-TasNet" -> "mindslab-ai/voicefilter"
"kaituoxu/Conv-TasNet" -> "microsoft/DNS-Challenge"
"kaituoxu/Conv-TasNet" -> "funcwj/uPIT-for-speech-separation"
"kaituoxu/Conv-TasNet" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"mosheman5/DNP" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"mosheman5/DNP" -> "santi-pdp/segan_pytorch"
"santi-pdp/segan_pytorch" -> "santi-pdp/segan"
"santi-pdp/segan_pytorch" -> "yongxuUSTC/sednn"
"santi-pdp/segan_pytorch" -> "leftthomas/SEGAN"
"santi-pdp/segan_pytorch" -> "anicolson/DeepXi"
"santi-pdp/segan_pytorch" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"santi-pdp/segan_pytorch" -> "vBaiCai/python-pesq"
"santi-pdp/segan_pytorch" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"santi-pdp/segan_pytorch" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"santi-pdp/segan_pytorch" -> "drethage/speech-denoising-wavenet"
"santi-pdp/segan_pytorch" -> "kaituoxu/Conv-TasNet"
"santi-pdp/segan_pytorch" -> "huyanxin/phasen"
"santi-pdp/segan_pytorch" -> "vbelz/Speech-enhancement"
"santi-pdp/segan_pytorch" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"santi-pdp/segan_pytorch" -> "fgnt/nara_wpe"
"santi-pdp/segan_pytorch" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"slhck/ffmpeg-normalize" -> "supasorn/synthesizing_obama_network_training" ["e"=1]
"slhck/ffmpeg-normalize" -> "wiseman/py-webrtcvad" ["e"=1]
"slhck/ffmpeg-normalize" -> "csteinmetz1/pyloudnorm"
"slhck/ffmpeg-normalize" -> "facebookresearch/WavAugment" ["e"=1]
"slhck/ffmpeg-normalize" -> "bootphon/phonemizer" ["e"=1]
"slhck/ffmpeg-normalize" -> "aliutkus/speechmetrics"
"slhck/ffmpeg-normalize" -> "fgnt/nara_wpe"
"slhck/ffmpeg-normalize" -> "HarryVolek/PyTorch_Speaker_Verification" ["e"=1]
"slhck/ffmpeg-normalize" -> "auspicious3000/SpeechSplit" ["e"=1]
"slhck/ffmpeg-normalize" -> "facebookresearch/textlesslib" ["e"=1]
"slhck/ffmpeg-normalize" -> "facebookresearch/denoiser"
"slhck/ffmpeg-normalize" -> "MontrealCorpusTools/Montreal-Forced-Aligner" ["e"=1]
"slhck/ffmpeg-normalize" -> "drethage/speech-denoising-wavenet"
"slhck/ffmpeg-normalize" -> "mindslab-ai/voicefilter"
"slhck/ffmpeg-normalize" -> "NATSpeech/NATSpeech" ["e"=1]
"timsainb/noisereduce" -> "facebookresearch/denoiser"
"timsainb/noisereduce" -> "iver56/audiomentations" ["e"=1]
"timsainb/noisereduce" -> "aliutkus/speechmetrics"
"timsainb/noisereduce" -> "wiseman/py-webrtcvad" ["e"=1]
"timsainb/noisereduce" -> "breizhn/DTLN"
"timsainb/noisereduce" -> "dodiku/noise_reduction"
"timsainb/noisereduce" -> "vbelz/Speech-enhancement"
"timsainb/noisereduce" -> "haoheliu/voicefixer"
"timsainb/noisereduce" -> "microsoft/DNS-Challenge"
"timsainb/noisereduce" -> "pyannote/pyannote-audio" ["e"=1]
"timsainb/noisereduce" -> "csteinmetz1/pyloudnorm"
"timsainb/noisereduce" -> "LCAV/pyroomacoustics"
"timsainb/noisereduce" -> "xiph/rnnoise"
"timsainb/noisereduce" -> "KinWaiCheuk/nnAudio" ["e"=1]
"timsainb/noisereduce" -> "santi-pdp/segan"
"matousc89/padasip" -> "matousc89/Python-Adaptive-Signal-Processing-Handbook"
"matousc89/padasip" -> "Wramberg/adaptfilt"
"matousc89/padasip" -> "ninja3697/Kernel-Adaptive-Filtering-in-Python"
"matousc89/padasip" -> "ewan-xu/pyaec"
"matousc89/padasip" -> "rohitner/adaptive-filters"
"matousc89/padasip" -> "schmiph2/pysepm"
"rookiepeng/antenna-array-analysis" -> "rookiepeng/antenna-models"
"rookiepeng/antenna-array-analysis" -> "rookiepeng/antarray"
"nanahou/Awesome-Speech-Enhancement" -> "Wenzhe-Liu/awesome-speech-enhancement"
"nanahou/Awesome-Speech-Enhancement" -> "gemengtju/Tutorial_Separation"
"nanahou/Awesome-Speech-Enhancement" -> "microsoft/DNS-Challenge"
"nanahou/Awesome-Speech-Enhancement" -> "huyanxin/DeepComplexCRN"
"nanahou/Awesome-Speech-Enhancement" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"nanahou/Awesome-Speech-Enhancement" -> "aliutkus/speechmetrics"
"nanahou/Awesome-Speech-Enhancement" -> "funcwj/setk"
"nanahou/Awesome-Speech-Enhancement" -> "jzi040941/PercepNet"
"nanahou/Awesome-Speech-Enhancement" -> "anicolson/DeepXi"
"nanahou/Awesome-Speech-Enhancement" -> "haoxiangsnr/FullSubNet"
"nanahou/Awesome-Speech-Enhancement" -> "huyanxin/phasen"
"nanahou/Awesome-Speech-Enhancement" -> "facebookresearch/denoiser"
"nanahou/Awesome-Speech-Enhancement" -> "vbelz/Speech-enhancement"
"nanahou/Awesome-Speech-Enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"nanahou/Awesome-Speech-Enhancement" -> "Ryuk17/SpeechAlgorithms"
"voice-engine/make-a-smart-speaker" -> "voice-engine/ec"
"voice-engine/make-a-smart-speaker" -> "voice-engine/voice-engine"
"voice-engine/make-a-smart-speaker" -> "mindorii/kws" ["e"=1]
"voice-engine/make-a-smart-speaker" -> "respeaker/mic_array"
"voice-engine/make-a-smart-speaker" -> "fgnt/nn-gev"
"voice-engine/make-a-smart-speaker" -> "xanguera/BeamformIt"
"voice-engine/make-a-smart-speaker" -> "colinsongf/keyword_spotting" ["e"=1]
"voice-engine/make-a-smart-speaker" -> "introlab/odas"
"voice-engine/make-a-smart-speaker" -> "wangwei2009/DOA"
"voice-engine/make-a-smart-speaker" -> "yongxuUSTC/sednn"
"voice-engine/make-a-smart-speaker" -> "kkumatani/distant_speech_recognition"
"voice-engine/make-a-smart-speaker" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"voice-engine/make-a-smart-speaker" -> "microsoft/AEC-Challenge"
"voice-engine/make-a-smart-speaker" -> "robin1001/beamforming"
"voice-engine/make-a-smart-speaker" -> "funcwj/CGMM-MVDR"
"yump/doamusic" -> "amjadsaadeh/pyMUSIC"
"vsubhashini/ica" -> "robical/BlindSourceSeparation"
"MTG/DeepConvSep" -> "andabi/music-source-separation"
"MTG/DeepConvSep" -> "francesclluis/source-separation-wavenet"
"MTG/DeepConvSep" -> "interactiveaudiolab/nussl"
"MTG/DeepConvSep" -> "posenhuang/deeplearningsourceseparation"
"MTG/DeepConvSep" -> "f90/Wave-U-Net"
"MTG/DeepConvSep" -> "wslihgt/pyfasst"
"MTG/DeepConvSep" -> "Js-Mim/mss_pytorch"
"MTG/DeepConvSep" -> "craffel/mir_eval" ["e"=1]
"MTG/DeepConvSep" -> "marl/medleydb" ["e"=1]
"MTG/DeepConvSep" -> "MTG/gaia" ["e"=1]
"MTG/DeepConvSep" -> "zhr1201/deep-clustering"
"MTG/DeepConvSep" -> "urinieto/msaf" ["e"=1]
"MTG/DeepConvSep" -> "bmcfee/muda" ["e"=1]
"MTG/DeepConvSep" -> "madebyollin/acapellabot"
"MTG/DeepConvSep" -> "drethage/speech-denoising-wavenet"
"ShichengChen/Audio-Source-Separation" -> "scpark20/universal-music-translation"
"Wenzhe-Liu/awesome-speech-enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"Wenzhe-Liu/awesome-speech-enhancement" -> "anicolson/DeepXi"
"Wenzhe-Liu/awesome-speech-enhancement" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"Wenzhe-Liu/awesome-speech-enhancement" -> "microsoft/DNS-Challenge"
"Wenzhe-Liu/awesome-speech-enhancement" -> "huyanxin/DeepComplexCRN"
"Wenzhe-Liu/awesome-speech-enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"Wenzhe-Liu/awesome-speech-enhancement" -> "funcwj/setk"
"Wenzhe-Liu/awesome-speech-enhancement" -> "jzi040941/PercepNet"
"Wenzhe-Liu/awesome-speech-enhancement" -> "haoxiangsnr/FullSubNet"
"Wenzhe-Liu/awesome-speech-enhancement" -> "huyanxin/phasen"
"Wenzhe-Liu/awesome-speech-enhancement" -> "aliutkus/speechmetrics"
"Wenzhe-Liu/awesome-speech-enhancement" -> "microsoft/MS-SNSD"
"Wenzhe-Liu/awesome-speech-enhancement" -> "microsoft/AEC-Challenge"
"Wenzhe-Liu/awesome-speech-enhancement" -> "vbelz/Speech-enhancement"
"Wenzhe-Liu/awesome-speech-enhancement" -> "breizhn/DTLN"
"fgnt/pb_bss" -> "funcwj/setk"
"fgnt/pb_bss" -> "fgnt/nn-gev"
"fgnt/pb_bss" -> "fgnt/nara_wpe"
"fgnt/pb_bss" -> "nttcslab-sp/dnn_wpe"
"fgnt/pb_bss" -> "fgnt/pb_chime5"
"fgnt/pb_bss" -> "funcwj/CGMM-MVDR"
"fgnt/pb_bss" -> "funcwj/cgmm-mask-estimator"
"fgnt/pb_bss" -> "fakufaku/torchiva"
"fgnt/pb_bss" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"fgnt/pb_bss" -> "seanwood/gcc-nmf"
"fgnt/pb_bss" -> "d-kitamura/ILRMA"
"fgnt/pb_bss" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"fgnt/pb_bss" -> "sekiguchi92/SoundSourceSeparation"
"fgnt/pb_bss" -> "speechLabBcCuny/onssen"
"fgnt/pb_bss" -> "yluo42/TAC"
"francesclluis/source-separation-wavenet" -> "MTG/DeepConvSep"
"francesclluis/source-separation-wavenet" -> "f90/Wave-U-Net"
"francesclluis/source-separation-wavenet" -> "sigsep/norbert" ["e"=1]
"francesclluis/source-separation-wavenet" -> "andabi/music-source-separation"
"francesclluis/source-separation-wavenet" -> "ShichengChen/Audio-Source-Separation"
"haoxiangsnr/SNR-Based-Progressive-Learning-of-Deep-Neural-Network-for-Speech-Enhancement" -> "haoxiangsnr/Speech_Enhancement_Tools"
"interactiveaudiolab/nussl" -> "posenhuang/deeplearningsourceseparation"
"interactiveaudiolab/nussl" -> "MTG/DeepConvSep"
"interactiveaudiolab/nussl" -> "Js-Mim/mss_pytorch"
"interactiveaudiolab/nussl" -> "wslihgt/pyfasst"
"interactiveaudiolab/nussl" -> "IoSR-Surrey/untwist"
"interactiveaudiolab/nussl" -> "craffel/mir_eval" ["e"=1]
"jagger2048/rnnoise-windows" -> "GregorR/rnnoise-nu"
"petotamas/pyArgus" -> "zinka/arraytool"
"petotamas/pyArgus" -> "morriswmz/doatools.py"
"petotamas/pyArgus" -> "petotamas/APRiL"
"petotamas/pyArgus" -> "MSBeni/AoA_IQsamples"
"petotamas/pyArgus" -> "rookiepeng/antenna-array-analysis"
"petotamas/pyArgus" -> "jonkraft/PhasedArray"
"petotamas/pyArgus" -> "rookiepeng/antarray"
"Rikorose/DeepFilterNet" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"Rikorose/DeepFilterNet" -> "jzi040941/PercepNet"
"Rikorose/DeepFilterNet" -> "echocatzh/MTFAA-Net"
"Rikorose/DeepFilterNet" -> "haoxiangsnr/FullSubNet"
"Rikorose/DeepFilterNet" -> "felixfuyihui/Uformer"
"Rikorose/DeepFilterNet" -> "sp-uhh/sgmse"
"Rikorose/DeepFilterNet" -> "breizhn/DTLN"
"Rikorose/DeepFilterNet" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"Rikorose/DeepFilterNet" -> "fjiang9/NKF-AEC"
"Rikorose/DeepFilterNet" -> "microsoft/DNS-Challenge"
"Rikorose/DeepFilterNet" -> "haoheliu/voicefixer"
"Rikorose/DeepFilterNet" -> "aliutkus/speechmetrics"
"Rikorose/DeepFilterNet" -> "vb000/Waveformer"
"Rikorose/DeepFilterNet" -> "ruizhecao96/CMGAN"
"Rikorose/DeepFilterNet" -> "Qinwen-Hu/dparn"
"microsoft/DNS-Challenge" -> "huyanxin/DeepComplexCRN"
"microsoft/DNS-Challenge" -> "microsoft/AEC-Challenge"
"microsoft/DNS-Challenge" -> "breizhn/DTLN"
"microsoft/DNS-Challenge" -> "microsoft/MS-SNSD"
"microsoft/DNS-Challenge" -> "haoxiangsnr/FullSubNet"
"microsoft/DNS-Challenge" -> "jzi040941/PercepNet"
"microsoft/DNS-Challenge" -> "nanahou/Awesome-Speech-Enhancement"
"microsoft/DNS-Challenge" -> "anicolson/DeepXi"
"microsoft/DNS-Challenge" -> "Wenzhe-Liu/awesome-speech-enhancement"
"microsoft/DNS-Challenge" -> "aliutkus/speechmetrics"
"microsoft/DNS-Challenge" -> "facebookresearch/denoiser"
"microsoft/DNS-Challenge" -> "huyanxin/phasen"
"microsoft/DNS-Challenge" -> "funcwj/setk"
"microsoft/DNS-Challenge" -> "fgnt/nara_wpe"
"microsoft/DNS-Challenge" -> "LCAV/pyroomacoustics"
"emilbjornson/optimal-beamforming" -> "TianLin0509/Hybrid-Beamforming-for-Millimeter-Wave-Systems-Using-the-MMSE-Criterion" ["e"=1]
"emilbjornson/optimal-beamforming" -> "jorgengrythe/beamforming"
"emilbjornson/optimal-beamforming" -> "emilbjornson/book-resource-allocation" ["e"=1]
"emilbjornson/optimal-beamforming" -> "emilbjornson/IRS-relaying" ["e"=1]
"cpuimage/WebRTC_VAD" -> "cpuimage/WebRTC_AGC"
"cpuimage/WebRTC_VAD" -> "cpuimage/WebRTC_AECM"
"cpuimage/WebRTC_VAD" -> "cpuimage/WebRTC_NS"
"cpuimage/WebRTC_VAD" -> "cpuimage/rnnoise"
"cpuimage/WebRTC_VAD" -> "cpuimage/resampler"
"Jonathan-LeRoux/IguanaTex" -> "abenori/TeX2img"
"Jonathan-LeRoux/IguanaTex" -> "fgnt/nara_wpe"
"Jonathan-LeRoux/IguanaTex" -> "ray851107/IguanaTexMac"
"Jonathan-LeRoux/IguanaTex" -> "DavidDiazGuerra/gpuRIR"
"Jonathan-LeRoux/IguanaTex" -> "fgnt/ci_sdr"
"JorisCos/LibriMix" -> "xuchenglin28/speaker_extraction"
"JorisCos/LibriMix" -> "popcornell/SparseLibriMix"
"JorisCos/LibriMix" -> "gemengtju/Tutorial_Separation"
"JorisCos/LibriMix" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"JorisCos/LibriMix" -> "yluo42/TAC"
"JorisCos/LibriMix" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"JorisCos/LibriMix" -> "JusperLee/Conv-TasNet"
"JorisCos/LibriMix" -> "chenzhuo1011/libri_css"
"JorisCos/LibriMix" -> "funcwj/conv-tasnet"
"JorisCos/LibriMix" -> "ujscjj/DPTNet"
"JorisCos/LibriMix" -> "aliutkus/speechmetrics"
"JorisCos/LibriMix" -> "naplab/Conv-TasNet"
"JorisCos/LibriMix" -> "Enny1991/beamformers"
"JorisCos/LibriMix" -> "asteroid-team/asteroid"
"JorisCos/LibriMix" -> "DavidDiazGuerra/gpuRIR"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "yump/doamusic"
"morriswmz/doa-tools" -> "morriswmz/doatools.py"
"morriswmz/doa-tools" -> "msamsami/doa-estimation-music"
"morriswmz/doa-tools" -> "wangwei2009/DOA"
"morriswmz/doa-tools" -> "Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation"
"morriswmz/doa-tools" -> "polarch/Spherical-Array-Processing" ["e"=1]
"morriswmz/doa-tools" -> "chenhui07c8/DOA-AOA-algorithms"
"morriswmz/doa-tools" -> "dengjunquan/DoA-Estimation-MUSIC-ESPRIT"
"morriswmz/doa-tools" -> "LCAV/FRIDA"
"morriswmz/doa-tools" -> "xuchenglin28/WSCM-MUSIC"
"morriswmz/doa-tools" -> "yump/doamusic"
"ImperialCollegeLondon/sap-voicebox" -> "fgnt/nara_wpe"
"ImperialCollegeLondon/sap-voicebox" -> "jtkim-kaist/Speech-enhancement"
"ImperialCollegeLondon/sap-voicebox" -> "DavidDiazGuerra/gpuRIR"
"ImperialCollegeLondon/sap-voicebox" -> "helianvine/fdndlp"
"ImperialCollegeLondon/sap-voicebox" -> "ZitengWang/MASP"
"ImperialCollegeLondon/sap-voicebox" -> "funcwj/setk"
"ImperialCollegeLondon/sap-voicebox" -> "athena-team/athena-signal"
"ImperialCollegeLondon/sap-voicebox" -> "jfsantos/SRMRpy"
"ImperialCollegeLondon/sap-voicebox" -> "orchidas/Pitch-Tracking" ["e"=1]
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" -> "xiaoli1368/Microphone-sound-source-localization"
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" -> "aishoot/Sound_Localization_Algorithms"
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" -> "xiongyihui/tdoa"
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" -> "morriswmz/doa-tools"
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" -> "snsun/cgmm_mvdr"
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" -> "funcwj/setk"
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" -> "Wenzhe-Liu/awesome-speech-enhancement"
"AgoraIO-Community/Solo" -> "microsoft/AEC-Challenge"
"AgoraIO-Community/Solo" -> "shichaog/RNNAec"
"huyanxin/DeepComplexCRN" -> "maggie0830/DCCRN"
"huyanxin/DeepComplexCRN" -> "jzi040941/PercepNet"
"huyanxin/DeepComplexCRN" -> "microsoft/DNS-Challenge"
"huyanxin/DeepComplexCRN" -> "haoxiangsnr/FullSubNet"
"huyanxin/DeepComplexCRN" -> "huyanxin/phasen"
"huyanxin/DeepComplexCRN" -> "breizhn/DTLN"
"huyanxin/DeepComplexCRN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"huyanxin/DeepComplexCRN" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"huyanxin/DeepComplexCRN" -> "microsoft/MS-SNSD"
"huyanxin/DeepComplexCRN" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"huyanxin/DeepComplexCRN" -> "seorim0/DCCRN-with-various-loss-functions"
"huyanxin/DeepComplexCRN" -> "nanahou/Awesome-Speech-Enhancement"
"huyanxin/DeepComplexCRN" -> "Wenzhe-Liu/awesome-speech-enhancement"
"huyanxin/DeepComplexCRN" -> "kaituoxu/Conv-TasNet"
"huyanxin/DeepComplexCRN" -> "anicolson/DeepXi"
"tky823/audio_source_separation" -> "lili-0805/MVAE"
"wangwei2009/DOA" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"wangwei2009/DOA" -> "xiaoli1368/Microphone-sound-source-localization"
"wangwei2009/DOA" -> "robin1001/beamforming"
"wangwei2009/DOA" -> "morriswmz/doa-tools"
"wangwei2009/DOA" -> "xiongyihui/tdoa"
"wangwei2009/DOA" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"wangwei2009/DOA" -> "xuchenglin28/WSCM-MUSIC"
"wangwei2009/DOA" -> "pchao6/Sound_Localization_Algorithms"
"andabi/music-source-separation" -> "MTG/DeepConvSep"
"andabi/music-source-separation" -> "f90/Wave-U-Net"
"andabi/music-source-separation" -> "Js-Mim/mss_pytorch"
"andabi/music-source-separation" -> "posenhuang/deeplearningsourceseparation"
"andabi/music-source-separation" -> "hjkwon0609/source_separation_ml_jeju"
"andabi/music-source-separation" -> "francesclluis/source-separation-wavenet"
"andabi/music-source-separation" -> "drethage/speech-denoising-wavenet"
"andabi/music-source-separation" -> "interactiveaudiolab/nussl"
"andabi/music-source-separation" -> "santi-pdp/segan"
"andabi/music-source-separation" -> "sigsep/open-unmix-pytorch" ["e"=1]
"andabi/music-source-separation" -> "sungheonpark/music_source_sepearation_SH_net"
"andabi/music-source-separation" -> "ybayle/awesome-deep-learning-music" ["e"=1]
"andabi/music-source-separation" -> "zhr1201/deep-clustering"
"andabi/music-source-separation" -> "pchao6/LSTM_PIT_Speech_Separation"
"andabi/music-source-separation" -> "madebyollin/acapellabot"
"JusperLee/Conv-TasNet" -> "JusperLee/Dual-Path-RNN-Pytorch"
"JusperLee/Conv-TasNet" -> "naplab/Conv-TasNet"
"JusperLee/Conv-TasNet" -> "kaituoxu/Conv-TasNet"
"JusperLee/Conv-TasNet" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"JusperLee/Conv-TasNet" -> "yluo42/TAC"
"JusperLee/Conv-TasNet" -> "JorisCos/LibriMix"
"JusperLee/Conv-TasNet" -> "funcwj/conv-tasnet"
"JusperLee/Conv-TasNet" -> "JusperLee/Deep-Clustering-for-Speech-Separation"
"JusperLee/Conv-TasNet" -> "JusperLee/Deep-Encoder-Decoder-Conv-TasNet"
"JusperLee/Conv-TasNet" -> "gemengtju/Tutorial_Separation"
"JusperLee/Conv-TasNet" -> "JusperLee/Looking-to-Listen-at-the-Cocktail-Party" ["e"=1]
"JusperLee/Conv-TasNet" -> "Wenzhe-Liu/awesome-speech-enhancement"
"JusperLee/Conv-TasNet" -> "JusperLee/Calculate-SNR-SDR"
"JusperLee/Conv-TasNet" -> "kaituoxu/TasNet"
"JusperLee/Conv-TasNet" -> "JusperLee/UtterancePIT-Speech-Separation"
"jtkim-kaist/Speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"jtkim-kaist/Speech-enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"jtkim-kaist/Speech-enhancement" -> "yongxuUSTC/DNN-for-speech-enhancement"
"jtkim-kaist/Speech-enhancement" -> "yongxuUSTC/sednn"
"jtkim-kaist/Speech-enhancement" -> "hyli666/DNN-SpeechEnhancement"
"jtkim-kaist/Speech-enhancement" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"jtkim-kaist/Speech-enhancement" -> "jtkim-kaist/VAD" ["e"=1]
"jtkim-kaist/Speech-enhancement" -> "anicolson/DeepXi"
"jtkim-kaist/Speech-enhancement" -> "seanwood/gcc-nmf"
"jtkim-kaist/Speech-enhancement" -> "ZitengWang/MASP"
"jtkim-kaist/Speech-enhancement" -> "vBaiCai/python-pesq"
"respeaker/get_started_with_respeaker" -> "respeaker/respeaker_python_library"
"respeaker/get_started_with_respeaker" -> "respeaker/avs" ["e"=1]
"respeaker/get_started_with_respeaker" -> "respeaker/respeaker-feed"
"respeaker/get_started_with_respeaker" -> "respeaker/Alexa"
"respeaker/get_started_with_respeaker" -> "respeaker/mic_array"
"respeaker/get_started_with_respeaker" -> "respeaker/respeaker_arduino_library"
"respeaker/get_started_with_respeaker" -> "voice-engine/voice-engine"
"respeaker/get_started_with_respeaker" -> "respeaker/seeed-voicecard"
"respeaker/get_started_with_respeaker" -> "Fuhua-Chen/ReSpeaker-Microphone-Array-HID-tool"
"google-research/sound-separation" -> "kaituoxu/Conv-TasNet"
"google-research/sound-separation" -> "naplab/Conv-TasNet"
"google-research/sound-separation" -> "JorisCos/LibriMix"
"google-research/sound-separation" -> "mpariente/asteroid"
"google-research/sound-separation" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"google-research/sound-separation" -> "microsoft/DNS-Challenge"
"google-research/sound-separation" -> "JusperLee/Dual-Path-RNN-Pytorch"
"google-research/sound-separation" -> "microsoft/AEC-Challenge"
"google-research/sound-separation" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"google-research/sound-separation" -> "jzi040941/PercepNet"
"google-research/sound-separation" -> "yluo42/TAC"
"google-research/sound-separation" -> "nussl/nussl" ["e"=1]
"google-research/sound-separation" -> "anicolson/DeepXi"
"google-research/sound-separation" -> "Wenzhe-Liu/awesome-speech-enhancement"
"google-research/sound-separation" -> "huyanxin/phasen"
"asteroid-team/asteroid" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"asteroid-team/asteroid" -> "microsoft/DNS-Challenge"
"asteroid-team/asteroid" -> "facebookresearch/denoiser"
"asteroid-team/asteroid" -> "huyanxin/DeepComplexCRN"
"asteroid-team/asteroid" -> "gemengtju/Tutorial_Separation"
"asteroid-team/asteroid" -> "nanahou/Awesome-Speech-Enhancement"
"asteroid-team/asteroid" -> "kaituoxu/Conv-TasNet"
"asteroid-team/asteroid" -> "JorisCos/LibriMix"
"asteroid-team/asteroid" -> "speechbrain/speechbrain" ["e"=1]
"asteroid-team/asteroid" -> "Wenzhe-Liu/awesome-speech-enhancement"
"asteroid-team/asteroid" -> "haoxiangsnr/FullSubNet"
"asteroid-team/asteroid" -> "LCAV/pyroomacoustics"
"asteroid-team/asteroid" -> "aliutkus/speechmetrics"
"asteroid-team/asteroid" -> "asteroid-team/torch-audiomentations" ["e"=1]
"asteroid-team/asteroid" -> "DavidDiazGuerra/gpuRIR"
"chenzhuo1011/libri_css" -> "yluo42/TAC"
"chenzhuo1011/libri_css" -> "xuchenglin28/speaker_extraction"
"chenzhuo1011/libri_css" -> "Enny1991/beamformers"
"chenzhuo1011/libri_css" -> "gemengtju/SpEx_Plus"
"chenzhuo1011/libri_css" -> "ujscjj/DPTNet"
"funcwj/deep-clustering" -> "zhr1201/deep-clustering"
"funcwj/deep-clustering" -> "funcwj/uPIT-for-speech-separation"
"funcwj/deep-clustering" -> "naplab/DANet"
"funcwj/deep-clustering" -> "pchao6/LSTM_PIT_Speech_Separation"
"funcwj/deep-clustering" -> "snsun/pit-speech-separation"
"funcwj/setk" -> "fgnt/pb_bss"
"funcwj/setk" -> "fgnt/nn-gev"
"funcwj/setk" -> "fgnt/nara_wpe"
"funcwj/setk" -> "anicolson/DeepXi"
"funcwj/setk" -> "athena-team/athena-signal"
"funcwj/setk" -> "funcwj/CGMM-MVDR"
"funcwj/setk" -> "seanwood/gcc-nmf"
"funcwj/setk" -> "funcwj/cgmm-mask-estimator"
"funcwj/setk" -> "funcwj/aps"
"funcwj/setk" -> "ZitengWang/MASP"
"funcwj/setk" -> "fgnt/pb_chime5"
"funcwj/setk" -> "Wenzhe-Liu/awesome-speech-enhancement"
"funcwj/setk" -> "speechLabBcCuny/onssen"
"funcwj/setk" -> "nanahou/Awesome-Speech-Enhancement"
"funcwj/setk" -> "microsoft/AEC-Challenge"
"funcwj/uPIT-for-speech-separation" -> "snsun/pit-speech-separation"
"funcwj/uPIT-for-speech-separation" -> "pchao6/LSTM_PIT_Speech_Separation"
"funcwj/uPIT-for-speech-separation" -> "funcwj/deep-clustering"
"funcwj/uPIT-for-speech-separation" -> "naplab/DANet"
"funcwj/uPIT-for-speech-separation" -> "kaituoxu/TasNet"
"gemengtju/SpEx_Plus" -> "xuchenglin28/speaker_extraction_SpEx"
"gemengtju/SpEx_Plus" -> "xuchenglin28/speaker_extraction"
"gemengtju/SpEx_Plus" -> "mborsdorf/UniversalSpeakerExtraction"
"gemengtju/Tutorial_Separation" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"gemengtju/Tutorial_Separation" -> "nanahou/Awesome-Speech-Enhancement"
"gemengtju/Tutorial_Separation" -> "kaituoxu/Conv-TasNet"
"gemengtju/Tutorial_Separation" -> "xuchenglin28/speaker_extraction"
"gemengtju/Tutorial_Separation" -> "JorisCos/LibriMix"
"gemengtju/Tutorial_Separation" -> "tky823/DNN-based_source_separation"
"gemengtju/Tutorial_Separation" -> "asteroid-team/asteroid"
"gemengtju/Tutorial_Separation" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"gemengtju/Tutorial_Separation" -> "JusperLee/Dual-Path-RNN-Pytorch"
"gemengtju/Tutorial_Separation" -> "Wenzhe-Liu/awesome-speech-enhancement"
"gemengtju/Tutorial_Separation" -> "yluo42/TAC"
"gemengtju/Tutorial_Separation" -> "gemengtju/SpEx_Plus"
"gemengtju/Tutorial_Separation" -> "naplab/Conv-TasNet"
"gemengtju/Tutorial_Separation" -> "JusperLee/Conv-TasNet"
"gemengtju/Tutorial_Separation" -> "huyanxin/DeepComplexCRN"
"xuchenglin28/speaker_extraction" -> "xuchenglin28/speech_separation"
"xuchenglin28/speaker_extraction" -> "xuchenglin28/speaker_extraction_SpEx"
"xuchenglin28/speaker_extraction" -> "gemengtju/SpEx_Plus"
"xuchenglin28/speaker_extraction" -> "chenzhuo1011/libri_css"
"xuchenglin28/speaker_extraction" -> "haoxiangsnr/SpEx"
"xuchenglin28/speaker_extraction" -> "BUTSpeechFIT/speakerbeam"
"cpuimage/WebRTC_AGC" -> "cpuimage/WebRTC_VAD"
"cpuimage/WebRTC_AGC" -> "cpuimage/WebRTC_AECM"
"cpuimage/WebRTC_AGC" -> "cpuimage/WebRTC_NS"
"cpuimage/WebRTC_AGC" -> "cpuimage/resampler"
"cpuimage/WebRTC_AGC" -> "YangangCao/WebRTC-3A1V"
"cpuimage/WebRTC_AGC" -> "jorgehatccrma/pyagc"
"Js-Mim/mss_pytorch" -> "dr-costas/mad-twinnet"
"Js-Mim/mss_pytorch" -> "sigsep/sigsep-mus-2018"
"BBuf/model-compression" -> "vkothapally/JAECBF"
"BBuf/model-compression" -> "Eric-mingjie/network-slimming" ["e"=1]
"matousc89/Python-Adaptive-Signal-Processing-Handbook" -> "matousc89/padasip"
"matousc89/Python-Adaptive-Signal-Processing-Handbook" -> "rohitner/adaptive-filters"
"matousc89/Python-Adaptive-Signal-Processing-Handbook" -> "Wramberg/adaptfilt"
"Edresson/VoiceSplit" -> "gemengtju/SpEx_Plus"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "gemengtju/Tutorial_Separation"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "JusperLee/Dual-Path-RNN-Pytorch"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "Wenzhe-Liu/awesome-speech-enhancement"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "nanahou/Awesome-Speech-Enhancement"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "JusperLee/Conv-TasNet"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "asteroid-team/asteroid"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "yluo42/TAC"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "microsoft/DNS-Challenge"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "JorisCos/LibriMix"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "kaituoxu/Conv-TasNet"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "Ryuk17/SpeechAlgorithms"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "naplab/Conv-TasNet"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "aliutkus/speechmetrics"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "DavidDiazGuerra/gpuRIR"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"f90/Wave-U-Net-Pytorch" -> "f90/Wave-U-Net"
"f90/Wave-U-Net-Pytorch" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"f90/Wave-U-Net-Pytorch" -> "kaituoxu/Conv-TasNet"
"f90/Wave-U-Net-Pytorch" -> "naplab/Conv-TasNet"
"vb000/Waveformer" -> "felixfuyihui/Uformer"
"vb000/Waveformer" -> "Le-Xiaohuai-speech/SKIP-DPCRN"
"vb000/Waveformer" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"vb000/Waveformer" -> "echocatzh/PFDKF"
"vb000/Waveformer" -> "fjiang9/NKF-AEC"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_VAD"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_AECM"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_AGC"
"cpuimage/WebRTC_NS" -> "cpuimage/rnnoise"
"cpuimage/WebRTC_NS" -> "cpuimage/SimpleAudioDenoise"
"cpuimage/WebRTC_NS" -> "cpuimage/resampler"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_NS_CPP"
"cpuimage/WebRTC_NS" -> "jagger2048/WebRtc_noise_suppression"
"cpuimage/WebRTC_NS" -> "shichaog/WebRTC-audio-processing"
"cpuimage/WebRTC_NS" -> "garyyu/WebRTC_VoiceEngine"
"cpuimage/WebRTC_NS" -> "cpuimage/AudioDenoise"
"cpuimage/WebRTC_NS" -> "cpuimage/FFTResampler"
"cpuimage/WebRTC_NS" -> "Baidu-AIP/speech-vad-demo" ["e"=1]
"cpuimage/WebRTC_NS" -> "ewan-xu/AEC3"
"cpuimage/WebRTC_NS" -> "Ryuk17/SpeechAlgorithms"
"aishoot/Sound_Localization_Algorithms" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"aishoot/Sound_Localization_Algorithms" -> "ZitengWang/MASP"
"aishoot/Sound_Localization_Algorithms" -> "wangwei2009/DOA"
"aishoot/Sound_Localization_Algorithms" -> "huangzhenyu/beamforming"
"aishoot/Sound_Localization_Algorithms" -> "Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation"
"aishoot/Sound_Localization_Algorithms" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"JackHCC/Audio-Digital-Processing" -> "fzzfbyx/Audio-FIR-denoising-filter-MATLAB_GUI"
"furushchev/respeaker_ros" -> "respeaker/usb_4_mic_array"
"jim-schwoebel/voicebook" -> "jim-schwoebel/voice_gender_detection"
"jim-schwoebel/voicebook" -> "jim-schwoebel/voice_datasets"
"jim-schwoebel/voicebook" -> "jim-schwoebel/allie"
"respeaker/mic_hat" -> "respeaker/seeed-voicecard"
"vBaiCai/python-pesq" -> "mpariente/pystoi"
"vBaiCai/python-pesq" -> "ludlows/python-pesq"
"vBaiCai/python-pesq" -> "aliutkus/speechmetrics"
"vBaiCai/python-pesq" -> "schmiph2/pysepm"
"vBaiCai/python-pesq" -> "santi-pdp/segan_pytorch"
"vBaiCai/python-pesq" -> "anicolson/DeepXi"
"vBaiCai/python-pesq" -> "JasonSWFu/MetricGAN"
"vBaiCai/python-pesq" -> "fgnt/nara_wpe"
"vBaiCai/python-pesq" -> "huyanxin/phasen"
"vBaiCai/python-pesq" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"vBaiCai/python-pesq" -> "DavidDiazGuerra/gpuRIR"
"vBaiCai/python-pesq" -> "microsoft/DNS-Challenge"
"vBaiCai/python-pesq" -> "funcwj/setk"
"vBaiCai/python-pesq" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"vBaiCai/python-pesq" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"jorgengrythe/beamforming" -> "huangzhenyu/beamforming"
"jorgengrythe/beamforming" -> "robin1001/beamforming"
"jorgengrythe/beamforming" -> "emilbjornson/optimal-beamforming"
"jorgengrythe/beamforming" -> "pchao6/Sound_Localization_Algorithms"
"jorgengrythe/beamforming" -> "acoular/acoular"
"jorgengrythe/beamforming" -> "chenwj1989/Beamforming_Examples"
"jorgengrythe/beamforming" -> "xanguera/BeamformIt"
"jorgengrythe/beamforming" -> "jgarciagimenez/GSC_beamforming"
"jorgengrythe/beamforming" -> "snsun/cgmm_mvdr"
"jorgengrythe/beamforming" -> "ZitengWang/MASP"
"jorgengrythe/beamforming" -> "funcwj/CGMM-MVDR"
"jorgengrythe/beamforming" -> "kkumatani/distant_speech_recognition"
"jorgengrythe/beamforming" -> "funcwj/cgmm-mask-estimator"
"jorgengrythe/beamforming" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"jorgengrythe/beamforming" -> "wangwei2009/DOA"
"vbelz/Speech-enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"vbelz/Speech-enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"vbelz/Speech-enhancement" -> "Wenzhe-Liu/awesome-speech-enhancement"
"vbelz/Speech-enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"vbelz/Speech-enhancement" -> "santi-pdp/segan_pytorch"
"vbelz/Speech-enhancement" -> "breizhn/DTLN"
"vbelz/Speech-enhancement" -> "anicolson/DeepXi"
"vbelz/Speech-enhancement" -> "funcwj/setk"
"vbelz/Speech-enhancement" -> "santi-pdp/segan"
"vbelz/Speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"vbelz/Speech-enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"vbelz/Speech-enhancement" -> "seanwood/gcc-nmf"
"vbelz/Speech-enhancement" -> "microsoft/DNS-Challenge"
"vbelz/Speech-enhancement" -> "aliutkus/speechmetrics"
"vbelz/Speech-enhancement" -> "drethage/speech-denoising-wavenet"
"openBliSSART/openBliSSART" -> "wslihgt/pyfasst"
"openBliSSART/openBliSSART" -> "vsubhashini/ica"
"thesofproject/sof" -> "thesofproject/linux"
"thesofproject/sof" -> "thesofproject/sof-docs"
"thesofproject/sof" -> "xiph/speexdsp"
"thesofproject/sof" -> "thesofproject/sof-test"
"huangzhenyu/beamforming" -> "kkumatani/distant_speech_recognition"
"huangzhenyu/beamforming" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"huangzhenyu/beamforming" -> "jorgengrythe/beamforming"
"microsoft/AEC-Challenge" -> "breizhn/DTLN-aec"
"microsoft/AEC-Challenge" -> "jzi040941/PercepNet"
"microsoft/AEC-Challenge" -> "microsoft/DNS-Challenge"
"microsoft/AEC-Challenge" -> "ewan-xu/AEC3"
"microsoft/AEC-Challenge" -> "breizhn/DTLN"
"microsoft/AEC-Challenge" -> "microsoft/P.808"
"microsoft/AEC-Challenge" -> "wavesaudio/Speex-AEC-matlab"
"microsoft/AEC-Challenge" -> "athena-team/athena-signal"
"microsoft/AEC-Challenge" -> "ewan-xu/pyaec"
"microsoft/AEC-Challenge" -> "fjiang9/NKF-AEC"
"microsoft/AEC-Challenge" -> "LXP-Never/AEC_DeepModel"
"microsoft/AEC-Challenge" -> "kkumatani/distant_speech_recognition"
"microsoft/AEC-Challenge" -> "huyanxin/phasen"
"microsoft/AEC-Challenge" -> "funcwj/setk"
"microsoft/AEC-Challenge" -> "ConferencingSpeech/ConferencingSpeech2021"
"respeaker/respeaker_python_library" -> "respeaker/get_started_with_respeaker"
"respeaker/respeaker_python_library" -> "respeaker/respeaker_arduino_library"
"respeaker/respeaker_python_library" -> "respeaker/microsoft_cognitive_services"
"DavidDiazGuerra/gpuRIR" -> "ehabets/RIR-Generator"
"DavidDiazGuerra/gpuRIR" -> "fgnt/nara_wpe"
"DavidDiazGuerra/gpuRIR" -> "LCAV/pyroomacoustics"
"DavidDiazGuerra/gpuRIR" -> "yluo42/TAC"
"DavidDiazGuerra/gpuRIR" -> "microsoft/AEC-Challenge"
"DavidDiazGuerra/gpuRIR" -> "Audio-WestlakeU/NBSS"
"DavidDiazGuerra/gpuRIR" -> "fgnt/nn-gev"
"DavidDiazGuerra/gpuRIR" -> "funcwj/setk"
"DavidDiazGuerra/gpuRIR" -> "microsoft/DNS-Challenge"
"DavidDiazGuerra/gpuRIR" -> "RoyJames/room-impulse-responses"
"DavidDiazGuerra/gpuRIR" -> "aliutkus/speechmetrics"
"DavidDiazGuerra/gpuRIR" -> "yluo42/FRA-RIR"
"DavidDiazGuerra/gpuRIR" -> "Enny1991/beamformers"
"DavidDiazGuerra/gpuRIR" -> "fgnt/pb_bss"
"DavidDiazGuerra/gpuRIR" -> "naplab/Conv-TasNet"
"DiegoLeon96/Neural-Speech-Dereverberation" -> "zehuachenImperial/SkipConvNet"
"DiegoLeon96/Neural-Speech-Dereverberation" -> "flavioeverardo/erb_bands"
"csd111/dereverberation" -> "shamim-hussain/speech_dereverbaration_using_lp_residual"
"ehabets/RIR-Generator" -> "DavidDiazGuerra/gpuRIR"
"ehabets/RIR-Generator" -> "fgnt/nara_wpe"
"ehabets/RIR-Generator" -> "jzi040941/PercepNet"
"ehabets/RIR-Generator" -> "fgnt/nn-gev"
"ehabets/RIR-Generator" -> "LCAV/pyroomacoustics"
"ehabets/RIR-Generator" -> "microsoft/DNS-Challenge"
"ehabets/RIR-Generator" -> "microsoft/AEC-Challenge"
"ehabets/RIR-Generator" -> "athena-team/athena-signal"
"ehabets/RIR-Generator" -> "xanguera/BeamformIt"
"ehabets/RIR-Generator" -> "aliutkus/speechmetrics"
"ehabets/RIR-Generator" -> "yluo42/TAC"
"ehabets/RIR-Generator" -> "kaituoxu/Conv-TasNet"
"ehabets/RIR-Generator" -> "fgnt/pb_bss"
"ehabets/RIR-Generator" -> "Marvin182/rir-generator"
"ehabets/RIR-Generator" -> "Enny1991/beamformers"
"shamim-hussain/speech_dereverbaration_using_lp_residual" -> "csd111/dereverberation"
"zehuachenImperial/SkipConvNet" -> "DiegoLeon96/Neural-Speech-Dereverberation"
"pseeth/torch-stft" -> "huyanxin/phasen"
"pseeth/torch-stft" -> "funcwj/setk"
"pseeth/torch-stft" -> "naplab/Conv-TasNet"
"pseeth/torch-stft" -> "etzinis/two_step_mask_learning"
"pseeth/torch-stft" -> "mpariente/pytorch_stoi"
"pseeth/torch-stft" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"pseeth/torch-stft" -> "yluo42/TAC"
"pseeth/torch-stft" -> "ConferencingSpeech/ConferencingSpeech2021"
"bastamon/sound_signal_process-matlab-" -> "busyyang/python_sound_open"
"bastamon/sound_signal_process-matlab-" -> "JackHCC/Audio-Digital-Processing"
"bastamon/sound_signal_process-matlab-" -> "veenveenveen/SpeechSignalProcessingCourse"
"bastamon/sound_signal_process-matlab-" -> "taw19960426/-Speech-signal-processing-experiment-tutorial-_python"
"DoubangoTelecom/webrtc-audioproc" -> "xshl5/KOTI_AEC"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/FFTResampler"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/WebRTC_NS_CPP"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/AudioDenoise"
"markostam/active-noise-cancellation" -> "xiezhq-hermann/ANC_signal-system_project"
"markostam/active-noise-cancellation" -> "LiXirong/AdaptiveFilterandActiveNoiseCancellation"
"markostam/active-noise-cancellation" -> "sandprddy/Active-Noise-Cancellation-System"
"markostam/active-noise-cancellation" -> "xiph/speexdsp"
"markostam/active-noise-cancellation" -> "ewan-xu/pyaec"
"markostam/active-noise-cancellation" -> "psykulsk/RpiANC"
"markostam/active-noise-cancellation" -> "ZitengWang/MASP"
"markostam/active-noise-cancellation" -> "shichaog/WebRTC-audio-processing"
"markostam/active-noise-cancellation" -> "seanwood/gcc-nmf"
"markostam/active-noise-cancellation" -> "stephencwelch/Active-Noise-Cancellation"
"markostam/active-noise-cancellation" -> "Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation"
"markostam/active-noise-cancellation" -> "jtkim-kaist/Speech-enhancement"
"markostam/active-noise-cancellation" -> "acoular/acoular"
"markostam/active-noise-cancellation" -> "wangwei2009/DOA"
"markostam/active-noise-cancellation" -> "jzi040941/PercepNet"
"JusperLee/Calculate-SNR-SDR" -> "JusperLee/UtterancePIT-Speech-Separation"
"JusperLee/Calculate-SNR-SDR" -> "JusperLee/speech_separation"
"ewan-xu/pyaec" -> "jzi040941/PercepNet"
"ewan-xu/pyaec" -> "CharlesThaCat/acoustic-interference-cancellation"
"ewan-xu/pyaec" -> "breizhn/DTLN-aec"
"ewan-xu/pyaec" -> "fjiang9/NKF-AEC"
"ewan-xu/pyaec" -> "nay0648/unified2021"
"ewan-xu/pyaec" -> "microsoft/AEC-Challenge"
"ewan-xu/pyaec" -> "Turing311/Realtime_AudioDenoise_EchoCancellation"
"ewan-xu/pyaec" -> "ewan-xu/AEC3"
"ewan-xu/pyaec" -> "ZitengWang/MASP"
"ewan-xu/pyaec" -> "PandoraLS/traditional-speech-enhancement"
"ewan-xu/pyaec" -> "xiongyihui/speexdsp-python"
"ewan-xu/pyaec" -> "shichaog/WebRTC-audio-processing"
"ewan-xu/pyaec" -> "LXP-Never/AEC_DeepModel"
"athena-team/athena-signal" -> "funcwj/setk"
"athena-team/athena-signal" -> "kkumatani/distant_speech_recognition"
"athena-team/athena-signal" -> "microsoft/AEC-Challenge"
"athena-team/athena-signal" -> "jzi040941/PercepNet"
"athena-team/athena-signal" -> "shichaog/WebRTC-audio-processing"
"athena-team/athena-signal" -> "fgnt/nara_wpe"
"athena-team/athena-signal" -> "anicolson/DeepXi"
"athena-team/athena-signal" -> "robin1001/beamforming"
"athena-team/athena-signal" -> "Ryuk17/SpeechAlgorithms"
"athena-team/athena-signal" -> "huyanxin/DeepComplexCRN"
"athena-team/athena-signal" -> "ehabets/RIR-Generator"
"athena-team/athena-signal" -> "microsoft/DNS-Challenge"
"athena-team/athena-signal" -> "ewan-xu/AEC3"
"athena-team/athena-signal" -> "ZitengWang/MASP"
"athena-team/athena-signal" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "sandprddy/Active-Noise-Cancellation-System"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "markostam/active-noise-cancellation"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "xiezhq-hermann/ANC_signal-system_project"
"JusperLee/Deep-Clustering-for-Speech-Separation" -> "JusperLee/UtterancePIT-Speech-Separation"
"JusperLee/Deep-Clustering-for-Speech-Separation" -> "JusperLee/Conv-TasNet"
"JusperLee/Deep-Clustering-for-Speech-Separation" -> "JusperLee/Calculate-SNR-SDR"
"dodiku/noise_reduction" -> "ShinoharaYuuyoru/NoiseReductionUsingGRU"
"leftthomas/SEGAN" -> "santi-pdp/segan_pytorch"
"leftthomas/SEGAN" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"leftthomas/SEGAN" -> "JasonSWFu/MetricGAN"
"d-kitamura/ILRMA" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"d-kitamura/ILRMA" -> "d-kitamura/AuxIVA-ISS"
"ruizhecao96/CMGAN" -> "yuguochencuc/DB-AIAT"
"ruizhecao96/CMGAN" -> "sp-uhh/sgmse"
"ruizhecao96/CMGAN" -> "NVIDIA/CleanUNet"
"ruizhecao96/CMGAN" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"ruizhecao96/CMGAN" -> "Andong-Li-speech/TaylorSENet"
"sp-uhh/sgmse" -> "neillu23/CDiffuSE"
"sp-uhh/sgmse" -> "sp-uhh/storm"
"sp-uhh/sgmse" -> "ruizhecao96/CMGAN"
"sp-uhh/sgmse" -> "NVIDIA/CleanUNet"
"sp-uhh/sgmse" -> "felixfuyihui/Uformer"
"sp-uhh/sgmse" -> "yluo42/FRA-RIR"
"sp-uhh/sgmse" -> "DiegoLeon96/Neural-Speech-Dereverberation"
"sp-uhh/sgmse" -> "Andong-Li-speech/TaylorBeamformer"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "jzi040941/PercepNet"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "huyanxin/DeepComplexCRN"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "etzinis/sudo_rm_rf"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "vbelz/Speech-enhancement"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "ruizhecao96/CMGAN"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "breizhn/DTLN"
"introlab/odas" -> "introlab/odas_web"
"introlab/odas" -> "respeaker/mic_array"
"introlab/odas" -> "introlab/manyears"
"introlab/odas" -> "xanguera/BeamformIt"
"introlab/odas" -> "LCAV/pyroomacoustics"
"introlab/odas" -> "acoular/acoular"
"introlab/odas" -> "funcwj/setk"
"introlab/odas" -> "athena-team/athena-signal"
"introlab/odas" -> "robin1001/beamforming"
"introlab/odas" -> "wangwei2009/DOA"
"introlab/odas" -> "kkumatani/distant_speech_recognition"
"introlab/odas" -> "pchao6/Sound_Localization_Algorithms"
"introlab/odas" -> "seanwood/gcc-nmf"
"introlab/odas" -> "ZitengWang/MASP"
"introlab/odas" -> "voice-engine/make-a-smart-speaker"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "yluo42/TAC"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "ujscjj/DPTNet"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "JusperLee/Dual-Path-RNN-Pytorch"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "chenzhuo1011/libri_css"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "kaituoxu/Conv-TasNet"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "JorisCos/LibriMix"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "funcwj/conv-tasnet"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "xuchenglin28/speaker_extraction"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "chanil1218/DCUnet.pytorch"
"SuperKogito/spafe" -> "jzi040941/PercepNet"
"SuperKogito/spafe" -> "detly/gammatone"
"SuperKogito/spafe" -> "ZhihaoDU/speech_feature_extractor"
"SuperKogito/spafe" -> "KinWaiCheuk/nnAudio" ["e"=1]
"SuperKogito/spafe" -> "fgnt/nara_wpe"
"SuperKogito/spafe" -> "schmiph2/pysepm"
"SuperKogito/spafe" -> "jsingh811/pyAudioProcessing"
"SuperKogito/spafe" -> "Snowdar/asv-subtools" ["e"=1]
"SuperKogito/spafe" -> "pranaymanocha/PerceptualAudio"
"SuperKogito/spafe" -> "qiuqiangkong/torchlibrosa" ["e"=1]
"SuperKogito/spafe" -> "cvqluu/TDNN" ["e"=1]
"yluo42/TAC" -> "Enny1991/beamformers"
"yluo42/TAC" -> "yoonsanghyu/FaSNet-TAC-PyTorch"
"yluo42/TAC" -> "chenzhuo1011/libri_css"
"yluo42/TAC" -> "ujscjj/DPTNet"
"yluo42/TAC" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"yluo42/TAC" -> "xuchenglin28/speaker_extraction"
"yluo42/TAC" -> "fgnt/nn-gev"
"yluo42/TAC" -> "fgnt/pb_chime5"
"yluo42/TAC" -> "JusperLee/Dual-Path-RNN-Pytorch"
"yluo42/TAC" -> "kaituoxu/Conv-TasNet"
"yluo42/TAC" -> "DavidDiazGuerra/gpuRIR"
"yluo42/TAC" -> "speechLabBcCuny/onssen"
"yluo42/TAC" -> "yluo42/FRA-RIR"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_NS"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_VAD"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_AECM"
"cpuimage/rnnoise" -> "cpuimage/resampler"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_AGC"
"cpuimage/rnnoise" -> "cpuimage/AudioDenoise"
"cpuimage/rnnoise" -> "YongyuG/rnnoise_16k"
"cpuimage/rnnoise" -> "ZitengWang/MASP"
"cpuimage/rnnoise" -> "cpuimage/SimpleAudioDenoise"
"cpuimage/rnnoise" -> "kkumatani/distant_speech_recognition"
"cpuimage/rnnoise" -> "xiph/rnnoise"
"cpuimage/rnnoise" -> "cpuimage/FFTResampler"
"cpuimage/rnnoise" -> "jagger2048/rnnoise-windows"
"cpuimage/rnnoise" -> "athena-team/athena-signal"
"cpuimage/rnnoise" -> "orctom/rnnoise-java"
"KyleZhang1118/Voice-Separation-and-Enhancement" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"KyleZhang1118/Voice-Separation-and-Enhancement" -> "d-kitamura/AuxIVA-ISS"
"ZitengWang/MASP" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"ZitengWang/MASP" -> "fgnt/nn-gev"
"ZitengWang/MASP" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"ZitengWang/MASP" -> "nay0648/bssaec2020"
"ZitengWang/MASP" -> "kkumatani/distant_speech_recognition"
"ZitengWang/MASP" -> "DistantSpeechRecognition/mcse"
"ZitengWang/MASP" -> "funcwj/CGMM-MVDR"
"anicolson/DeepXi" -> "funcwj/setk"
"anicolson/DeepXi" -> "Wenzhe-Liu/awesome-speech-enhancement"
"anicolson/DeepXi" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"anicolson/DeepXi" -> "microsoft/DNS-Challenge"
"anicolson/DeepXi" -> "aliutkus/speechmetrics"
"anicolson/DeepXi" -> "fgnt/nara_wpe"
"anicolson/DeepXi" -> "santi-pdp/segan_pytorch"
"anicolson/DeepXi" -> "microsoft/MS-SNSD"
"anicolson/DeepXi" -> "yongxuUSTC/sednn"
"anicolson/DeepXi" -> "breizhn/DTLN"
"anicolson/DeepXi" -> "huyanxin/DeepComplexCRN"
"anicolson/DeepXi" -> "nanahou/Awesome-Speech-Enhancement"
"anicolson/DeepXi" -> "huyanxin/phasen"
"anicolson/DeepXi" -> "athena-team/athena-signal"
"anicolson/DeepXi" -> "vBaiCai/python-pesq"
"ewan-xu/AEC3" -> "breizhn/DTLN-aec"
"ewan-xu/AEC3" -> "microsoft/AEC-Challenge"
"ewan-xu/AEC3" -> "cpuimage/WebRTC_AECM"
"ewan-xu/AEC3" -> "Turing311/Realtime_AudioDenoise_EchoCancellation"
"ewan-xu/AEC3" -> "ewan-xu/pyaec"
"ewan-xu/AEC3" -> "shichaog/WebRTC-audio-processing"
"ewan-xu/AEC3" -> "wavesaudio/Speex-AEC-matlab"
"huyanxin/phasen" -> "huyanxin/DeepComplexCRN"
"huyanxin/phasen" -> "jzi040941/PercepNet"
"huyanxin/phasen" -> "funcwj/conv-tasnet"
"huyanxin/phasen" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"huyanxin/phasen" -> "haoxiangsnr/FullSubNet"
"huyanxin/phasen" -> "microsoft/DNS-Challenge"
"huyanxin/phasen" -> "microsoft/AEC-Challenge"
"huyanxin/phasen" -> "funcwj/setk"
"huyanxin/phasen" -> "anicolson/DeepXi"
"huyanxin/phasen" -> "maggie0830/DCCRN"
"huyanxin/phasen" -> "aliutkus/speechmetrics"
"huyanxin/phasen" -> "Wenzhe-Liu/awesome-speech-enhancement"
"huyanxin/phasen" -> "mpariente/pystoi"
"posenhuang/deeplearningsourceseparation" -> "pchao6/LSTM_PIT_Speech_Separation"
"posenhuang/deeplearningsourceseparation" -> "snsun/pit-speech-separation"
"posenhuang/deeplearningsourceseparation" -> "seanwood/gcc-nmf"
"posenhuang/deeplearningsourceseparation" -> "interactiveaudiolab/nussl"
"posenhuang/deeplearningsourceseparation" -> "amaas/rnn-speech-denoising"
"posenhuang/deeplearningsourceseparation" -> "MTG/DeepConvSep"
"posenhuang/deeplearningsourceseparation" -> "Unisound/SpeechSeparation"
"posenhuang/deeplearningsourceseparation" -> "posenhuang/singingvoiceseparationrpca"
"posenhuang/deeplearningsourceseparation" -> "craffel/mir_eval" ["e"=1]
"posenhuang/deeplearningsourceseparation" -> "funcwj/CGMM-MVDR"
"posenhuang/deeplearningsourceseparation" -> "fgnt/nara_wpe"
"posenhuang/deeplearningsourceseparation" -> "yongxuUSTC/sednn"
"posenhuang/deeplearningsourceseparation" -> "andabi/music-source-separation"
"posenhuang/deeplearningsourceseparation" -> "robin1001/beamforming"
"posenhuang/deeplearningsourceseparation" -> "drethage/speech-denoising-wavenet"
"seanwood/gcc-nmf" -> "funcwj/setk"
"seanwood/gcc-nmf" -> "funcwj/CGMM-MVDR"
"seanwood/gcc-nmf" -> "pchao6/LSTM_PIT_Speech_Separation"
"seanwood/gcc-nmf" -> "fgnt/pb_bss"
"seanwood/gcc-nmf" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"seanwood/gcc-nmf" -> "fgnt/nn-gev"
"seanwood/gcc-nmf" -> "speechLabBcCuny/onssen"
"seanwood/gcc-nmf" -> "sekiguchi92/SoundSourceSeparation"
"seanwood/gcc-nmf" -> "ZitengWang/MASP"
"seanwood/gcc-nmf" -> "anicolson/DeepXi"
"seanwood/gcc-nmf" -> "posenhuang/deeplearningsourceseparation"
"seanwood/gcc-nmf" -> "xanguera/BeamformIt"
"seanwood/gcc-nmf" -> "Wenzhe-Liu/awesome-speech-enhancement"
"seanwood/gcc-nmf" -> "DistantSpeechRecognition/mcse"
"seanwood/gcc-nmf" -> "yongxuUSTC/sednn"
"xiongyihui/python-webrtc-audio-processing" -> "xiongyihui/speexdsp-python"
"xiongyihui/python-webrtc-audio-processing" -> "kkumatani/distant_speech_recognition"
"xiongyihui/python-webrtc-audio-processing" -> "wavesaudio/Speex-AEC-matlab"
"xiongyihui/python-webrtc-audio-processing" -> "shichaog/WebRTC-audio-processing"
"xiongyihui/python-webrtc-audio-processing" -> "snsun/cgmm_mvdr"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "hyli666/DNN-SpeechEnhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "yongxuUSTC/sednn"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "jtkim-kaist/Speech-enhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "santi-pdp/segan"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "leftthomas/SEGAN"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "jonlu0602/DeepDenoisingAutoencoder"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "yongxuUSTC/DNN-for-speech-enhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "auspicious3000/WaveNet-Enhancement"
"gionanide/Speech_Signal_Processing_and_Classification" -> "ZhihaoDU/speech_feature_extractor"
"gionanide/Speech_Signal_Processing_and_Classification" -> "gionanide/Neural_Machine_Translation"
"Zhangtingyuxuan/AcousticFeatureExtraction" -> "Zhangtingyuxuan/voice_activity_detection"
"Zhangtingyuxuan/voice_activity_detection" -> "Zhangtingyuxuan/AcousticFeatureExtraction"
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"seorim0/DCCRN-with-various-loss-functions" -> "felixfuyihui/Uformer"
"speechLabBcCuny/onssen" -> "mpariente/AsSteroid"
"speechLabBcCuny/onssen" -> "funcwj/setk"
"speechLabBcCuny/onssen" -> "yluo42/TAC"
"speechLabBcCuny/onssen" -> "chenzhuo1011/libri_css"
"speechLabBcCuny/onssen" -> "fgnt/pb_bss"
"speechLabBcCuny/onssen" -> "pchao6/LSTM_PIT_Speech_Separation"
"speechLabBcCuny/onssen" -> "fgnt/sms_wsj"
"speechLabBcCuny/onssen" -> "etzinis/two_step_mask_learning"
"speechLabBcCuny/onssen" -> "seanwood/gcc-nmf"
"speechLabBcCuny/onssen" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"speechLabBcCuny/onssen" -> "mpariente/asteroid"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "funcwj/CGMM-MVDR"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "fgnt/nn-gev"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "snsun/cgmm_mvdr"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "Enny1991/beamformers"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "aishoot/Sound_Localization_Algorithms"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "huangzhenyu/beamforming"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "funcwj/setk"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "DistantSpeechRecognition/mcse"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "funcwj/cgmm-mask-estimator"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "ZitengWang/MASP"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "fgnt/nara_wpe"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "chenwj1989/Beamforming_Examples"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "xanguera/BeamformIt"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "yluo42/TAC"
"fakufaku/fast_bss_eval" -> "fakufaku/torchiva"
"fakufaku/fast_bss_eval" -> "fgnt/ci_sdr"
"fakufaku/fast_bss_eval" -> "tky823/ssspy"
"funcwj/CGMM-MVDR" -> "funcwj/cgmm-mask-estimator"
"funcwj/CGMM-MVDR" -> "snsun/cgmm_mvdr"
"funcwj/CGMM-MVDR" -> "fgnt/nn-gev"
"funcwj/CGMM-MVDR" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"funcwj/CGMM-MVDR" -> "xanguera/BeamformIt"
"funcwj/CGMM-MVDR" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"funcwj/CGMM-MVDR" -> "DistantSpeechRecognition/mcse"
"funcwj/CGMM-MVDR" -> "funcwj/setk"
"funcwj/CGMM-MVDR" -> "gogyzzz/beamformit_matlab"
"funcwj/CGMM-MVDR" -> "chenwj1989/Beamforming_Examples"
"funcwj/cgmm-mask-estimator" -> "funcwj/CGMM-MVDR"
"funcwj/cgmm-mask-estimator" -> "snsun/cgmm_mvdr"
"funcwj/cgmm-mask-estimator" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"sekiguchi92/SoundSourceSeparation" -> "nay0648/unified2021"
"sekiguchi92/SoundSourceSeparation" -> "nttcslab-sp/dnn_wpe"
"sekiguchi92/SoundSourceSeparation" -> "echocatzh/MTFAA-Net"
"sekiguchi92/SoundSourceSeparation" -> "wangtianrui/HGCN"
"snsun/cgmm_mvdr" -> "funcwj/cgmm-mask-estimator"
"snsun/cgmm_mvdr" -> "funcwj/CGMM-MVDR"
"snsun/cgmm_mvdr" -> "fgnt/nn-gev"
"tky823/ssspy" -> "onolab-tmu/libss"
"naplab/DANet" -> "funcwj/deep-clustering"
"naplab/DANet" -> "funcwj/uPIT-for-speech-separation"
"naplab/DANet" -> "khaotik/DaNet-Tensorflow"
"jonlu0602/DeepDenoisingAutoencoder" -> "WilliamYu1993/ICSE"
"acoular/acoular" -> "xanguera/BeamformIt"
"acoular/acoular" -> "robin1001/beamforming"
"acoular/acoular" -> "jorgengrythe/beamforming"
"acoular/acoular" -> "ZitengWang/MASP"
"acoular/acoular" -> "kkumatani/distant_speech_recognition"
"acoular/acoular" -> "LCAV/pyroomacoustics"
"acoular/acoular" -> "funcwj/CGMM-MVDR"
"acoular/acoular" -> "fgnt/nara_wpe"
"acoular/acoular" -> "respeaker/mic_array"
"acoular/acoular" -> "athena-team/athena-signal"
"acoular/acoular" -> "seanwood/gcc-nmf"
"acoular/acoular" -> "introlab/odas"
"acoular/acoular" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"acoular/acoular" -> "funcwj/cgmm-mask-estimator"
"acoular/acoular" -> "jzi040941/PercepNet"
"AppleHolic/source_separation" -> "sweetcocoa/DeepComplexUNetPyTorch"
"AppleHolic/source_separation" -> "chanil1218/DCUnet.pytorch"
"AppleHolic/source_separation" -> "tky823/DNN-based_source_separation"
"AppleHolic/source_separation" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"AppleHolic/source_separation" -> "funcwj/setk"
"AppleHolic/source_separation" -> "speechLabBcCuny/onssen"
"AppleHolic/source_separation" -> "huyanxin/phasen"
"AppleHolic/source_separation" -> "aliutkus/speechmetrics"
"AppleHolic/source_separation" -> "huyanxin/DeepComplexCRN"
"AppleHolic/source_separation" -> "funcwj/conv-tasnet"
"AppleHolic/source_separation" -> "haoxiangsnr/FullSubNet"
"AppleHolic/source_separation" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"AppleHolic/source_separation" -> "AppleHolic/pytorch_sound"
"AppleHolic/source_separation" -> "ludlows/python-pesq"
"AppleHolic/source_separation" -> "microsoft/DNS-Challenge"
"sunits/rir_simulator_python" -> "jonashaag/RealRIRs"
"TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques" -> "d-kitamura/ILRMA"
"chanil1218/DCUnet.pytorch" -> "maggie0830/DCCRN"
"chanil1218/DCUnet.pytorch" -> "chanil1218/Attention-SE.pytorch"
"funcwj/aps" -> "felixfuyihui/Uformer"
"funcwj/aps" -> "funcwj/setk"
"google/visqol" -> "aliutkus/speechmetrics"
"google/visqol" -> "gabrielmittag/NISQA"
"google/visqol" -> "pranaymanocha/PerceptualAudio"
"google/visqol" -> "ludlows/python-pesq"
"google/visqol" -> "microsoft/DNS-Challenge"
"google/visqol" -> "microsoft/AEC-Challenge"
"google/visqol" -> "jzi040941/PercepNet"
"google/visqol" -> "huyanxin/DeepComplexCRN"
"google/visqol" -> "facebookresearch/WavAugment" ["e"=1]
"google/visqol" -> "lochenchou/MOSNet"
"google/visqol" -> "microsoft/MS-SNSD"
"google/visqol" -> "fgnt/nara_wpe"
"google/visqol" -> "huyanxin/phasen"
"google/visqol" -> "mozilla/LPCNet" ["e"=1]
"google/visqol" -> "jik876/hifi-gan" ["e"=1]
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "huyanxin/DeepComplexCRN"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "anicolson/DeepXi"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "huyanxin/phasen"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "Wenzhe-Liu/awesome-speech-enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "microsoft/MS-SNSD"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "maggie0830/DCCRN"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "haoxiangsnr/FullSubNet"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "vbelz/Speech-enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "JupiterEthan/GCRN-complex"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "vbelz/Speech-enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "santi-pdp/segan_pytorch"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "anicolson/DeepXi"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "JasonSWFu/MetricGAN"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "f90/Wave-U-Net-Pytorch"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "yongxuUSTC/sednn"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "schmiph2/pysepm"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "funcwj/setk"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "huyanxin/phasen"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "Wenzhe-Liu/awesome-speech-enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"introlab/manyears" -> "kkumatani/distant_speech_recognition"
"introlab/manyears" -> "introlab/odas"
"introlab/manyears" -> "pchao6/Sound_Localization_Algorithms"
"introlab/manyears" -> "LeeTaewoo/TL-SSC_SRP-PHAT"
"introlab/manyears" -> "xanguera/BeamformIt"
"introlab/manyears" -> "LeeTaewoo/fast_sound_source_localization_using_TLSSC"
"introlab/manyears" -> "xiaoli1368/Microphone-sound-source-localization"
"introlab/manyears" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"introlab/manyears" -> "robin1001/beamforming"
"introlab/manyears" -> "Wenzhe-Liu/awesome-speech-enhancement"
"kkumatani/distant_speech_recognition" -> "robin1001/beamforming"
"kkumatani/distant_speech_recognition" -> "helianvine/fdndlp"
"kkumatani/distant_speech_recognition" -> "fgnt/nara_wpe"
"kkumatani/distant_speech_recognition" -> "xanguera/BeamformIt"
"kkumatani/distant_speech_recognition" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"kkumatani/distant_speech_recognition" -> "athena-team/athena-signal"
"kkumatani/distant_speech_recognition" -> "ZitengWang/MASP"
"kkumatani/distant_speech_recognition" -> "pchao6/Sound_Localization_Algorithms"
"kkumatani/distant_speech_recognition" -> "fgnt/nn-gev"
"kkumatani/distant_speech_recognition" -> "microsoft/AEC-Challenge"
"kkumatani/distant_speech_recognition" -> "wavesaudio/Speex-AEC-matlab"
"kkumatani/distant_speech_recognition" -> "huangzhenyu/beamforming"
"kkumatani/distant_speech_recognition" -> "funcwj/CGMM-MVDR"
"kkumatani/distant_speech_recognition" -> "snsun/cgmm_mvdr"
"kkumatani/distant_speech_recognition" -> "nttcslab-sp/dnn_wpe"
"nttcslab-sp/dnn_wpe" -> "sekiguchi92/SoundSourceSeparation"
"pchao6/Sound_Localization_Algorithms" -> "kkumatani/distant_speech_recognition"
"pchao6/Sound_Localization_Algorithms" -> "xiaoli1368/Microphone-sound-source-localization"
"pchao6/Sound_Localization_Algorithms" -> "xanguera/BeamformIt"
"pchao6/Sound_Localization_Algorithms" -> "jorgengrythe/beamforming"
"pchao6/Sound_Localization_Algorithms" -> "ZitengWang/MASP"
"pchao6/Sound_Localization_Algorithms" -> "funcwj/CGMM-MVDR"
"pchao6/Sound_Localization_Algorithms" -> "wangwei2009/DOA"
"pchao6/Sound_Localization_Algorithms" -> "introlab/manyears"
"singaxiong/SignalGraph" -> "fgnt/nn-gev"
"xanguera/BeamformIt" -> "fgnt/nn-gev"
"xanguera/BeamformIt" -> "robin1001/beamforming"
"xanguera/BeamformIt" -> "funcwj/CGMM-MVDR"
"xanguera/BeamformIt" -> "kkumatani/distant_speech_recognition"
"xanguera/BeamformIt" -> "snsun/cgmm_mvdr"
"xanguera/BeamformIt" -> "acoular/acoular"
"xanguera/BeamformIt" -> "funcwj/setk"
"xanguera/BeamformIt" -> "funcwj/cgmm-mask-estimator"
"xanguera/BeamformIt" -> "fgnt/nara_wpe"
"xanguera/BeamformIt" -> "ehabets/RIR-Generator"
"xanguera/BeamformIt" -> "pchao6/Sound_Localization_Algorithms"
"xanguera/BeamformIt" -> "Enny1991/beamformers"
"xanguera/BeamformIt" -> "seanwood/gcc-nmf"
"xanguera/BeamformIt" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"xanguera/BeamformIt" -> "shichaog/WebRTC-audio-processing"
"yongxuUSTC/DNN-Speech-enhancement-demo-tool" -> "yongxuUSTC/DNN-for-speech-enhancement"
"yongxuUSTC/DNN-Speech-enhancement-demo-tool" -> "hyli666/DNN-SpeechEnhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"yongxuUSTC/DNN-for-speech-enhancement" -> "hyli666/DNN-SpeechEnhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "yongxuUSTC/sednn"
"yongxuUSTC/DNN-for-speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"yongxuUSTC/DNN-for-speech-enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "jtkim-kaist/Speech-enhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "santi-pdp/segan"
"yongxuUSTC/DNN-for-speech-enhancement" -> "helianvine/fdndlp"
"yongxuUSTC/DNN-for-speech-enhancement" -> "seanwood/gcc-nmf"
"Audio-WestlakeU/NBSS" -> "yluo42/FRA-RIR"
"tky823/DNN-based_source_separation" -> "tky823/audio_source_separation"
"tky823/DNN-based_source_separation" -> "naplab/Conv-TasNet"
"tky823/DNN-based_source_separation" -> "gemengtju/Tutorial_Separation"
"tky823/DNN-based_source_separation" -> "etzinis/sudo_rm_rf"
"tky823/DNN-based_source_separation" -> "ujscjj/DPTNet"
"tky823/DNN-based_source_separation" -> "nussl/nussl" ["e"=1]
"tky823/DNN-based_source_separation" -> "sekiguchi92/SoundSourceSeparation"
"tky823/DNN-based_source_separation" -> "yluo42/TAC"
"tky823/DNN-based_source_separation" -> "ws-choi/Conditioned-Source-Separation-LaSAFT" ["e"=1]
"aliutkus/speechmetrics" -> "lochenchou/MOSNet"
"aliutkus/speechmetrics" -> "vBaiCai/python-pesq"
"aliutkus/speechmetrics" -> "ludlows/python-pesq"
"aliutkus/speechmetrics" -> "schmiph2/pysepm"
"aliutkus/speechmetrics" -> "gabrielmittag/NISQA"
"aliutkus/speechmetrics" -> "microsoft/DNS-Challenge"
"aliutkus/speechmetrics" -> "mpariente/pystoi"
"aliutkus/speechmetrics" -> "anicolson/DeepXi"
"aliutkus/speechmetrics" -> "fgnt/nara_wpe"
"aliutkus/speechmetrics" -> "jzi040941/PercepNet"
"aliutkus/speechmetrics" -> "nanahou/Awesome-Speech-Enhancement"
"aliutkus/speechmetrics" -> "google/visqol"
"aliutkus/speechmetrics" -> "huyanxin/phasen"
"aliutkus/speechmetrics" -> "facebookresearch/WavAugment" ["e"=1]
"aliutkus/speechmetrics" -> "LCAV/pyroomacoustics"
"fgnt/nn-gev" -> "funcwj/CGMM-MVDR"
"fgnt/nn-gev" -> "Enny1991/beamformers"
"fgnt/nn-gev" -> "xanguera/BeamformIt"
"fgnt/nn-gev" -> "funcwj/setk"
"fgnt/nn-gev" -> "snsun/cgmm_mvdr"
"fgnt/nn-gev" -> "funcwj/cgmm-mask-estimator"
"fgnt/nn-gev" -> "DistantSpeechRecognition/mcse"
"fgnt/nn-gev" -> "fgnt/pb_bss"
"fgnt/nn-gev" -> "nttcslab-sp/dnn_wpe"
"fgnt/nn-gev" -> "fgnt/pb_chime5"
"fgnt/nn-gev" -> "ZitengWang/MASP"
"fgnt/nn-gev" -> "ZitengWang/nn_mask"
"fgnt/nn-gev" -> "fgnt/nara_wpe"
"fgnt/nn-gev" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"fgnt/nn-gev" -> "ConferencingSpeech/ConferencingSpeech2021"
"robin1001/beamforming" -> "kkumatani/distant_speech_recognition"
"robin1001/beamforming" -> "xanguera/BeamformIt"
"robin1001/beamforming" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"robin1001/beamforming" -> "xiongyihui/tdoa"
"robin1001/beamforming" -> "snsun/cgmm_mvdr"
"robin1001/beamforming" -> "wavesaudio/Speex-AEC-matlab"
"robin1001/beamforming" -> "wangwei2009/DOA"
"robin1001/beamforming" -> "DistantSpeechRecognition/mcse"
"robin1001/beamforming" -> "ZitengWang/MASP"
"robin1001/beamforming" -> "funcwj/cgmm-mask-estimator"
"robin1001/beamforming" -> "willhope/Noise-reduction" ["e"=1]
"naplab/Conv-TasNet" -> "funcwj/conv-tasnet"
"naplab/Conv-TasNet" -> "kaituoxu/Conv-TasNet"
"naplab/Conv-TasNet" -> "JusperLee/Conv-TasNet"
"naplab/Conv-TasNet" -> "yluo42/TAC"
"naplab/Conv-TasNet" -> "tky823/DNN-based_source_separation"
"naplab/Conv-TasNet" -> "huyanxin/phasen"
"naplab/Conv-TasNet" -> "microsoft/DNS-Challenge"
"naplab/Conv-TasNet" -> "Enny1991/beamformers"
"naplab/Conv-TasNet" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"naplab/Conv-TasNet" -> "JorisCos/LibriMix"
"naplab/Conv-TasNet" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"naplab/Conv-TasNet" -> "aliutkus/speechmetrics"
"naplab/Conv-TasNet" -> "ujscjj/DPTNet"
"naplab/Conv-TasNet" -> "speechLabBcCuny/onssen"
"naplab/Conv-TasNet" -> "fgnt/nn-gev"
"breizhn/DTLN" -> "breizhn/DTLN-aec"
"breizhn/DTLN" -> "jzi040941/PercepNet"
"breizhn/DTLN" -> "haoxiangsnr/FullSubNet"
"breizhn/DTLN" -> "huyanxin/DeepComplexCRN"
"breizhn/DTLN" -> "microsoft/DNS-Challenge"
"breizhn/DTLN" -> "microsoft/AEC-Challenge"
"breizhn/DTLN" -> "Turing311/Realtime_AudioDenoise_EchoCancellation"
"breizhn/DTLN" -> "anicolson/DeepXi"
"breizhn/DTLN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"breizhn/DTLN" -> "facebookresearch/denoiser"
"breizhn/DTLN" -> "Wenzhe-Liu/awesome-speech-enhancement"
"breizhn/DTLN" -> "nanahou/Awesome-Speech-Enhancement"
"breizhn/DTLN" -> "microsoft/MS-SNSD"
"breizhn/DTLN" -> "maggie0830/DCCRN"
"breizhn/DTLN" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"nii-yamagishilab/mos-finetune-ssl" -> "dhimasryan/MOSA-Net-Cross-Domain"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JusperLee/Conv-TasNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"JusperLee/Dual-Path-RNN-Pytorch" -> "kaituoxu/Conv-TasNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"JusperLee/Dual-Path-RNN-Pytorch" -> "yluo42/TAC"
"JusperLee/Dual-Path-RNN-Pytorch" -> "gemengtju/Tutorial_Separation"
"JusperLee/Dual-Path-RNN-Pytorch" -> "naplab/Conv-TasNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "ujscjj/DPTNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "xuchenglin28/speaker_extraction"
"JusperLee/Dual-Path-RNN-Pytorch" -> "Wenzhe-Liu/awesome-speech-enhancement"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JusperLee/Looking-to-Listen-at-the-Cocktail-Party" ["e"=1]
"JusperLee/Dual-Path-RNN-Pytorch" -> "jzi040941/PercepNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "huyanxin/DeepComplexCRN"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JorisCos/LibriMix"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JusperLee/Deep-Clustering-for-Speech-Separation"
"lochenchou/MOSNet" -> "aliutkus/speechmetrics"
"lochenchou/MOSNet" -> "gabrielmittag/NISQA"
"lochenchou/MOSNet" -> "JasonSWFu/Quality-Net"
"lochenchou/MOSNet" -> "k2kobayashi/crank" ["e"=1]
"lochenchou/MOSNet" -> "nii-yamagishilab/multi-speaker-tacotron" ["e"=1]
"lochenchou/MOSNet" -> "nii-yamagishilab/mos-finetune-ssl"
"JesperDramsch/keras-complex" -> "NEGU93/cvnn"
"JesperDramsch/keras-complex" -> "MRSRL/complex-networks-release"
"JesperDramsch/keras-complex" -> "JesperDramsch/Complex-CNN-Seismic"
"JesperDramsch/keras-complex" -> "ivannz/cplxmodule"
"JesperDramsch/keras-complex" -> "ChihebTrabelsi/deep_complex_networks"
"JesperDramsch/keras-complex" -> "wavefrontshaping/complexPyTorch"
"garyyu/WebRTC_VoiceEngine" -> "xshl5/KOTI_AEC"
"garyyu/WebRTC_VoiceEngine" -> "DoubangoTelecom/webrtc-audioproc"
"morriswmz/doatools.py" -> "morriswmz/doa-tools"
"morriswmz/doatools.py" -> "petotamas/pyArgus"
"morriswmz/doatools.py" -> "dengjunquan/DoA-Estimation-MUSIC-ESPRIT"
"morriswmz/doatools.py" -> "LCAV/FRIDA"
"Max-Manning/passiveRadar" -> "jmfriedt/passive_radar"
"Max-Manning/passiveRadar" -> "rtlsdrblog/kerberossdr"
"msamsami/doa-estimation-music" -> "morriswmz/doa-tools"
"msamsami/doa-estimation-music" -> "xuchenglin28/WSCM-MUSIC"
"msamsami/doa-estimation-music" -> "chenhui07c8/DOA-AOA-algorithms"
"JasonSWFu/MetricGAN" -> "jonlu0602/DeepDenoisingAutoencoder"
"JasonSWFu/MetricGAN" -> "Zihang97/PAGAN"
"JasonSWFu/MetricGAN" -> "aleXiehta/PhoneFortifiedPerceptualLoss"
"JasonSWFu/MetricGAN" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"JasonSWFu/MetricGAN" -> "leftthomas/SEGAN"
"JasonSWFu/MetricGAN" -> "vBaiCai/python-pesq"
"JasonSWFu/MetricGAN" -> "WilliamYu1993/ICSE"
"amaas/rnn-speech-denoising" -> "posenhuang/deeplearningsourceseparation"
"amaas/rnn-speech-denoising" -> "zhr1201/OMLSA-speech-enhancement"
"asappresearch/sru" -> "bamtercelboo/pytorch_SRU"
"asappresearch/sru" -> "haoxiangsnr/FullSubNet"
"asappresearch/sru" -> "lmnt-com/haste"
"asappresearch/sru" -> "microsoft/fastformers" ["e"=1]
"asappresearch/sru" -> "idiap/fast-transformers" ["e"=1]
"asappresearch/sru" -> "facebookresearch/WavAugment" ["e"=1]
"asappresearch/sru" -> "guolinke/TUPE" ["e"=1]
"asappresearch/sru" -> "microsoft/AEC-Challenge"
"asappresearch/sru" -> "huyanxin/DeepComplexCRN"
"asappresearch/sru" -> "google-research/long-range-arena" ["e"=1]
"asappresearch/sru" -> "hirofumi0810/neural_sp" ["e"=1]
"asappresearch/sru" -> "anicolson/DeepXi"
"asappresearch/sru" -> "kaituoxu/Speech-Transformer" ["e"=1]
"cpuimage/resampler" -> "cpuimage/FFTResampler"
"cpuimage/resampler" -> "cpuimage/WebRTC_AECM"
"cpuimage/resampler" -> "cpuimage/WebRTC_AGC"
"cpuimage/resampler" -> "cpuimage/WebRTC_VAD"
"shichaog/WebRTC-audio-processing" -> "athena-team/athena-signal"
"shichaog/WebRTC-audio-processing" -> "wavesaudio/Speex-AEC-matlab"
"shichaog/WebRTC-audio-processing" -> "ewan-xu/AEC3"
"shichaog/WebRTC-audio-processing" -> "microsoft/AEC-Challenge"
"shichaog/WebRTC-audio-processing" -> "robin1001/beamforming"
"shichaog/WebRTC-audio-processing" -> "ewan-xu/pyaec"
"shichaog/WebRTC-audio-processing" -> "shichaog/RNNAec"
"shichaog/WebRTC-audio-processing" -> "jzi040941/PercepNet"
"shichaog/WebRTC-audio-processing" -> "xanguera/BeamformIt"
"shichaog/WebRTC-audio-processing" -> "cpuimage/WebRTC_AECM"
"shichaog/WebRTC-audio-processing" -> "ZitengWang/MASP"
"shichaog/WebRTC-audio-processing" -> "YangangCao/WebRTC-3A1V"
"shichaog/WebRTC-audio-processing" -> "lifeiteng/codingmath"
"shichaog/WebRTC-audio-processing" -> "xiongyihui/python-webrtc-audio-processing"
"shichaog/WebRTC-audio-processing" -> "xiongyihui/speexdsp-python"
"introlab/odas_web" -> "introlab/odas"
"introlab/odas_web" -> "introlab/16SoundsUSB"
"voice-engine/voice-engine" -> "respeaker/mic_array"
"voice-engine/voice-engine" -> "respeaker/seeed-voicecard"
"voice-engine/voice-engine" -> "respeaker/mic_hat"
"voice-engine/voice-engine" -> "voice-engine/make-a-smart-speaker"
"voice-engine/voice-engine" -> "respeaker/avs" ["e"=1]
"voice-engine/voice-engine" -> "voice-engine/ec"
"yechengxi/LightNet" -> "huashiyiqike/LSTM-MATLAB"
"yechengxi/LightNet" -> "yechengxi/LightCapsNet"
"yechengxi/LightNet" -> "JianboTang/RNN_MATLAB"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_VAD"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_AGC"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_NS"
"cpuimage/WebRTC_AECM" -> "ewan-xu/AEC3"
"cpuimage/WebRTC_AECM" -> "cpuimage/resampler"
"cpuimage/WebRTC_AECM" -> "Turing311/Realtime_AudioDenoise_EchoCancellation"
"cpuimage/WebRTC_AECM" -> "YangangCao/WebRTC-3A1V"
"cpuimage/WebRTC_AECM" -> "wavesaudio/Speex-AEC-matlab"
"cpuimage/WebRTC_AECM" -> "DoubangoTelecom/webrtc-audioproc"
"cpuimage/WebRTC_AECM" -> "LXP-Never/AEC_DeepModel"
"cpuimage/WebRTC_AECM" -> "xshl5/KOTI_AEC"
"cpuimage/WebRTC_AECM" -> "shichaog/WebRTC-audio-processing"
"MRSRL/complex-networks-release" -> "CedricChing/DeepMRI" ["e"=1]
"MRSRL/complex-networks-release" -> "MRSRL/dl-cs"
"MRSRL/complex-networks-release" -> "VLOGroup/mri-variationalnetwork" ["e"=1]
"MRSRL/complex-networks-release" -> "khammernik/sigmanet" ["e"=1]
"MRSRL/complex-networks-release" -> "hossam-elrewaidy/urus-mri-recon"
"ivannz/cplxmodule" -> "wavefrontshaping/complexPyTorch"
"ivannz/cplxmodule" -> "MRSRL/complex-networks-release"
"fakufaku/torchiva" -> "yluo42/FRA-RIR"
"fakufaku/torchiva" -> "fakufaku/piva"
"GregorR/rnnoise-models" -> "GregorR/rnnoise-nu"
"GregorR/rnnoise-models" -> "jagger2048/rnnoise-windows"
"detly/gammatone" -> "bingo-todd/Gammatone-filters"
"detly/gammatone" -> "ZhihaoDU/speech_feature_extractor"
"mpariente/pystoi" -> "vBaiCai/python-pesq"
"mpariente/pystoi" -> "ludlows/python-pesq"
"mpariente/pystoi" -> "aliutkus/speechmetrics"
"mpariente/pystoi" -> "schmiph2/pysepm"
"mpariente/pystoi" -> "jfsantos/SRMRpy"
"mpariente/pystoi" -> "huyanxin/phasen"
"mpariente/pystoi" -> "mpariente/pytorch_stoi"
"mpariente/pystoi" -> "DavidDiazGuerra/gpuRIR"
"mpariente/pystoi" -> "anicolson/DeepXi"
"mpariente/pystoi" -> "JasonSWFu/MetricGAN"
"mpariente/pystoi" -> "fgnt/nara_wpe"
"mpariente/pystoi" -> "haoxiangsnr/FullSubNet"
"mpariente/pystoi" -> "santi-pdp/segan_pytorch"
"mpariente/pystoi" -> "ujscjj/DPTNet"
"mpariente/pystoi" -> "pchao6/LSTM_PIT_Speech_Separation"
"sweetcocoa/DeepComplexUNetPyTorch" -> "chanil1218/DCUnet.pytorch"
"sweetcocoa/DeepComplexUNetPyTorch" -> "litcoderr/ComplexCNN"
"sweetcocoa/DeepComplexUNetPyTorch" -> "AppleHolic/source_separation"
"sweetcocoa/DeepComplexUNetPyTorch" -> "huyanxin/DeepComplexCRN"
"sweetcocoa/DeepComplexUNetPyTorch" -> "maggie0830/DCCRN"
"respeaker/usb_4_mic_array" -> "furushchev/respeaker_ros"
"respeaker/mic_array" -> "voice-engine/voice-engine"
"respeaker/mic_array" -> "introlab/odas"
"respeaker/mic_array" -> "xiongyihui/tdoa"
"respeaker/mic_array" -> "respeaker/seeed-voicecard"
"respeaker/mic_array" -> "voice-engine/ec"
"respeaker/mic_array" -> "robin1001/beamforming"
"respeaker/mic_array" -> "wangwei2009/DOA"
"respeaker/mic_array" -> "acoular/acoular"
"respeaker/mic_array" -> "respeaker/respeaker_python_library"
"respeaker/mic_array" -> "respeaker/usb_4_mic_array"
"respeaker/mic_array" -> "voice-engine/make-a-smart-speaker"
"respeaker/mic_array" -> "xanguera/BeamformIt"
"respeaker/mic_array" -> "morriswmz/doa-tools"
"respeaker/mic_array" -> "LCAV/pyroomacoustics"
"respeaker/mic_array" -> "funcwj/setk"
"huashiyiqike/LSTM-MATLAB" -> "yechengxi/LightNet"
"huashiyiqike/LSTM-MATLAB" -> "JianboTang/RNN_MATLAB"
"huashiyiqike/LSTM-MATLAB" -> "singaxiong/SignalGraph"
"huashiyiqike/LSTM-MATLAB" -> "cwxcode/LSTM-matlab"
"huashiyiqike/LSTM-MATLAB" -> "huashiyiqike/NETLAB"
"huashiyiqike/LSTM-MATLAB" -> "SunQilin/lstm_matlab"
"huashiyiqike/LSTM-MATLAB" -> "jimmy-ren/vLSTM"
"dr-costas/mad-twinnet" -> "Js-Mim/mss_pytorch"
"snsun/pit-speech-separation" -> "Unisound/SpeechSeparation"
"snsun/pit-speech-separation" -> "pchao6/LSTM_PIT_Speech_Separation"
"snsun/pit-speech-separation" -> "khaotik/DaNet-Tensorflow"
"snsun/pit-speech-separation" -> "funcwj/uPIT-for-speech-separation"
"snsun/pit-speech-separation" -> "zhr1201/deep-clustering"
"snsun/pit-speech-separation" -> "funcwj/deep-clustering"
"zhr1201/deep-clustering" -> "funcwj/deep-clustering"
"zhr1201/deep-clustering" -> "jcsilva/deep-clustering"
"zhr1201/deep-clustering" -> "khaotik/DaNet-Tensorflow"
"zhr1201/deep-clustering" -> "pchao6/LSTM_PIT_Speech_Separation"
"zhr1201/deep-clustering" -> "naplab/DANet"
"zhr1201/deep-clustering" -> "snsun/pit-speech-separation"
"zhr1201/deep-clustering" -> "Unisound/SpeechSeparation"
"zhr1201/deep-clustering" -> "chaodengusc/DeWave"
"zhr1201/deep-clustering" -> "funcwj/uPIT-for-speech-separation"
"DistantSpeechRecognition/mcse" -> "fgnt/nn-gev"
"DistantSpeechRecognition/mcse" -> "funcwj/CGMM-MVDR"
"DistantSpeechRecognition/mcse" -> "ZitengWang/MASP"
"DistantSpeechRecognition/mcse" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"DistantSpeechRecognition/mcse" -> "helianvine/fdndlp"
"Enny1991/beamformers" -> "yluo42/TAC"
"Enny1991/beamformers" -> "fgnt/nn-gev"
"Enny1991/beamformers" -> "yoonsanghyu/FaSNet-TAC-PyTorch"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "jgarciagimenez/GSC_beamforming"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "XiaoxiangGao/Dual_mic_phase_based_speech_enhancement"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "funcwj/cgmm-mask-estimator"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "satyanamuduri/Speech-Enhancement-Using-GSC"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "funcwj/CGMM-MVDR"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "Akki369/Generalised-Side-Lobe-Canceller"
"nay0648/unified2021" -> "felixfuyihui/Uformer"
"nay0648/unified2021" -> "echocatzh/py-aec-unified2021"
"nay0648/unified2021" -> "sekiguchi92/SoundSourceSeparation"
"ConferencingSpeech/ConferencingSpeech2021" -> "echocatzh/MTFAA-Net"
"ConferencingSpeech/ConferencingSpeech2021" -> "yluo42/FRA-RIR"
"ConferencingSpeech/ConferencingSpeech2021" -> "ConferencingSpeech/ConferencingSpeech2022"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "felixfuyihui/Uformer"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "Qinwen-Hu/dparn"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "alibabasglab/FRCRN"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "huyanxin/DeepComplexCRN"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "IMYBo/SDDNet"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "Le-Xiaohuai-speech/SKIP-DPCRN"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "yuguochencuc/SF-Net"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "jzi040941/PercepNet"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "fjiang9/NKF-AEC"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "echocatzh/MTFAA-Net"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "seorim0/DCCRN-with-various-loss-functions"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "wangtianrui/HGCN"
"MuSAELab/SRMRToolbox" -> "jfsantos/SRMRpy"
"Turing311/Realtime_AudioDenoise_EchoCancellation" -> "breizhn/DTLN-aec"
"Turing311/Realtime_AudioDenoise_EchoCancellation" -> "PandoraLS/traditional-speech-enhancement"
"Turing311/Realtime_AudioDenoise_EchoCancellation" -> "avcodecs/DTLNtfliteC"
"Turing311/Realtime_AudioDenoise_EchoCancellation" -> "Turing311/Face_Liveness_Detection_Android_iOS"
"Turing311/Realtime_AudioDenoise_EchoCancellation" -> "ewan-xu/pyaec"
"Turing311/Realtime_AudioDenoise_EchoCancellation" -> "ewan-xu/AEC3"
"Turing311/Realtime_AudioDenoise_EchoCancellation" -> "YangangCao/WebRTC-3A1V"
"d-kitamura/AuxIVA-ISS" -> "theLittleTiger/AuxIVA"
"microsoft/P.808" -> "microsoft/AEC-Challenge"
"microsoft/P.808" -> "microsoft/MS-SNSD"
"microsoft/P.808" -> "microsoft/DNS-Challenge"
"wavesaudio/Speex-AEC-matlab" -> "xiongyihui/speexdsp-python"
"xiph/speexdsp" -> "xiph/speex" ["e"=1]
"xiph/speexdsp" -> "wavesaudio/Speex-AEC-matlab"
"xiph/speexdsp" -> "microsoft/AEC-Challenge"
"xiph/speexdsp" -> "xiongyihui/speexdsp-python"
"xiph/speexdsp" -> "robin1001/beamforming"
"xiph/speexdsp" -> "ZitengWang/MASP"
"xiph/speexdsp" -> "kkumatani/distant_speech_recognition"
"xiph/speexdsp" -> "xanguera/BeamformIt"
"xiph/speexdsp" -> "ewan-xu/pyaec"
"xiph/speexdsp" -> "jzi040941/PercepNet"
"xiph/speexdsp" -> "athena-team/athena-signal"
"xiph/speexdsp" -> "voice-engine/ec"
"xiph/speexdsp" -> "breizhn/DTLN-aec"
"xiph/speexdsp" -> "markostam/active-noise-cancellation"
"xiph/speexdsp" -> "DoubangoTelecom/webrtc-audioproc"
"JupiterEthan/CRN-causal" -> "JupiterEthan/GCRN-complex"
"JupiterEthan/GCRN-complex" -> "JupiterEthan/CRN-causal"
"breizhn/DTLN-aec" -> "Turing311/Realtime_AudioDenoise_EchoCancellation"
"breizhn/DTLN-aec" -> "breizhn/DTLN"
"breizhn/DTLN-aec" -> "microsoft/AEC-Challenge"
"breizhn/DTLN-aec" -> "jzi040941/PercepNet"
"breizhn/DTLN-aec" -> "ewan-xu/pyaec"
"breizhn/DTLN-aec" -> "fjiang9/NKF-AEC"
"breizhn/DTLN-aec" -> "ewan-xu/AEC3"
"breizhn/DTLN-aec" -> "rrbluke/CDEC"
"breizhn/DTLN-aec" -> "LXP-Never/AEC_DeepModel"
"breizhn/DTLN-aec" -> "huyanxin/DeepComplexCRN"
"breizhn/DTLN-aec" -> "ZitengWang/MASP"
"breizhn/DTLN-aec" -> "nay0648/unified2021"
"breizhn/DTLN-aec" -> "avcodecs/DTLNtfliteC"
"breizhn/DTLN-aec" -> "echocatzh/MTFAA-Net"
"etzinis/sudo_rm_rf" -> "hit-thusz-RookieCJ/FullSubNet-plus"
"etzinis/sudo_rm_rf" -> "ujscjj/DPTNet"
"etzinis/sudo_rm_rf" -> "tky823/DNN-based_source_separation"
"etzinis/sudo_rm_rf" -> "yluo42/TAC"
"etzinis/sudo_rm_rf" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"etzinis/sudo_rm_rf" -> "haoxiangsnr/FullSubNet"
"etzinis/sudo_rm_rf" -> "jzi040941/PercepNet"
"etzinis/sudo_rm_rf" -> "etzinis/two_step_mask_learning"
"etzinis/sudo_rm_rf" -> "kaituoxu/Conv-TasNet"
"etzinis/sudo_rm_rf" -> "gemengtju/Tutorial_Separation"
"etzinis/sudo_rm_rf" -> "Zhongyang-debug/Attention-Is-All-You-Need-In-Speech-Separation"
"YangangCao/WebRTC-3A1V" -> "xiaochunxin/OMLSA-MCRA"
"auspicious3000/deepbeam" -> "zhr1201/Multi-channel-speech-extraction-using-DNN"
"xiongyihui/tdoa" -> "robin1001/beamforming"
"xiongyihui/tdoa" -> "xiaoli1368/Microphone-sound-source-localization"
"xiongyihui/tdoa" -> "wangwei2009/DOA"
"xiongyihui/tdoa" -> "snsun/cgmm_mvdr"
"xiongyihui/tdoa" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"respeaker/seeed-voicecard" -> "respeaker/mic_hat"
"respeaker/seeed-voicecard" -> "voice-engine/voice-engine"
"respeaker/seeed-voicecard" -> "respeaker/mic_array"
"respeaker/seeed-voicecard" -> "respeaker/4mics_hat"
"respeaker/seeed-voicecard" -> "voice-engine/ec"
"respeaker/seeed-voicecard" -> "HinTak/seeed-voicecard"
"respeaker/seeed-voicecard" -> "respeaker/get_started_with_respeaker"
"respeaker/seeed-voicecard" -> "respeaker/respeaker_python_library"
"respeaker/seeed-voicecard" -> "respeaker/avs" ["e"=1]
"respeaker/seeed-voicecard" -> "waveshare/WM8960-Audio-HAT"
"respeaker/seeed-voicecard" -> "voice-engine/make-a-smart-speaker"
"respeaker/seeed-voicecard" -> "SeeedDocument/ReSpeaker-4-Mic-Array-for-Raspberry-Pi"
"respeaker/seeed-voicecard" -> "respeaker/respeakerd"
"respeaker/seeed-voicecard" -> "respeaker/usb_4_mic_array"
"respeaker/seeed-voicecard" -> "introlab/odas"
"daitan-innovation/cnn-audio-denoiser" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"daitan-innovation/cnn-audio-denoiser" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"daitan-innovation/cnn-audio-denoiser" -> "vbelz/Speech-enhancement"
"daitan-innovation/cnn-audio-denoiser" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"daitan-innovation/cnn-audio-denoiser" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"daitan-innovation/cnn-audio-denoiser" -> "Wenzhe-Liu/awesome-speech-enhancement"
"hyli666/DNN-SpeechEnhancement" -> "funcwj/nn-ideal-mask"
"zinka/arraytool" -> "petotamas/pyArgus"
"vivjay30/Cone-of-Silence" -> "yluo42/TAC"
"vivjay30/Cone-of-Silence" -> "felixfuyihui/AISHELL-4" ["e"=1]
"vivjay30/Cone-of-Silence" -> "yuhogun0908/MISOnet"
"vivjay30/Cone-of-Silence" -> "funcwj/aps"
"vivjay30/Cone-of-Silence" -> "chenzhuo1011/libri_css"
"Andong-Li-speech/TaylorBeamformer" -> "Andong-Li-speech/G2Net"
"adobe-research/MetaAF" -> "fjiang9/NKF-AEC"
"adobe-research/MetaAF" -> "yluo42/FRA-RIR"
"adobe-research/MetaAF" -> "echocatzh/MTFAA-Net"
"adobe-research/MetaAF" -> "vkothapally/JAECBF"
"adobe-research/MetaAF" -> "felixfuyihui/Uformer"
"echocatzh/py-aec-unified2021" -> "vkothapally/Subband-Beamformer"
"felixfuyihui/Uformer" -> "Andong-Li-speech/TaylorBeamformer"
"felixfuyihui/Uformer" -> "Le-Xiaohuai-speech/SKIP-DPCRN"
"felixfuyihui/Uformer" -> "wangtianrui/HGCN"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "felixfuyihui/Uformer"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "yuguochencuc/DB-AIAT"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "Andong-Li-speech/TaylorBeamformer"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "echocatzh/MTFAA-Net"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "jzi040941/PercepNet"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "haoxiangsnr/FullSubNet"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "wangtianrui/HGCN"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "Andong-Li-speech/TaylorSENet"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "Le-Xiaohuai-speech/SKIP-DPCRN"
"hit-thusz-RookieCJ/FullSubNet-plus" -> "yluo42/FRA-RIR"
"pranaymanocha/PerceptualAudio" -> "adrienchaton/PerceptualAudio_Pytorch"
"pranaymanocha/PerceptualAudio" -> "google/visqol"
"pranaymanocha/PerceptualAudio" -> "aliutkus/speechmetrics"
"pranaymanocha/PerceptualAudio" -> "csteinmetz1/auraloss" ["e"=1]
"pranaymanocha/PerceptualAudio" -> "gabrielmittag/NISQA"
"pranaymanocha/PerceptualAudio" -> "maxrmorrison/torchcrepe" ["e"=1]
"pranaymanocha/PerceptualAudio" -> "facebookresearch/WavAugment" ["e"=1]
"yluo42/FRA-RIR" -> "fakufaku/torchiva"
"timsainb/python_spectrograms_and_inversion" -> "kastnerkyle/tools"
"timsainb/python_spectrograms_and_inversion" -> "posenhuang/singingvoiceseparationrpca"
"litcoderr/ComplexCNN" -> "wavefrontshaping/complexPyTorch"
"litcoderr/ComplexCNN" -> "sweetcocoa/DeepComplexUNetPyTorch"
"litcoderr/ComplexCNN" -> "ChihebTrabelsi/deep_complex_networks"
"litcoderr/ComplexCNN" -> "MRSRL/complex-networks-release"
"auspicious3000/WaveNet-Enhancement" -> "auspicious3000/deepbeam"
"jgarciagimenez/GSC_beamforming" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"jgarciagimenez/GSC_beamforming" -> "satyanamuduri/Speech-Enhancement-Using-GSC"
"jgarciagimenez/GSC_beamforming" -> "Akki369/Generalised-Side-Lobe-Canceller"
"voice-engine/ec" -> "voice-engine/make-a-smart-speaker"
"voice-engine/ec" -> "breizhn/DTLN-aec"
"voice-engine/ec" -> "respeaker/mic_array"
"voice-engine/ec" -> "xiongyihui/speexdsp-python"
"voice-engine/ec" -> "xiph/speexdsp"
"voice-engine/ec" -> "voice-engine/voice-engine"
"voice-engine/ec" -> "Spritea/AEC"
"voice-engine/ec" -> "respeaker/seeed-voicecard"
"ujscjj/DPTNet" -> "yluo42/TAC"
"ujscjj/DPTNet" -> "yoonsanghyu/Dual-Path-Transformer-Network-PyTorch"
"ujscjj/DPTNet" -> "etzinis/two_step_mask_learning"
"Ifsttar/I-Simpa" -> "PyTTAmaster/PyTTa"
"Ifsttar/I-Simpa" -> "Ifsttar/NoiseModelling"
"Ifsttar/I-Simpa" -> "aothms/ear"
"Ifsttar/I-Simpa" -> "pyfar/pyfar"
"Ifsttar/I-Simpa" -> "rinaldipp/tmm"
"maggie0830/DCCRN" -> "huyanxin/DeepComplexCRN"
"maggie0830/DCCRN" -> "wangtianrui/DCCRN"
"maggie0830/DCCRN" -> "chanil1218/DCUnet.pytorch"
"maggie0830/DCCRN" -> "seorim0/DCCRN-with-various-loss-functions"
"maggie0830/DCCRN" -> "JupiterEthan/GCRN-complex"
"maggie0830/DCCRN" -> "felixfuyihui/Uformer"
"maggie0830/DCCRN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"kaituoxu/TasNet" -> "runninging/TASNET"
"kaituoxu/TasNet" -> "kaituoxu/Conv-TasNet"
"kaituoxu/TasNet" -> "funcwj/conv-tasnet"
"kaituoxu/TasNet" -> "funcwj/uPIT-for-speech-separation"
"psykulsk/RpiANC" -> "xiezhq-hermann/ANC_signal-system_project"
"psykulsk/RpiANC" -> "CharlieHouse/RPi_SISO_ANC"
"Andong-Li-speech/EaBNet" -> "Andong-Li-speech/TaylorBeamformer"
"Andong-Li-speech/GaGNet" -> "wangtianrui/HGCN"
"Andong-Li-speech/TaylorSENet" -> "Andong-Li-speech/G2Net"
"Andong-Li-speech/TaylorSENet" -> "Le-Xiaohuai-speech/SKIP-DPCRN"
"NVIDIA/CleanUNet" -> "mindslab-ai/phaseaug" ["e"=1]
"NVIDIA/CleanUNet" -> "ruizhecao96/CMGAN"
"NVIDIA/CleanUNet" -> "sp-uhh/sgmse"
"neillu23/CDiffuSE" -> "sp-uhh/sgmse"
"neillu23/CDiffuSE" -> "yluo42/FRA-RIR"
"neillu23/CDiffuSE" -> "sp-uhh/storm"
"neillu23/CDiffuSE" -> "zqwang7/CausalityCheck"
"thesofproject/linux" -> "thesofproject/sof"
"thesofproject/linux" -> "thesofproject/kconfig"
"khaotik/DaNet-Tensorflow" -> "snsun/pit-speech-separation"
"khaotik/DaNet-Tensorflow" -> "Unisound/SpeechSeparation"
"khaotik/DaNet-Tensorflow" -> "zhr1201/deep-clustering"
"khaotik/DaNet-Tensorflow" -> "naplab/DANet"
"khaotik/DaNet-Tensorflow" -> "funcwj/conv-tas-net"
"khaotik/DaNet-Tensorflow" -> "Totoketchup/Adaptive-MultiSpeaker-Separation"
"khaotik/DaNet-Tensorflow" -> "funcwj/deep-clustering"
"khaotik/DaNet-Tensorflow" -> "pchao6/LSTM_PIT_Speech_Separation"
"PyTTAmaster/PyTTa" -> "rinaldipp/tmm"
"PyTTAmaster/PyTTa" -> "eric-brandao/rec_room_wave_acoustics"
"Wramberg/adaptfilt" -> "matousc89/Python-Adaptive-Signal-Processing-Handbook"
"Wramberg/adaptfilt" -> "rohitner/adaptive-filters"
"Spritea/AEC" -> "vaaiibhav/LMS-echo-cancellation"
"Spritea/AEC" -> "wavesaudio/Speex-AEC-matlab"
"Unisound/SpeechSeparation" -> "snsun/pit-speech-separation"
"etzinis/two_step_mask_learning" -> "mpariente/AsSteroid"
"etzinis/two_step_mask_learning" -> "ujscjj/DPTNet"
"FrancoisGrondin/BIRD" -> "yluo42/FRA-RIR"
"FrancoisGrondin/BIRD" -> "nay0648/unified2021"
"RoyJames/room-impulse-responses" -> "DavidDiazGuerra/gpuRIR"
"RoyJames/room-impulse-responses" -> "jonashaag/RealRIRs"
"RoyJames/room-impulse-responses" -> "maj4e/pyrirtool"
"RoyJames/room-impulse-responses" -> "jzi040941/PercepNet"
"RoyJames/room-impulse-responses" -> "Marvin182/rir-database"
"RoyJames/room-impulse-responses" -> "fgnt/ci_sdr"
"RoyJames/room-impulse-responses" -> "yluo42/FRA-RIR"
"flavioeverardo/erb_bands" -> "eran-shahar/Double-talk-Detection-aided-Residual-Echo-Suppression-via-Spectrogram-Masking-and-Refinement"
"mpariente/AsSteroid" -> "etzinis/two_step_mask_learning"
"xiongyihui/speexdsp-python" -> "wavesaudio/Speex-AEC-matlab"
"xiongyihui/speexdsp-python" -> "xiongyihui/python-webrtc-audio-processing"
"pchao6/LSTM_PIT_Speech_Separation" -> "snsun/pit-speech-separation"
"pchao6/LSTM_PIT_Speech_Separation" -> "funcwj/uPIT-for-speech-separation"
"pchao6/LSTM_PIT_Speech_Separation" -> "funcwj/deep-clustering"
"pchao6/LSTM_PIT_Speech_Separation" -> "kaituoxu/Conv-TasNet"
"pchao6/LSTM_PIT_Speech_Separation" -> "zhr1201/deep-clustering"
"pchao6/LSTM_PIT_Speech_Separation" -> "posenhuang/deeplearningsourceseparation"
"pchao6/LSTM_PIT_Speech_Separation" -> "seanwood/gcc-nmf"
"pchao6/LSTM_PIT_Speech_Separation" -> "speechLabBcCuny/onssen"
"pchao6/LSTM_PIT_Speech_Separation" -> "khaotik/DaNet-Tensorflow"
"pchao6/LSTM_PIT_Speech_Separation" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"pchao6/LSTM_PIT_Speech_Separation" -> "bill9800/speech_separation" ["e"=1]
"pchao6/LSTM_PIT_Speech_Separation" -> "naplab/DANet"
"pchao6/LSTM_PIT_Speech_Separation" -> "mindslab-ai/voicefilter"
"pchao6/LSTM_PIT_Speech_Separation" -> "mpariente/asteroid"
"pchao6/LSTM_PIT_Speech_Separation" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"JusperLee/UtterancePIT-Speech-Separation" -> "JusperLee/ExamOnline" ["e"=1]
"JusperLee/UtterancePIT-Speech-Separation" -> "JusperLee/Deep-Clustering-for-Speech-Separation"
"jcsilva/deep-clustering" -> "zhr1201/deep-clustering"
"jcsilva/deep-clustering" -> "Unisound/SpeechSeparation"
"krakenrf/krakensdr_doa" -> "krakenrf/heimdall_daq_fw"
"krakenrf/krakensdr_doa" -> "krakenrf/krakensdr_docs"
"krakenrf/krakensdr_doa" -> "krakenrf/krakensdr_pr"
"krakenrf/krakensdr_doa" -> "krakenrf/gr-krakensdr"
"krakenrf/krakensdr_doa" -> "ckoval7/df-aggregator"
"sarulab-speech/UTMOS22" -> "unilight/LDNet"
"helianvine/fdndlp" -> "fgnt/nara_wpe"
"helianvine/fdndlp" -> "kkumatani/distant_speech_recognition"
"helianvine/fdndlp" -> "shamim-hussain/speech_dereverbaration_using_lp_residual"
"helianvine/fdndlp" -> "DistantSpeechRecognition/mcse"
"helianvine/fdndlp" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"JusperLee/Deep-Encoder-Decoder-Conv-TasNet" -> "JusperLee/small-tools"
"jagger2048/WebRtc_noise_suppression" -> "TracyJichuan/webrtc_noise_suppression"
"wslihgt/pyfasst" -> "openBliSSART/openBliSSART"
"JianboTang/RNN_MATLAB" -> "jimmy-ren/vLSTM"
"JusperLee/awesome-speech-enhancement" -> "JusperLee/small-tools"
"rtlsdrblog/kerberossdr" -> "rtlsdrblog/rtl-sdr-kerberos"
"rtlsdrblog/kerberossdr" -> "petotamas/APRiL"
"rtlsdrblog/kerberossdr" -> "tejeez/rtl_coherent" ["e"=1]
"rtlsdrblog/kerberossdr" -> "krakenrf/krakensdr_doa"
"xiaoli1368/Microphone-sound-source-localization" -> "Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation"
"xiaoli1368/Microphone-sound-source-localization" -> "wangwei2009/DOA"
"xiaoli1368/Microphone-sound-source-localization" -> "pchao6/Sound_Localization_Algorithms"
"xiaoli1368/Microphone-sound-source-localization" -> "LeeTaewoo/fast_sound_source_localization_using_TLSSC"
"xiaoli1368/Microphone-sound-source-localization" -> "xiongyihui/tdoa"
"xiaoli1368/Microphone-sound-source-localization" -> "sindhurach94/Sound-source-localization"
"haoheliu/voicefixer_main" -> "haoheliu/voicefixer"
"Sato-Kunihiko/audio-SNR" -> "speechLabBcCuny/onssen"
"Sato-Kunihiko/audio-SNR" -> "funcwj/setk"
"dhimasryan/MOSA-Net-Cross-Domain" -> "nii-yamagishilab/mos-finetune-ssl"
"dhimasryan/MOSA-Net-Cross-Domain" -> "dhimasryan/STOI-Net"
"xiph/LPCNet" -> "Qinwen-Hu/dparn"
"xiph/LPCNet" -> "jzi040941/PercepNet"
"xiph/LPCNet" -> "yl4579/StyleTTS" ["e"=1]
"zhr1201/Multi-channel-speech-extraction-using-DNN" -> "auspicious3000/deepbeam"
"BrechtDeMan/WebAudioEvaluationTool" -> "audiolabs/webMUSHRA"
"krakenrf/krakensdr_docs" -> "krakenrf/krakensdr_doa"
"krakenrf/krakensdr_docs" -> "krakenrf/heimdall_daq_fw"
"sky1456723/Pytorch-MBNet" -> "unilight/LDNet"
"BUTSpeechFIT/speakerbeam" -> "xuchenglin28/speaker_extraction_SpEx"
"BUTSpeechFIT/speakerbeam" -> "mborsdorf/UniversalSpeakerExtraction"
"JusperLee/TDANet" -> "Andong-Li-speech/TaylorBeamformer"
"xuchenglin28/speaker_extraction_SpEx" -> "gemengtju/SpEx_Plus"
"xuchenglin28/speaker_extraction_SpEx" -> "mborsdorf/UniversalSpeakerExtraction"
"IMYBo/SDDNet" -> "wangtianrui/HGCN"
"krakenrf/heimdall_daq_fw" -> "krakenrf/gr-krakensdr"
"krakenrf/heimdall_daq_fw" -> "krakenrf/krakensdr_doa"
"krakenrf/heimdall_daq_fw" -> "krakenrf/krakensdr_pr"
"jfsantos/SRMRpy" -> "MuSAELab/SRMRToolbox"
"krakenrf/gr-krakensdr" -> "krakenrf/heimdall_daq_fw"
"abenori/TeX2img" -> "doraTeX/TeX2img"
"xshl5/KOTI_AEC" -> "DoubangoTelecom/webrtc-audioproc"
"pyfar/pyfar" -> "pyfar/sofar"
"JusperLee/Arxiv-New-Paper-Server" -> "JusperLee/small-tools"
"unilight/LDNet" -> "sarulab-speech/UTMOS22"
"unilight/LDNet" -> "sky1456723/Pytorch-MBNet"
"unilight/LDNet" -> "dhimasryan/MOSA-Net-Cross-Domain"
"IoSR-Surrey/untwist" ["l"="2.698,39.299"]
"interactiveaudiolab/nussl" ["l"="2.666,39.274"]
"GregorR/rnnoise-nu" ["l"="2.136,39.237"]
"GregorR/rnnoise-models" ["l"="2.116,39.236"]
"jagger2048/rnnoise-windows" ["l"="2.168,39.239"]
"Ryuk17/SpeechAlgorithms" ["l"="2.44,39.237"]
"jzi040941/PercepNet" ["l"="2.457,39.236"]
"funcwj/setk" ["l"="2.445,39.218"]
"athena-team/athena-signal" ["l"="2.406,39.235"]
"aliutkus/speechmetrics" ["l"="2.471,39.185"]
"nanahou/Awesome-Speech-Enhancement" ["l"="2.475,39.198"]
"Wenzhe-Liu/awesome-speech-enhancement" ["l"="2.476,39.211"]
"JusperLee/Speech-Separation-Paper-Tutorial" ["l"="2.497,39.167"]
"microsoft/AEC-Challenge" ["l"="2.424,39.234"]
"microsoft/DNS-Challenge" ["l"="2.458,39.193"]
"breizhn/DTLN-aec" ["l"="2.421,39.27"]
"huyanxin/DeepComplexCRN" ["l"="2.493,39.212"]
"ewan-xu/pyaec" ["l"="2.414,39.284"]
"anicolson/DeepXi" ["l"="2.485,39.22"]
"breizhn/DTLN" ["l"="2.458,39.225"]
"ZitengWang/MASP" ["l"="2.385,39.249"]
"busyyang/python_sound_open" ["l"="2.458,39.329"]
"bastamon/sound_signal_process-matlab-" ["l"="2.471,39.401"]
"Le-Xiaohuai-speech/DPCRN_DNS3" ["l"="2.497,39.274"]
"Zhangtingyuxuan/AcousticFeatureExtraction" ["l"="2.487,39.39"]
"eesungkim/Speech_Enhancement_DNN_NMF" ["l"="2.516,39.252"]
"zhr1201/CNN-for-single-channel-speech-enhancement" ["l"="2.535,39.255"]
"linan2/TensorFlow-speech-enhancement-Chinese" ["l"="2.559,39.278"]
"yongxuUSTC/sednn" ["l"="2.505,39.246"]
"jtkim-kaist/Speech-enhancement" ["l"="2.489,39.262"]
"hyli666/DNN-SpeechEnhancement" ["l"="2.533,39.276"]
"eesungkim/Speech_Enhancement_MMSE-STSA" ["l"="2.568,39.293"]
"yongxuUSTC/DNN-for-speech-enhancement" ["l"="2.505,39.262"]
"yongxuUSTC/DNN-Speech-enhancement-demo-tool" ["l"="2.52,39.279"]
"santi-pdp/segan_pytorch" ["l"="2.531,39.227"]
"seanwood/gcc-nmf" ["l"="2.471,39.239"]
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" ["l"="2.548,39.238"]
"fgnt/nn-gev" ["l"="2.412,39.215"]
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" ["l"="2.528,39.218"]
"facebookresearch/denoiser" ["l"="2.442,39.185"]
"asteroid-team/asteroid" ["l"="2.469,39.165"]
"haoxiangsnr/FullSubNet" ["l"="2.476,39.222"]
"facebookresearch/WavAugment" ["l"="0.383,39.87"]
"jik876/hifi-gan" ["l"="0.378,40.04"]
"facebookresearch/svoice" ["l"="2.477,39.139"]
"snakers4/silero-vad" ["l"="0.453,39.817"]
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" ["l"="2.512,39.221"]
"hit-thusz-RookieCJ/FullSubNet-plus" ["l"="2.484,39.274"]
"huyanxin/phasen" ["l"="2.493,39.201"]
"maggie0830/DCCRN" ["l"="2.545,39.208"]
"echocatzh/MTFAA-Net" ["l"="2.465,39.282"]
"microsoft/MS-SNSD" ["l"="2.463,39.206"]
"Rikorose/DeepFilterNet" ["l"="2.468,39.271"]
"nay0648/unified2021" ["l"="2.456,39.295"]
"felixfuyihui/Uformer" ["l"="2.488,39.287"]
"cookcodes/Percepnet-Keras" ["l"="2.499,39.285"]
"fjiang9/NKF-AEC" ["l"="2.471,39.296"]
"linan2/TensorFlow-speech-enhancement" ["l"="2.6,39.306"]
"haoxiangsnr/Speech_Enhancement_Tools" ["l"="2.618,39.321"]
"boozyguo/ClearWave" ["l"="2.595,39.32"]
"ludlows/python-pesq" ["l"="2.497,39.192"]
"mpariente/pystoi" ["l"="2.524,39.203"]
"vBaiCai/python-pesq" ["l"="2.512,39.212"]
"schmiph2/pysepm" ["l"="2.505,39.202"]
"gabrielmittag/NISQA" ["l"="2.46,39.152"]
"DavidDiazGuerra/gpuRIR" ["l"="2.483,39.191"]
"kaituoxu/Conv-TasNet" ["l"="2.529,39.174"]
"majianjia/nnom" ["l"="2.424,39.22"]
"ARM-software/ML-KWS-for-MCU" ["l"="2.649,39.735"]
"xboot/libonnx" ["l"="-31.581,41.427"]
"tensorflow/tflite-micro" ["l"="27.366,35.569"]
"ai-techsystems/deepC" ["l"="27.352,35.537"]
"ARM-software/ML-examples" ["l"="27.427,35.518"]
"xiph/rnnoise" ["l"="2.385,39.199"]
"microsoft/P.808" ["l"="2.422,39.186"]
"mpariente/pytorch_stoi" ["l"="2.553,39.177"]
"werman/noise-suppression-for-voice" ["l"="-34.727,3.624"]
"santi-pdp/segan" ["l"="2.516,39.235"]
"drethage/speech-denoising-wavenet" ["l"="2.533,39.242"]
"cpuimage/rnnoise" ["l"="2.291,39.249"]
"LCAV/pyroomacoustics" ["l"="2.412,39.201"]
"mozilla/LPCNet" ["l"="0.475,40.101"]
"jtkim-kaist/VAD" ["l"="0.478,39.736"]
"fgnt/nara_wpe" ["l"="2.45,39.209"]
"fgnt/pb_chime5" ["l"="2.441,39.201"]
"ChihebTrabelsi/deep_complex_networks" ["l"="2.574,39.147"]
"wavefrontshaping/complexPyTorch" ["l"="2.622,39.135"]
"litcoderr/ComplexCNN" ["l"="2.604,39.131"]
"JesperDramsch/keras-complex" ["l"="2.618,39.115"]
"MRSRL/complex-networks-release" ["l"="2.638,39.106"]
"ivannz/cplxmodule" ["l"="2.639,39.122"]
"NEGU93/cvnn" ["l"="2.616,39.103"]
"naplab/Conv-TasNet" ["l"="2.508,39.161"]
"zhongyuanzhao/dl_ofdm" ["l"="3.196,39.247"]
"mpariente/asteroid" ["l"="2.519,39.186"]
"helianvine/fdndlp" ["l"="2.397,39.217"]
"kkumatani/distant_speech_recognition" ["l"="2.374,39.242"]
"ehabets/RIR-Generator" ["l"="2.429,39.197"]
"fgnt/pb_bss" ["l"="2.434,39.212"]
"nttcslab-sp/dnn_wpe" ["l"="2.42,39.25"]
"funcwj/cgmm-mask-estimator" ["l"="2.388,39.223"]
"yluo42/TAC" ["l"="2.484,39.164"]
"speechLabBcCuny/onssen" ["l"="2.499,39.183"]
"funcwj/conv-tasnet" ["l"="2.519,39.165"]
"JorisCos/LibriMix" ["l"="2.495,39.142"]
"pchao6/LSTM_PIT_Speech_Separation" ["l"="2.576,39.202"]
"Andong-Li-speech/EaBNet" ["l"="2.467,39.341"]
"vkothapally/JAECBF" ["l"="2.517,39.35"]
"yuguochencuc/SF-Net" ["l"="2.509,39.306"]
"adobe-research/MetaAF" ["l"="2.5,39.313"]
"vkothapally/Subband-Beamformer" ["l"="2.45,39.342"]
"yluo42/FRA-RIR" ["l"="2.512,39.271"]
"google/lyra" ["l"="2.343,39.15"]
"facebookresearch/encodec" ["l"="0.22,39.966"]
"xiph/opus" ["l"="-26.661,13.663"]
"kan-bayashi/ParallelWaveGAN" ["l"="0.435,40.065"]
"espnet/espnet" ["l"="0.517,39.96"]
"lucidrains/audiolm-pytorch" ["l"="0.188,39.973"]
"speechbrain/speechbrain" ["l"="0.467,39.899"]
"google/oboe" ["l"="50.889,1.827"]
"fatchord/WaveRNN" ["l"="0.514,40.078"]
"f90/Wave-U-Net" ["l"="2.576,39.22"]
"f90/Wave-U-Net-Pytorch" ["l"="2.571,39.19"]
"francesclluis/source-separation-wavenet" ["l"="2.656,39.235"]
"andabi/music-source-separation" ["l"="2.631,39.245"]
"sigsep/open-unmix-pytorch" ["l"="0.061,40.018"]
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" ["l"="2.544,39.23"]
"MTG/DeepConvSep" ["l"="2.65,39.253"]
"craffel/mir_eval" ["l"="1.697,38.472"]
"mindslab-ai/voicefilter" ["l"="2.54,39.162"]
"JusperLee/Conv-TasNet" ["l"="2.527,39.132"]
"etzinis/sudo_rm_rf" ["l"="2.512,39.175"]
"gemengtju/Tutorial_Separation" ["l"="2.503,39.15"]
"jim-schwoebel/voice_datasets" ["l"="2.408,39.123"]
"JRMeyer/open-speech-corpora" ["l"="0.53,39.899"]
"s3prl/s3prl" ["l"="0.402,39.901"]
"iver56/audiomentations" ["l"="0.307,39.857"]
"auspicious3000/autovc" ["l"="0.362,40.125"]
"asteroid-team/torch-audiomentations" ["l"="0.287,39.881"]
"auspicious3000/SpeechSplit" ["l"="0.363,40.098"]
"kuleshov/audio-super-res" ["l"="2.442,39.157"]
"jhetherly/EnglishSpeechUpsampler" ["l"="2.404,39.076"]
"haoheliu/voicefixer" ["l"="2.446,39.259"]
"descriptinc/melgan-neurips" ["l"="0.443,40.088"]
"mindslab-ai/nuwave" ["l"="0.145,40.071"]
"mindslab-ai/nuwave2" ["l"="0.136,40.046"]
"zkx06111/WSRGlow" ["l"="2.402,39.096"]
"HarryVolek/PyTorch_Speaker_Verification" ["l"="0.392,39.759"]
"wq2012/awesome-diarization" ["l"="0.407,39.803"]
"google/uis-rnn" ["l"="0.433,39.779"]
"Edresson/VoiceSplit" ["l"="2.545,39.083"]
"acoular/acoular" ["l"="2.396,39.247"]
"xanguera/BeamformIt" ["l"="2.389,39.237"]
"python-acoustics/python-acoustics" ["l"="2.38,39.153"]
"audiolabs/webMUSHRA" ["l"="2.343,39.103"]
"BrechtDeMan/WebAudioEvaluationTool" ["l"="2.322,39.075"]
"csteinmetz1/pyloudnorm" ["l"="2.408,39.162"]
"csteinmetz1/auraloss" ["l"="0.17,39.929"]
"carlthome/python-audio-effects" ["l"="1.68,38.458"]
"pranaymanocha/PerceptualAudio" ["l"="2.436,39.127"]
"justinsalamon/scaper" ["l"="1.681,38.407"]
"BrechtDeMan/loudness.py" ["l"="2.373,39.124"]
"KinWaiCheuk/nnAudio" ["l"="0.247,39.888"]
"spatialaudio/computational_acoustics" ["l"="22.755,30.683"]
"PyTTAmaster/PyTTa" ["l"="2.309,39.099"]
"SiggiGue/pyfilterbank" ["l"="1.506,38.623"]
"timmahrt/pyAcoustics" ["l"="2.326,39.12"]
"RoyJames/room-impulse-responses" ["l"="2.553,39.193"]
"Ifsttar/I-Simpa" ["l"="2.283,39.097"]
"pyfar/pyfar" ["l"="2.303,39.119"]
"spatialaudio/digital-signal-processing-lecture" ["l"="22.869,30.692"]
"spatialaudio/python-sounddevice" ["l"="1.559,38.584"]
"madebyollin/acapellabot" ["l"="2.702,39.254"]
"laserb/deep-vocal-isolation" ["l"="2.751,39.254"]
"leftthomas/SEGAN" ["l"="2.562,39.248"]
"vbelz/Speech-enhancement" ["l"="2.5,39.227"]
"JesperDramsch/Complex-CNN-Seismic" ["l"="2.632,39.09"]
"sweetcocoa/DeepComplexUNetPyTorch" ["l"="2.582,39.165"]
"williamFalcon/pytorch-complex-tensor" ["l"="2.678,39.1"]
"omrijsharon/torchlex" ["l"="2.663,39.117"]
"muqiaoy/dl_signal" ["l"="2.681,39.117"]
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" ["l"="2.549,39.22"]
"JasonSWFu/MetricGAN" ["l"="2.57,39.237"]
"auspicious3000/WaveNet-Enhancement" ["l"="2.591,39.296"]
"mosheman5/DNP" ["l"="2.596,39.236"]
"kaituoxu/TasNet" ["l"="2.567,39.161"]
"funcwj/voice-filter" ["l"="2.571,39.111"]
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" ["l"="2.524,39.155"]
"funcwj/CGMM-MVDR" ["l"="2.4,39.226"]
"lochenchou/MOSNet" ["l"="2.467,39.113"]
"JasonSWFu/Quality-Net" ["l"="2.464,39.094"]
"google/visqol" ["l"="2.452,39.17"]
"maxrmorrison/torchcrepe" ["l"="0.152,39.98"]
"facebookresearch/speech-resynthesis" ["l"="0.283,40.071"]
"LEEYOONHYUNG/BVAE-TTS" ["l"="0.322,40.071"]
"ivanvovk/WaveGrad" ["l"="0.331,40.044"]
"haoheliu/voicefixer_main" ["l"="2.434,39.31"]
"NVIDIA/BigVGAN" ["l"="0.245,40.02"]
"brentspell/hifi-gan-bwe" ["l"="0.168,40.049"]
"ruizhecao96/CMGAN" ["l"="2.469,39.314"]
"sp-uhh/sgmse" ["l"="2.481,39.335"]
"rishikksh20/HiFiplusplus-pytorch" ["l"="0.086,40.033"]
"lmnt-com/diffwave" ["l"="0.284,40.029"]
"haoheliu/ssr_eval" ["l"="0.082,40.05"]
"JusperLee/Dual-Path-RNN-Pytorch" ["l"="2.516,39.148"]
"funcwj/uPIT-for-speech-separation" ["l"="2.606,39.189"]
"slhck/ffmpeg-normalize" ["l"="2.488,39.237"]
"supasorn/synthesizing_obama_network_training" ["l"="35.027,31.687"]
"wiseman/py-webrtcvad" ["l"="0.495,39.811"]
"bootphon/phonemizer" ["l"="0.463,40.017"]
"facebookresearch/textlesslib" ["l"="0.281,39.992"]
"MontrealCorpusTools/Montreal-Forced-Aligner" ["l"="0.473,40.032"]
"NATSpeech/NATSpeech" ["l"="-27.325,19.395"]
"timsainb/noisereduce" ["l"="2.406,39.177"]
"dodiku/noise_reduction" ["l"="2.361,39.087"]
"pyannote/pyannote-audio" ["l"="0.435,39.837"]
"matousc89/padasip" ["l"="2.551,39.341"]
"matousc89/Python-Adaptive-Signal-Processing-Handbook" ["l"="2.572,39.367"]
"Wramberg/adaptfilt" ["l"="2.583,39.382"]
"ninja3697/Kernel-Adaptive-Filtering-in-Python" ["l"="2.592,39.362"]
"rohitner/adaptive-filters" ["l"="2.564,39.379"]
"rookiepeng/antenna-array-analysis" ["l"="2.046,39.409"]
"rookiepeng/antenna-models" ["l"="2.03,39.426"]
"rookiepeng/antarray" ["l"="2.056,39.395"]
"voice-engine/make-a-smart-speaker" ["l"="2.384,39.278"]
"voice-engine/ec" ["l"="2.351,39.313"]
"voice-engine/voice-engine" ["l"="2.334,39.323"]
"mindorii/kws" ["l"="2.652,39.717"]
"respeaker/mic_array" ["l"="2.343,39.293"]
"colinsongf/keyword_spotting" ["l"="2.652,39.703"]
"introlab/odas" ["l"="2.358,39.254"]
"wangwei2009/DOA" ["l"="2.325,39.271"]
"robin1001/beamforming" ["l"="2.374,39.256"]
"yump/doamusic" ["l"="2.179,39.317"]
"amjadsaadeh/pyMUSIC" ["l"="2.149,39.32"]
"vsubhashini/ica" ["l"="2.826,39.293"]
"robical/BlindSourceSeparation" ["l"="2.85,39.298"]
"posenhuang/deeplearningsourceseparation" ["l"="2.58,39.251"]
"wslihgt/pyfasst" ["l"="2.73,39.274"]
"Js-Mim/mss_pytorch" ["l"="2.705,39.279"]
"marl/medleydb" ["l"="1.756,38.464"]
"MTG/gaia" ["l"="1.603,38.506"]
"zhr1201/deep-clustering" ["l"="2.644,39.21"]
"urinieto/msaf" ["l"="1.716,38.487"]
"bmcfee/muda" ["l"="1.63,38.433"]
"ShichengChen/Audio-Source-Separation" ["l"="2.729,39.233"]
"scpark20/universal-music-translation" ["l"="2.768,39.231"]
"fakufaku/torchiva" ["l"="2.564,39.262"]
"TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques" ["l"="2.365,39.196"]
"d-kitamura/ILRMA" ["l"="2.335,39.183"]
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" ["l"="2.362,39.221"]
"sekiguchi92/SoundSourceSeparation" ["l"="2.463,39.258"]
"sigsep/norbert" ["l"="-0.044,40.028"]
"haoxiangsnr/SNR-Based-Progressive-Learning-of-Deep-Neural-Network-for-Speech-Enhancement" ["l"="2.651,39.342"]
"petotamas/pyArgus" ["l"="2.077,39.385"]
"zinka/arraytool" ["l"="2.076,39.404"]
"morriswmz/doatools.py" ["l"="2.159,39.35"]
"petotamas/APRiL" ["l"="1.994,39.417"]
"MSBeni/AoA_IQsamples" ["l"="2.06,39.373"]
"jonkraft/PhasedArray" ["l"="2.04,39.382"]
"vb000/Waveformer" ["l"="2.484,39.31"]
"Qinwen-Hu/dparn" ["l"="2.516,39.296"]
"emilbjornson/optimal-beamforming" ["l"="2.291,39.218"]
"TianLin0509/Hybrid-Beamforming-for-Millimeter-Wave-Systems-Using-the-MMSE-Criterion" ["l"="3.255,39.154"]
"jorgengrythe/beamforming" ["l"="2.342,39.234"]
"emilbjornson/book-resource-allocation" ["l"="3.304,39.183"]
"emilbjornson/IRS-relaying" ["l"="3.267,39.127"]
"cpuimage/WebRTC_VAD" ["l"="2.269,39.272"]
"cpuimage/WebRTC_AGC" ["l"="2.269,39.287"]
"cpuimage/WebRTC_AECM" ["l"="2.31,39.281"]
"cpuimage/WebRTC_NS" ["l"="2.286,39.27"]
"cpuimage/resampler" ["l"="2.279,39.281"]
"Jonathan-LeRoux/IguanaTex" ["l"="2.612,39.16"]
"abenori/TeX2img" ["l"="2.69,39.136"]
"ray851107/IguanaTexMac" ["l"="2.669,39.145"]
"fgnt/ci_sdr" ["l"="2.636,39.181"]
"xuchenglin28/speaker_extraction" ["l"="2.507,39.106"]
"popcornell/SparseLibriMix" ["l"="2.489,39.088"]
"chenzhuo1011/libri_css" ["l"="2.492,39.127"]
"ujscjj/DPTNet" ["l"="2.511,39.137"]
"Enny1991/beamformers" ["l"="2.436,39.173"]
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" ["l"="2.182,39.332"]
"morriswmz/doa-tools" ["l"="2.242,39.312"]
"msamsami/doa-estimation-music" ["l"="2.226,39.328"]
"Wenzhe-Liu/sound-source-localization-algorithm_DOA_estimation" ["l"="2.338,39.266"]
"polarch/Spherical-Array-Processing" ["l"="-11.385,40.751"]
"chenhui07c8/DOA-AOA-algorithms" ["l"="2.207,39.325"]
"LCAV/FRIDA" ["l"="2.191,39.347"]
"xuchenglin28/WSCM-MUSIC" ["l"="2.26,39.314"]
"ImperialCollegeLondon/sap-voicebox" ["l"="2.436,39.25"]
"jfsantos/SRMRpy" ["l"="2.537,39.287"]
"orchidas/Pitch-Tracking" ["l"="1.691,37.988"]
"xiaoli1368/Microphone-sound-source-localization" ["l"="2.311,39.252"]
"aishoot/Sound_Localization_Algorithms" ["l"="2.334,39.245"]
"xiongyihui/tdoa" ["l"="2.331,39.256"]
"snsun/cgmm_mvdr" ["l"="2.365,39.236"]
"AgoraIO-Community/Solo" ["l"="2.286,39.199"]
"shichaog/RNNAec" ["l"="2.271,39.224"]
"seorim0/DCCRN-with-various-loss-functions" ["l"="2.523,39.264"]
"tky823/audio_source_separation" ["l"="2.591,39.084"]
"lili-0805/MVAE" ["l"="2.615,39.054"]
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" ["l"="2.39,39.267"]
"pchao6/Sound_Localization_Algorithms" ["l"="2.347,39.245"]
"hjkwon0609/source_separation_ml_jeju" ["l"="2.689,39.239"]
"sungheonpark/music_source_sepearation_SH_net" ["l"="2.679,39.256"]
"ybayle/awesome-deep-learning-music" ["l"="1.746,38.508"]
"JusperLee/Deep-Clustering-for-Speech-Separation" ["l"="2.548,39.102"]
"JusperLee/Deep-Encoder-Decoder-Conv-TasNet" ["l"="2.557,39.063"]
"JusperLee/Looking-to-Listen-at-the-Cocktail-Party" ["l"="26.549,-20.599"]
"JusperLee/Calculate-SNR-SDR" ["l"="2.567,39.077"]
"JusperLee/UtterancePIT-Speech-Separation" ["l"="2.564,39.092"]
"respeaker/get_started_with_respeaker" ["l"="2.285,39.356"]
"respeaker/respeaker_python_library" ["l"="2.281,39.341"]
"respeaker/avs" ["l"="2.607,40.01"]
"respeaker/respeaker-feed" ["l"="2.246,39.373"]
"respeaker/Alexa" ["l"="2.247,39.39"]
"respeaker/respeaker_arduino_library" ["l"="2.26,39.36"]
"respeaker/seeed-voicecard" ["l"="2.319,39.341"]
"Fuhua-Chen/ReSpeaker-Microphone-Array-HID-tool" ["l"="2.262,39.376"]
"google-research/sound-separation" ["l"="2.487,39.178"]
"nussl/nussl" ["l"="1.665,38.396"]
"gemengtju/SpEx_Plus" ["l"="2.52,39.093"]
"funcwj/deep-clustering" ["l"="2.624,39.198"]
"naplab/DANet" ["l"="2.635,39.19"]
"snsun/pit-speech-separation" ["l"="2.623,39.211"]
"funcwj/aps" ["l"="2.454,39.245"]
"xuchenglin28/speaker_extraction_SpEx" ["l"="2.52,39.074"]
"mborsdorf/UniversalSpeakerExtraction" ["l"="2.531,39.065"]
"tky823/DNN-based_source_separation" ["l"="2.535,39.147"]
"xuchenglin28/speech_separation" ["l"="2.497,39.061"]
"haoxiangsnr/SpEx" ["l"="2.504,39.071"]
"BUTSpeechFIT/speakerbeam" ["l"="2.519,39.056"]
"YangangCao/WebRTC-3A1V" ["l"="2.315,39.299"]
"jorgehatccrma/pyagc" ["l"="2.212,39.295"]
"dr-costas/mad-twinnet" ["l"="2.742,39.29"]
"sigsep/sigsep-mus-2018" ["l"="2.734,39.304"]
"BBuf/model-compression" ["l"="2.547,39.407"]
"Eric-mingjie/network-slimming" ["l"="30.896,35.639"]
"Le-Xiaohuai-speech/SKIP-DPCRN" ["l"="2.489,39.3"]
"echocatzh/PFDKF" ["l"="2.501,39.341"]
"cpuimage/SimpleAudioDenoise" ["l"="2.24,39.261"]
"cpuimage/WebRTC_NS_CPP" ["l"="2.231,39.272"]
"jagger2048/WebRtc_noise_suppression" ["l"="2.203,39.273"]
"shichaog/WebRTC-audio-processing" ["l"="2.357,39.268"]
"garyyu/WebRTC_VoiceEngine" ["l"="2.246,39.296"]
"cpuimage/AudioDenoise" ["l"="2.252,39.252"]
"cpuimage/FFTResampler" ["l"="2.254,39.268"]
"Baidu-AIP/speech-vad-demo" ["l"="0.536,39.733"]
"ewan-xu/AEC3" ["l"="2.374,39.27"]
"AkojimaSLP/Beamforming-for-speech-enhancement" ["l"="2.377,39.218"]
"huangzhenyu/beamforming" ["l"="2.333,39.222"]
"JackHCC/Audio-Digital-Processing" ["l"="2.487,39.454"]
"fzzfbyx/Audio-FIR-denoising-filter-MATLAB_GUI" ["l"="2.493,39.478"]
"furushchev/respeaker_ros" ["l"="2.331,39.39"]
"respeaker/usb_4_mic_array" ["l"="2.334,39.364"]
"jim-schwoebel/voicebook" ["l"="2.346,39.024"]
"jim-schwoebel/voice_gender_detection" ["l"="2.315,39.002"]
"jim-schwoebel/allie" ["l"="2.331,38.987"]
"respeaker/mic_hat" ["l"="2.313,39.357"]
"chenwj1989/Beamforming_Examples" ["l"="2.343,39.21"]
"jgarciagimenez/GSC_beamforming" ["l"="2.321,39.213"]
"openBliSSART/openBliSSART" ["l"="2.78,39.283"]
"thesofproject/sof" ["l"="2.337,39.421"]
"thesofproject/linux" ["l"="2.325,39.451"]
"thesofproject/sof-docs" ["l"="2.343,39.444"]
"xiph/speexdsp" ["l"="2.376,39.292"]
"thesofproject/sof-test" ["l"="2.318,39.437"]
"wavesaudio/Speex-AEC-matlab" ["l"="2.354,39.281"]
"LXP-Never/AEC_DeepModel" ["l"="2.37,39.281"]
"ConferencingSpeech/ConferencingSpeech2021" ["l"="2.438,39.226"]
"respeaker/microsoft_cognitive_services" ["l"="2.248,39.353"]
"Audio-WestlakeU/NBSS" ["l"="2.549,39.252"]
"DiegoLeon96/Neural-Speech-Dereverberation" ["l"="2.456,39.42"]
"zehuachenImperial/SkipConvNet" ["l"="2.449,39.441"]
"flavioeverardo/erb_bands" ["l"="2.452,39.457"]
"csd111/dereverberation" ["l"="2.289,39.159"]
"shamim-hussain/speech_dereverbaration_using_lp_residual" ["l"="2.314,39.176"]
"Marvin182/rir-generator" ["l"="2.382,39.137"]
"pseeth/torch-stft" ["l"="2.487,39.155"]
"etzinis/two_step_mask_learning" ["l"="2.509,39.127"]
"veenveenveen/SpeechSignalProcessingCourse" ["l"="2.489,39.434"]
"taw19960426/-Speech-signal-processing-experiment-tutorial-_python" ["l"="2.475,39.426"]
"DoubangoTelecom/webrtc-audioproc" ["l"="2.291,39.303"]
"xshl5/KOTI_AEC" ["l"="2.27,39.304"]
"markostam/active-noise-cancellation" ["l"="2.394,39.302"]
"xiezhq-hermann/ANC_signal-system_project" ["l"="2.372,39.347"]
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" ["l"="2.376,39.334"]
"sandprddy/Active-Noise-Cancellation-System" ["l"="2.389,39.341"]
"psykulsk/RpiANC" ["l"="2.374,39.364"]
"stephencwelch/Active-Noise-Cancellation" ["l"="2.394,39.355"]
"JusperLee/speech_separation" ["l"="2.582,39.057"]
"CharlesThaCat/acoustic-interference-cancellation" ["l"="2.409,39.338"]
"Turing311/Realtime_AudioDenoise_EchoCancellation" ["l"="2.392,39.29"]
"PandoraLS/traditional-speech-enhancement" ["l"="2.396,39.321"]
"xiongyihui/speexdsp-python" ["l"="2.357,39.299"]
"ShinoharaYuuyoru/NoiseReductionUsingGRU" ["l"="2.345,39.058"]
"d-kitamura/AuxIVA-ISS" ["l"="2.275,39.169"]
"yuguochencuc/DB-AIAT" ["l"="2.504,39.328"]
"NVIDIA/CleanUNet" ["l"="2.471,39.357"]
"Andong-Li-speech/TaylorSENet" ["l"="2.485,39.323"]
"neillu23/CDiffuSE" ["l"="2.505,39.356"]
"sp-uhh/storm" ["l"="2.493,39.37"]
"Andong-Li-speech/TaylorBeamformer" ["l"="2.493,39.329"]
"WenzheLiu-Speech/awesome-speech-enhancement" ["l"="2.477,39.251"]
"introlab/odas_web" ["l"="2.282,39.236"]
"introlab/manyears" ["l"="2.351,39.229"]
"chanil1218/DCUnet.pytorch" ["l"="2.578,39.177"]
"SuperKogito/spafe" ["l"="2.44,39.103"]
"detly/gammatone" ["l"="2.442,39.029"]
"ZhihaoDU/speech_feature_extractor" ["l"="2.422,39.018"]
"jsingh811/pyAudioProcessing" ["l"="2.416,39.046"]
"Snowdar/asv-subtools" ["l"="0.398,39.785"]
"qiuqiangkong/torchlibrosa" ["l"="0.236,39.869"]
"cvqluu/TDNN" ["l"="0.318,39.696"]
"yoonsanghyu/FaSNet-TAC-PyTorch" ["l"="2.444,39.139"]
"YongyuG/rnnoise_16k" ["l"="2.219,39.24"]
"orctom/rnnoise-java" ["l"="2.246,39.237"]
"KyleZhang1118/Voice-Separation-and-Enhancement" ["l"="2.293,39.175"]
"nay0648/bssaec2020" ["l"="2.318,39.238"]
"DistantSpeechRecognition/mcse" ["l"="2.382,39.231"]
"amaas/rnn-speech-denoising" ["l"="2.634,39.293"]
"Unisound/SpeechSeparation" ["l"="2.643,39.221"]
"posenhuang/singingvoiceseparationrpca" ["l"="2.669,39.309"]
"xiongyihui/python-webrtc-audio-processing" ["l"="2.337,39.28"]
"jonlu0602/DeepDenoisingAutoencoder" ["l"="2.588,39.269"]
"gionanide/Speech_Signal_Processing_and_Classification" ["l"="2.41,38.967"]
"gionanide/Neural_Machine_Translation" ["l"="2.405,38.947"]
"Zhangtingyuxuan/voice_activity_detection" ["l"="2.5,39.413"]
"mpariente/AsSteroid" ["l"="2.523,39.114"]
"fgnt/sms_wsj" ["l"="2.547,39.119"]
"fakufaku/fast_bss_eval" ["l"="2.669,39.219"]
"tky823/ssspy" ["l"="2.731,39.21"]
"gogyzzz/beamformit_matlab" ["l"="2.347,39.199"]
"wangtianrui/HGCN" ["l"="2.503,39.298"]
"onolab-tmu/libss" ["l"="2.757,39.206"]
"khaotik/DaNet-Tensorflow" ["l"="2.65,39.197"]
"WilliamYu1993/ICSE" ["l"="2.602,39.255"]
"AppleHolic/source_separation" ["l"="2.537,39.185"]
"AppleHolic/pytorch_sound" ["l"="2.584,39.128"]
"sunits/rir_simulator_python" ["l"="2.719,39.154"]
"jonashaag/RealRIRs" ["l"="2.665,39.167"]
"chanil1218/Attention-SE.pytorch" ["l"="2.635,39.161"]
"JupiterEthan/GCRN-complex" ["l"="2.598,39.22"]
"LeeTaewoo/TL-SSC_SRP-PHAT" ["l"="2.307,39.219"]
"LeeTaewoo/fast_sound_source_localization_using_TLSSC" ["l"="2.303,39.232"]
"singaxiong/SignalGraph" ["l"="2.24,39.142"]
"ws-choi/Conditioned-Source-Separation-LaSAFT" ["l"="0.003,40.079"]
"ZitengWang/nn_mask" ["l"="2.353,39.185"]
"willhope/Noise-reduction" ["l"="-26.71,13.781"]
"nii-yamagishilab/mos-finetune-ssl" ["l"="2.484,39.025"]
"dhimasryan/MOSA-Net-Cross-Domain" ["l"="2.491,38.987"]
"k2kobayashi/crank" ["l"="0.323,40.131"]
"nii-yamagishilab/multi-speaker-tacotron" ["l"="0.383,40.072"]
"Max-Manning/passiveRadar" ["l"="1.893,39.437"]
"jmfriedt/passive_radar" ["l"="1.871,39.43"]
"rtlsdrblog/kerberossdr" ["l"="1.925,39.446"]
"Zihang97/PAGAN" ["l"="2.612,39.263"]
"aleXiehta/PhoneFortifiedPerceptualLoss" ["l"="2.623,39.273"]
"zhr1201/OMLSA-speech-enhancement" ["l"="2.669,39.325"]
"asappresearch/sru" ["l"="2.442,39.288"]
"bamtercelboo/pytorch_SRU" ["l"="2.428,39.33"]
"lmnt-com/haste" ["l"="2.426,39.378"]
"microsoft/fastformers" ["l"="29.654,32.413"]
"idiap/fast-transformers" ["l"="29.608,30.76"]
"guolinke/TUPE" ["l"="29.602,30.87"]
"google-research/long-range-arena" ["l"="29.627,30.739"]
"hirofumi0810/neural_sp" ["l"="0.546,39.816"]
"kaituoxu/Speech-Transformer" ["l"="0.581,39.82"]
"lifeiteng/codingmath" ["l"="2.273,39.255"]
"introlab/16SoundsUSB" ["l"="2.222,39.216"]
"yechengxi/LightNet" ["l"="2.079,39.079"]
"huashiyiqike/LSTM-MATLAB" ["l"="2.123,39.09"]
"yechengxi/LightCapsNet" ["l"="2.046,39.069"]
"JianboTang/RNN_MATLAB" ["l"="2.095,39.067"]
"CedricChing/DeepMRI" ["l"="28.309,36.053"]
"MRSRL/dl-cs" ["l"="2.67,39.076"]
"VLOGroup/mri-variationalnetwork" ["l"="28.336,36.066"]
"khammernik/sigmanet" ["l"="28.332,36.085"]
"hossam-elrewaidy/urus-mri-recon" ["l"="2.656,39.084"]
"fakufaku/piva" ["l"="2.6,39.283"]
"bingo-todd/Gammatone-filters" ["l"="2.445,39.003"]
"cwxcode/LSTM-matlab" ["l"="2.117,39.066"]
"huashiyiqike/NETLAB" ["l"="2.132,39.073"]
"SunQilin/lstm_matlab" ["l"="2.101,39.1"]
"jimmy-ren/vLSTM" ["l"="2.103,39.08"]
"jcsilva/deep-clustering" ["l"="2.679,39.208"]
"chaodengusc/DeWave" ["l"="2.702,39.206"]
"XiaoxiangGao/Dual_mic_phase_based_speech_enhancement" ["l"="2.327,39.202"]
"satyanamuduri/Speech-Enhancement-Using-GSC" ["l"="2.309,39.206"]
"Akki369/Generalised-Side-Lobe-Canceller" ["l"="2.317,39.198"]
"echocatzh/py-aec-unified2021" ["l"="2.437,39.341"]
"ConferencingSpeech/ConferencingSpeech2022" ["l"="2.368,39.181"]
"alibabasglab/FRCRN" ["l"="2.541,39.319"]
"IMYBo/SDDNet" ["l"="2.525,39.31"]
"MuSAELab/SRMRToolbox" ["l"="2.564,39.317"]
"avcodecs/DTLNtfliteC" ["l"="2.412,39.301"]
"Turing311/Face_Liveness_Detection_Android_iOS" ["l"="2.378,39.318"]
"theLittleTiger/AuxIVA" ["l"="2.246,39.163"]
"xiph/speex" ["l"="-26.681,13.734"]
"JupiterEthan/CRN-causal" ["l"="2.624,39.226"]
"rrbluke/CDEC" ["l"="2.414,39.314"]
"Zhongyang-debug/Attention-Is-All-You-Need-In-Speech-Separation" ["l"="2.555,39.131"]
"xiaochunxin/OMLSA-MCRA" ["l"="2.285,39.322"]
"auspicious3000/deepbeam" ["l"="2.635,39.351"]
"zhr1201/Multi-channel-speech-extraction-using-DNN" ["l"="2.655,39.37"]
"respeaker/4mics_hat" ["l"="2.315,39.374"]
"HinTak/seeed-voicecard" ["l"="2.279,39.393"]
"waveshare/WM8960-Audio-HAT" ["l"="2.303,39.39"]
"SeeedDocument/ReSpeaker-4-Mic-Array-for-Raspberry-Pi" ["l"="2.281,39.376"]
"respeaker/respeakerd" ["l"="2.298,39.376"]
"daitan-innovation/cnn-audio-denoiser" ["l"="2.545,39.264"]
"funcwj/nn-ideal-mask" ["l"="2.574,39.307"]
"vivjay30/Cone-of-Silence" ["l"="2.457,39.128"]
"felixfuyihui/AISHELL-4" ["l"="0.303,39.8"]
"yuhogun0908/MISOnet" ["l"="2.454,39.08"]
"Andong-Li-speech/G2Net" ["l"="2.491,39.349"]
"adrienchaton/PerceptualAudio_Pytorch" ["l"="2.429,39.078"]
"timsainb/python_spectrograms_and_inversion" ["l"="2.73,39.349"]
"kastnerkyle/tools" ["l"="2.758,39.366"]
"Spritea/AEC" ["l"="2.309,39.32"]
"yoonsanghyu/Dual-Path-Transformer-Network-PyTorch" ["l"="2.507,39.091"]
"Ifsttar/NoiseModelling" ["l"="2.254,39.065"]
"aothms/ear" ["l"="2.242,39.081"]
"rinaldipp/tmm" ["l"="2.285,39.082"]
"wangtianrui/DCCRN" ["l"="2.603,39.204"]
"runninging/TASNET" ["l"="2.6,39.145"]
"CharlieHouse/RPi_SISO_ANC" ["l"="2.373,39.389"]
"Andong-Li-speech/GaGNet" ["l"="2.529,39.339"]
"mindslab-ai/phaseaug" ["l"="0.182,40.031"]
"zqwang7/CausalityCheck" ["l"="2.521,39.39"]
"thesofproject/kconfig" ["l"="2.317,39.47"]
"funcwj/conv-tas-net" ["l"="2.691,39.182"]
"Totoketchup/Adaptive-MultiSpeaker-Separation" ["l"="2.706,39.187"]
"eric-brandao/rec_room_wave_acoustics" ["l"="2.297,39.079"]
"vaaiibhav/LMS-echo-cancellation" ["l"="2.267,39.333"]
"FrancoisGrondin/BIRD" ["l"="2.52,39.323"]
"maj4e/pyrirtool" ["l"="2.619,39.177"]
"Marvin182/rir-database" ["l"="2.603,39.176"]
"eran-shahar/Double-talk-Detection-aided-Residual-Echo-Suppression-via-Spectrogram-Masking-and-Refinement" ["l"="2.449,39.48"]
"bill9800/speech_separation" ["l"="26.535,-20.615"]
"JusperLee/ExamOnline" ["l"="26.582,-20.585"]
"krakenrf/krakensdr_doa" ["l"="1.875,39.475"]
"krakenrf/heimdall_daq_fw" ["l"="1.859,39.483"]
"krakenrf/krakensdr_docs" ["l"="1.856,39.468"]
"krakenrf/krakensdr_pr" ["l"="1.844,39.48"]
"krakenrf/gr-krakensdr" ["l"="1.86,39.494"]
"ckoval7/df-aggregator" ["l"="1.883,39.496"]
"sarulab-speech/UTMOS22" ["l"="2.495,38.92"]
"unilight/LDNet" ["l"="2.5,38.939"]
"JusperLee/small-tools" ["l"="2.576,39.027"]
"TracyJichuan/webrtc_noise_suppression" ["l"="2.172,39.275"]
"JusperLee/awesome-speech-enhancement" ["l"="2.592,39.011"]
"rtlsdrblog/rtl-sdr-kerberos" ["l"="1.923,39.463"]
"tejeez/rtl_coherent" ["l"="-10.777,-37.699"]
"sindhurach94/Sound-source-localization" ["l"="2.262,39.242"]
"Sato-Kunihiko/audio-SNR" ["l"="2.418,39.146"]
"dhimasryan/STOI-Net" ["l"="2.496,38.968"]
"xiph/LPCNet" ["l"="2.54,39.303"]
"yl4579/StyleTTS" ["l"="0.156,40.095"]
"sky1456723/Pytorch-MBNet" ["l"="2.515,38.924"]
"JusperLee/TDANet" ["l"="2.517,39.371"]
"doraTeX/TeX2img" ["l"="2.722,39.123"]
"pyfar/sofar" ["l"="2.274,39.113"]
"JusperLee/Arxiv-New-Paper-Server" ["l"="2.579,39.007"]
}